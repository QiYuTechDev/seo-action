{"version":3,"file":"index.js","sources":["../webpack://qiyu-seo-action/./lib/cli.js","../webpack://qiyu-seo-action/./lib/code.js","../webpack://qiyu-seo-action/./lib/debug.js","../webpack://qiyu-seo-action/./lib/dl.js","../webpack://qiyu-seo-action/./lib/install.js","../webpack://qiyu-seo-action/./lib/main.js","../webpack://qiyu-seo-action/./lib/run.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/artifact-client.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/artifact-client.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/config-variables.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/download-http-client.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/download-specification.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/http-manager.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/requestUtils.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/status-reporter.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/upload-gzip.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/upload-http-client.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/upload-specification.js","../webpack://qiyu-seo-action/./node_modules/@actions/artifact/lib/internal/utils.js","../webpack://qiyu-seo-action/./node_modules/@actions/core/lib/command.js","../webpack://qiyu-seo-action/./node_modules/@actions/core/lib/core.js","../webpack://qiyu-seo-action/./node_modules/@actions/core/lib/file-command.js","../webpack://qiyu-seo-action/./node_modules/@actions/core/lib/oidc-utils.js","../webpack://qiyu-seo-action/./node_modules/@actions/core/lib/utils.js","../webpack://qiyu-seo-action/./node_modules/@actions/http-client/auth.js","../webpack://qiyu-seo-action/./node_modules/@actions/http-client/index.js","../webpack://qiyu-seo-action/./node_modules/@actions/http-client/proxy.js","../webpack://qiyu-seo-action/./node_modules/balanced-match/index.js","../webpack://qiyu-seo-action/./node_modules/brace-expansion/index.js","../webpack://qiyu-seo-action/./node_modules/concat-map/index.js","../webpack://qiyu-seo-action/./node_modules/data-uri-to-buffer/dist/src/index.js","../webpack://qiyu-seo-action/./node_modules/fs.realpath/index.js","../webpack://qiyu-seo-action/./node_modules/fs.realpath/old.js","../webpack://qiyu-seo-action/./node_modules/glob/common.js","../webpack://qiyu-seo-action/./node_modules/glob/glob.js","../webpack://qiyu-seo-action/./node_modules/glob/sync.js","../webpack://qiyu-seo-action/./node_modules/inflight/inflight.js","../webpack://qiyu-seo-action/./node_modules/inherits/inherits.js","../webpack://qiyu-seo-action/./node_modules/inherits/inherits_browser.js","../webpack://qiyu-seo-action/./node_modules/minimatch/minimatch.js","../webpack://qiyu-seo-action/./node_modules/fetch-blob/index.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/errors/base.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/errors/fetch-error.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/utils/is.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/utils/form-data.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/body.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/headers.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/utils/is-redirect.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/response.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/utils/get-search.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/request.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/errors/abort-error.js","../webpack://qiyu-seo-action/./node_modules/node-fetch/src/index.js","../webpack://qiyu-seo-action/./node_modules/once/once.js","../webpack://qiyu-seo-action/./node_modules/path-is-absolute/index.js","../webpack://qiyu-seo-action/./node_modules/tmp-promise/index.js","../webpack://qiyu-seo-action/./node_modules/tmp/lib/tmp.js","../webpack://qiyu-seo-action/./node_modules/tmp/node_modules/rimraf/rimraf.js","../webpack://qiyu-seo-action/./node_modules/tunnel/index.js","../webpack://qiyu-seo-action/./node_modules/tunnel/lib/tunnel.js","../webpack://qiyu-seo-action/./node_modules/web-streams-polyfill/dist/ponyfill.es2018.js","../webpack://qiyu-seo-action/./node_modules/wrappy/wrappy.js","../webpack://qiyu-seo-action/./node_modules/@vercel/ncc/dist/ncc/@@notfound.js","../webpack://qiyu-seo-action/./node_modules/fetch-blob/streams.cjs","../webpack://qiyu-seo-action/./node_modules/qiyu-seo/dist/seo_js_sdk.cjs","../webpack://qiyu-seo-action/external \"assert\"","../webpack://qiyu-seo-action/external \"buffer\"","../webpack://qiyu-seo-action/external \"child_process\"","../webpack://qiyu-seo-action/external \"crypto\"","../webpack://qiyu-seo-action/external \"events\"","../webpack://qiyu-seo-action/external \"fs\"","../webpack://qiyu-seo-action/external \"http\"","../webpack://qiyu-seo-action/external \"https\"","../webpack://qiyu-seo-action/external \"net\"","../webpack://qiyu-seo-action/external \"os\"","../webpack://qiyu-seo-action/external \"path\"","../webpack://qiyu-seo-action/external \"perf_hooks\"","../webpack://qiyu-seo-action/external \"process\"","../webpack://qiyu-seo-action/external \"stream\"","../webpack://qiyu-seo-action/external \"tls\"","../webpack://qiyu-seo-action/external \"url\"","../webpack://qiyu-seo-action/external \"util\"","../webpack://qiyu-seo-action/external \"zlib\"","../webpack://qiyu-seo-action/webpack/bootstrap","../webpack://qiyu-seo-action/webpack/runtime/define property getters","../webpack://qiyu-seo-action/webpack/runtime/hasOwnProperty shorthand","../webpack://qiyu-seo-action/webpack/runtime/make namespace object","../webpack://qiyu-seo-action/webpack/runtime/compat","../webpack://qiyu-seo-action/webpack/startup"],"sourcesContent":["\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.cliRun = void 0;\nconst core = __importStar(require(\"@actions/core\"));\nconst process_1 = __importDefault(require(\"process\"));\nconst child_process = __importStar(require(\"child_process\"));\nconst debug_1 = require(\"./debug\");\n/**\n * 运行 cli 命令\n * @param cli\n * @param args\n * @param sync\n * @param allow_fail\n */\nfunction cliRun(cli, args = null, sync = true, allow_fail = false) {\n    let shell = undefined;\n    if (cli === \"xpra\") {\n        shell = true;\n    }\n    core.info(`${cli} ${(args || []).join(\" \")}`);\n    if (!sync) {\n        const stdout = [];\n        const stderr = [];\n        const ret = child_process.spawn(cli, args || [], { detached: true, shell: shell });\n        ret.stdout.on('data', (data) => {\n            stdout.push(data);\n        });\n        ret.stderr.on('data', (data) => {\n            stderr.push(data);\n        });\n        process_1.default.on('beforeExit', () => {\n            core.info(`${cli} stdout:`);\n            for (const s of stdout) {\n                core.notice(s);\n            }\n            core.info(`${cli} stderr:`);\n            for (const s of stderr) {\n                core.info(s);\n            }\n        });\n        return;\n    }\n    let ret = child_process.spawnSync(cli, args || [], { shell: shell });\n    if (ret.status !== 0) {\n        if ((0, debug_1.debugMode)()) {\n            core.notice(`${cli} stdout: ${ret.stdout}`);\n            core.info(`${cli} stderr: ${ret.stderr}`);\n        }\n        if (allow_fail) {\n            core.info(`exec ${cli} ${JSON.stringify(args)} failed`);\n        }\n        else {\n            core.setFailed(`exec ${cli} ${JSON.stringify(args)} failed`);\n        }\n    }\n    else {\n        if ((0, debug_1.debugMode)()) {\n            core.notice(ret.stdout.toString());\n            core.info(ret.stderr.toString());\n        }\n    }\n}\nexports.cliRun = cliRun;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.runCode = void 0;\nconst fs_1 = __importDefault(require(\"fs\"));\nconst path_1 = __importDefault(require(\"path\"));\nconst os_1 = __importDefault(require(\"os\"));\nconst core = __importStar(require(\"@actions/core\"));\nconst artifact = __importStar(require(\"@actions/artifact\"));\nconst qiyu_seo_1 = require(\"qiyu-seo\");\nconst cli_1 = require(\"./cli\");\nconst debug_1 = require(\"./debug\");\nfunction uploadFile(name, file) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const client = artifact.create();\n        yield client.uploadArtifact(name, [file], path_1.default.dirname(file), { continueOnError: true });\n    });\n}\n/**\n * 运行 custom 代码\n */\nfunction runCode() {\n    var _a, _b, _c;\n    return __awaiter(this, void 0, void 0, function* () {\n        const url = core.getInput(\"url\");\n        const code_file = core.getInput(\"code\");\n        const snapshot = core.getBooleanInput(\"snapshot\");\n        const pdf = core.getBooleanInput(\"pdf\");\n        const video = core.getBooleanInput(\"video\");\n        const rrweb = core.getBooleanInput(\"rrweb\");\n        const timeout = Number(core.getInput(\"timeout\"));\n        const code = fs_1.default.readFileSync(`${process.env['GITHUB_WORKSPACE']}/${code_file}`, { encoding: 'utf-8' });\n        core.info(`try to visit url: ${url}`);\n        core.info(`js code:\\n${code}\\n\\n`);\n        const args = {\n            url: url,\n            fn_code: code,\n            timeout: timeout,\n            auto_close: true,\n            snapshot: snapshot,\n            pdf: pdf,\n            video: video,\n            rrweb: rrweb,\n        };\n        const bearer = process.env['SEO_REST_API_BEARER'] || 'seo';\n        if ((0, debug_1.debugMode)() && os_1.default.platform() === 'linux') {\n            (0, cli_1.cliRun)(\"sudo\", [\"netstat\", \"-plnt\"]);\n        }\n        let success = true;\n        const resp = yield qiyu_seo_1.Ci.do_post({ body: args, security: { bearer } }, (resp) => __awaiter(this, void 0, void 0, function* () {\n            return yield resp.json();\n        }), (resp) => __awaiter(this, void 0, void 0, function* () {\n            const txt = yield resp.text();\n            success = false;\n            core.setFailed(`失败:\nhttp code: ${resp.status} \nresult: ${txt}\n`);\n        }));\n        if (success) {\n            if (snapshot && ((_a = resp.data) === null || _a === void 0 ? void 0 : _a.snapshot_file)) {\n                yield uploadFile(\"snapshot\", resp.data.snapshot_file);\n            }\n            if (pdf && ((_b = resp.data) === null || _b === void 0 ? void 0 : _b.pdf_file)) {\n                yield uploadFile(\"pdf\", resp.data.pdf_file);\n            }\n            if (rrweb && ((_c = resp.data) === null || _c === void 0 ? void 0 : _c.rrweb_file)) {\n                yield uploadFile(\"rrweb\", resp.data.rrweb_file);\n            }\n            core.info(\"success:\");\n            core.info(JSON.stringify(resp, null, 2));\n        }\n    });\n}\nexports.runCode = runCode;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.debugMode = void 0;\nconst core = __importStar(require(\"@actions/core\"));\n/**\n * 调试模式\n */\nfunction debugMode() {\n    return core.getBooleanInput(\"debug\") || false;\n}\nexports.debugMode = debugMode;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.downloadPackage = exports.getDownloadUrl = exports.getDownloadFile = void 0;\nconst os_1 = __importDefault(require(\"os\"));\nconst core = __importStar(require(\"@actions/core\"));\nconst cli_1 = require(\"./cli\");\n/**\n * 获取下载的文件名\n */\nfunction getDownloadFile() {\n    switch (os_1.default.platform()) {\n        case 'linux':\n            return `seo_amd64.deb`;\n        case 'darwin':\n            return `mac.zip`;\n        case 'win32':\n            return `seo_setup.exe`;\n        default:\n            core.setFailed(`${os_1.default.platform()} is not supported[only support linux[debian&ubuntu] & macOS, win32]`);\n            return null;\n    }\n}\nexports.getDownloadFile = getDownloadFile;\n/**\n * 获取安装包下载的 URL\n * @param version\n */\nfunction getDownloadUrl(version) {\n    const prefix = 'https://github.com/QiYuTechDev/seo/releases/download';\n    switch (os_1.default.platform()) {\n        case 'linux':\n            return `${prefix}/${version}/${getDownloadFile()}`;\n        case 'darwin':\n            return `${prefix}/${version}/${getDownloadFile()}`;\n        case 'win32':\n            return `${prefix}/${version}/${getDownloadFile()}`;\n        default:\n            return null;\n    }\n}\nexports.getDownloadUrl = getDownloadUrl;\n/**\n * windows not have wget cli\n */\nfunction installWgetIfNeeded() {\n    if (os_1.default.platform() === 'win32') {\n        core.info(\"install wget for windows\");\n        (0, cli_1.cliRun)(\"choco\", [\"install\", \"--no-progress\", \"wget\"]);\n    }\n}\nfunction downloadPackage(version) {\n    const url = getDownloadUrl(version);\n    if (!url) {\n        core.setFailed('not supported platform[only support windows linux and macOS]');\n        return;\n    }\n    core.info('start download: ' + url);\n    installWgetIfNeeded();\n    (0, cli_1.cliRun)(\"wget\", [\"-q\", url]);\n}\nexports.downloadPackage = downloadPackage;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.installPackage = void 0;\nconst os_1 = __importDefault(require(\"os\"));\nconst core = __importStar(require(\"@actions/core\"));\nconst dl_1 = require(\"./dl\");\nconst cli_1 = require(\"./cli\");\nfunction installPackage() {\n    const file = (0, dl_1.getDownloadFile)();\n    if (!file) {\n        return;\n    }\n    core.info('start install:' + file);\n    switch (os_1.default.platform()) {\n        case \"win32\":\n            // https://github.com/Squirrel/Squirrel.Windows/pull/187\n            (0, cli_1.cliRun)(file, [\"-s\"]);\n            break;\n        case 'linux':\n            (0, cli_1.cliRun)(\"sudo\", [\"apt\", \"update\"]);\n            (0, cli_1.cliRun)(\"sudo\", [\"dpkg\", \"-i\", file]);\n            (0, cli_1.cliRun)(\"sudo\", [\"apt\", \"--fix-broken\", \"-y\", \"install\"]);\n            (0, cli_1.cliRun)(\"sudo\", [\"snap\", \"install\", \"chromium-ffmpeg\"]);\n            (0, cli_1.cliRun)(\"sudo\", [\"ln\", \"-s\", \"/snap/chromium-ffmpeg/current/chromium-ffmpeg-104195/chromium-ffmpeg/libffmpeg.so\", \"/usr/lib/x86_64-linux-gnu/libffmpeg.so\"]);\n            (0, cli_1.cliRun)(\"sudo\", [\"apt\", \"install\", \"-qq\", \"-y\", \"xpra\", \"dbus-x11\"]);\n            (0, cli_1.cliRun)(\"pip3\", [\"install\", \"--user\", \"xpra\"]);\n            break;\n        case 'darwin':\n            (0, cli_1.cliRun)(\"unzip\", [\"-qq\", file]);\n            break;\n        default:\n            core.setFailed(`${os_1.default.platform()} is not supported[only support linux[debian&ubuntu] & macOS, win32]`);\n            return;\n    }\n}\nexports.installPackage = installPackage;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst core = __importStar(require(\"@actions/core\"));\nconst node_fetch_1 = __importDefault(require(\"node-fetch\"));\nconst dl_1 = require(\"./dl\");\nconst install_1 = require(\"./install\");\nconst run_1 = require(\"./run\");\nconst code_1 = require(\"./code\");\nglobalThis.fetch = node_fetch_1.default;\nfunction main() {\n    try {\n        const version = core.getInput(\"version\");\n        core.info(`use seo version: ${version}`);\n        (0, dl_1.downloadPackage)(version);\n        (0, install_1.installPackage)();\n        (0, run_1.runSeo)();\n        setTimeout(() => __awaiter(this, void 0, void 0, function* () {\n            yield (0, code_1.runCode)();\n            process.exit(0);\n        }), 10 * 1000); // wait seo startup\n    }\n    catch (error) {\n        core.setFailed(error.message);\n    }\n}\nmain();\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.runSeo = void 0;\nconst os_1 = __importDefault(require(\"os\"));\nconst core = __importStar(require(\"@actions/core\"));\nconst cli_1 = require(\"./cli\");\nconst debug_1 = require(\"./debug\");\nfunction runLinux() {\n    core.info(\"install mongodb\");\n    (0, cli_1.cliRun)(\"wget\", [\"-qq\", \"https://repo.mongodb.org/apt/ubuntu/dists/focal/mongodb-org/5.0/multiverse/binary-amd64/mongodb-org-server_5.0.3_amd64.deb\"]);\n    (0, cli_1.cliRun)(\"sudo\", [\"dpkg\", \"-i\", \"mongodb-org-server_5.0.3_amd64.deb\"]);\n    (0, cli_1.cliRun)(\"sudo\", [\"mongod\", \"--fork\", \"--port=27019\", \"-f\", \"/etc/mongod.conf\"]);\n    core.info(\"xpra env info\");\n    (0, cli_1.cliRun)(\"xpra\", [\"start\", \"--start-child=\\\"env\\\"\", \"--bind-tcp=127.0.0.1:28182\", \"--html=off\", \"--exit-with-children\", \"--daemon=off\"], true, true);\n    core.info(\"test mongodb connection\");\n    (0, cli_1.cliRun)(\"xpra\", [\"start\", \"--start-child=\\\"seo --mongo-url=mongodb://127.0.0.1:27019 --test-mongo-server\\\"\", \"--bind-tcp=127.0.0.1:28182\", \"--html=off\", \"--exit-with-children\", \"--daemon=off\"], true, true);\n    core.info(\"start seo in background\");\n    (0, cli_1.cliRun)(\"xpra\", [\"start\", \"--start-child=\\\"seo --mongo-url=mongodb://127.0.0.1:27019\\\"\", \"--bind-tcp=127.0.0.1:28182\", \"--html=on\", \"--exit-with-children\", \"--daemon=on\"]);\n}\nfunction runMacOS() {\n    core.info(\"install mongodb\");\n    (0, cli_1.cliRun)(\"brew\", [\"tap\", \"mongodb/brew\"]);\n    (0, cli_1.cliRun)(\"brew\", [\"install\", \"mongodb-community@5.0\"]);\n    core.info(\"start mongodb\");\n    (0, cli_1.cliRun)(\"brew\", [\"services\", \"start\", \"mongodb-community\"]);\n    core.info(\"start seo\");\n    (0, cli_1.cliRun)(\"./seo.app/Contents/MacOS/seo\", [\"--test-mongo-server\", \"--mongo-url=mongodb://127.0.0.1:27019\"]);\n    (0, cli_1.cliRun)(\"./seo.app/Contents/MacOS/seo\", [\"--mongo-url=mongodb://127.0.0.1:27019\"], false);\n}\nfunction runWin32() {\n    if ((0, debug_1.debugMode)()) {\n        core.info(\"debug info\");\n        (0, cli_1.cliRun)(\"whoami\");\n        (0, cli_1.cliRun)(\"ls\", [\"c:\\\\\\\\users\\\\\\\\runneradmin\\\\\\\\AppData\\\\\\\\Local\\\\\\\\seo\"]);\n    }\n    core.info(\"install mongodb\");\n    (0, cli_1.cliRun)(\"choco\", [\"install\", \"mongodb\"]);\n    core.info(\"show all windows services\");\n    core.info(\"test mongodb connection\");\n    (0, cli_1.cliRun)(\"c:\\\\users\\\\runneradmin\\\\AppData\\\\Local\\\\seo\\\\seo.exe\", [\"--test-mongo-server\", \"--mongo-url=mongodb://127.0.0.1:27019\"]);\n    core.info(\"start seo\");\n    (0, cli_1.cliRun)(\"c:\\\\users\\\\runneradmin\\\\AppData\\\\Local\\\\seo\\\\seo.exe\", [\"--mongo-url=mongodb://127.0.0.1:27019\"], false);\n}\nfunction runSeo() {\n    process.env[\"SEO_REST_API_ENABLE\"] = \"1\";\n    process.env['SEO_REST_API_HOST'] = \"127.0.0.1\";\n    process.env['SEO_REST_API_PORT'] = \"18082\";\n    switch (os_1.default.platform()) {\n        case \"linux\":\n            runLinux();\n            break;\n        case \"win32\":\n            runWin32();\n            break;\n        case \"darwin\":\n            runMacOS();\n            break;\n        default:\n            break;\n    }\n}\nexports.runSeo = runSeo;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst artifact_client_1 = require(\"./internal/artifact-client\");\n/**\n * Constructs an ArtifactClient\n */\nfunction create() {\n    return artifact_client_1.DefaultArtifactClient.create();\n}\nexports.create = create;\n//# sourceMappingURL=artifact-client.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst core = __importStar(require(\"@actions/core\"));\nconst upload_specification_1 = require(\"./upload-specification\");\nconst upload_http_client_1 = require(\"./upload-http-client\");\nconst utils_1 = require(\"./utils\");\nconst download_http_client_1 = require(\"./download-http-client\");\nconst download_specification_1 = require(\"./download-specification\");\nconst config_variables_1 = require(\"./config-variables\");\nconst path_1 = require(\"path\");\nclass DefaultArtifactClient {\n    /**\n     * Constructs a DefaultArtifactClient\n     */\n    static create() {\n        return new DefaultArtifactClient();\n    }\n    /**\n     * Uploads an artifact\n     */\n    uploadArtifact(name, files, rootDirectory, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            utils_1.checkArtifactName(name);\n            // Get specification for the files being uploaded\n            const uploadSpecification = upload_specification_1.getUploadSpecification(name, rootDirectory, files);\n            const uploadResponse = {\n                artifactName: name,\n                artifactItems: [],\n                size: 0,\n                failedItems: []\n            };\n            const uploadHttpClient = new upload_http_client_1.UploadHttpClient();\n            if (uploadSpecification.length === 0) {\n                core.warning(`No files found that can be uploaded`);\n            }\n            else {\n                // Create an entry for the artifact in the file container\n                const response = yield uploadHttpClient.createArtifactInFileContainer(name, options);\n                if (!response.fileContainerResourceUrl) {\n                    core.debug(response.toString());\n                    throw new Error('No URL provided by the Artifact Service to upload an artifact to');\n                }\n                core.debug(`Upload Resource URL: ${response.fileContainerResourceUrl}`);\n                // Upload each of the files that were found concurrently\n                const uploadResult = yield uploadHttpClient.uploadArtifactToFileContainer(response.fileContainerResourceUrl, uploadSpecification, options);\n                // Update the size of the artifact to indicate we are done uploading\n                // The uncompressed size is used for display when downloading a zip of the artifact from the UI\n                yield uploadHttpClient.patchArtifactSize(uploadResult.totalSize, name);\n                core.info(`Finished uploading artifact ${name}. Reported size is ${uploadResult.uploadSize} bytes. There were ${uploadResult.failedItems.length} items that failed to upload`);\n                uploadResponse.artifactItems = uploadSpecification.map(item => item.absoluteFilePath);\n                uploadResponse.size = uploadResult.uploadSize;\n                uploadResponse.failedItems = uploadResult.failedItems;\n            }\n            return uploadResponse;\n        });\n    }\n    downloadArtifact(name, path, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const downloadHttpClient = new download_http_client_1.DownloadHttpClient();\n            const artifacts = yield downloadHttpClient.listArtifacts();\n            if (artifacts.count === 0) {\n                throw new Error(`Unable to find any artifacts for the associated workflow`);\n            }\n            const artifactToDownload = artifacts.value.find(artifact => {\n                return artifact.name === name;\n            });\n            if (!artifactToDownload) {\n                throw new Error(`Unable to find an artifact with the name: ${name}`);\n            }\n            const items = yield downloadHttpClient.getContainerItems(artifactToDownload.name, artifactToDownload.fileContainerResourceUrl);\n            if (!path) {\n                path = config_variables_1.getWorkSpaceDirectory();\n            }\n            path = path_1.normalize(path);\n            path = path_1.resolve(path);\n            // During upload, empty directories are rejected by the remote server so there should be no artifacts that consist of only empty directories\n            const downloadSpecification = download_specification_1.getDownloadSpecification(name, items.value, path, (options === null || options === void 0 ? void 0 : options.createArtifactFolder) || false);\n            if (downloadSpecification.filesToDownload.length === 0) {\n                core.info(`No downloadable files were found for the artifact: ${artifactToDownload.name}`);\n            }\n            else {\n                // Create all necessary directories recursively before starting any download\n                yield utils_1.createDirectoriesForArtifact(downloadSpecification.directoryStructure);\n                core.info('Directory structure has been setup for the artifact');\n                yield utils_1.createEmptyFilesForArtifact(downloadSpecification.emptyFilesToCreate);\n                yield downloadHttpClient.downloadSingleArtifact(downloadSpecification.filesToDownload);\n            }\n            return {\n                artifactName: name,\n                downloadPath: downloadSpecification.rootDownloadLocation\n            };\n        });\n    }\n    downloadAllArtifacts(path) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const downloadHttpClient = new download_http_client_1.DownloadHttpClient();\n            const response = [];\n            const artifacts = yield downloadHttpClient.listArtifacts();\n            if (artifacts.count === 0) {\n                core.info('Unable to find any artifacts for the associated workflow');\n                return response;\n            }\n            if (!path) {\n                path = config_variables_1.getWorkSpaceDirectory();\n            }\n            path = path_1.normalize(path);\n            path = path_1.resolve(path);\n            let downloadedArtifacts = 0;\n            while (downloadedArtifacts < artifacts.count) {\n                const currentArtifactToDownload = artifacts.value[downloadedArtifacts];\n                downloadedArtifacts += 1;\n                // Get container entries for the specific artifact\n                const items = yield downloadHttpClient.getContainerItems(currentArtifactToDownload.name, currentArtifactToDownload.fileContainerResourceUrl);\n                const downloadSpecification = download_specification_1.getDownloadSpecification(currentArtifactToDownload.name, items.value, path, true);\n                if (downloadSpecification.filesToDownload.length === 0) {\n                    core.info(`No downloadable files were found for any artifact ${currentArtifactToDownload.name}`);\n                }\n                else {\n                    yield utils_1.createDirectoriesForArtifact(downloadSpecification.directoryStructure);\n                    yield utils_1.createEmptyFilesForArtifact(downloadSpecification.emptyFilesToCreate);\n                    yield downloadHttpClient.downloadSingleArtifact(downloadSpecification.filesToDownload);\n                }\n                response.push({\n                    artifactName: currentArtifactToDownload.name,\n                    downloadPath: downloadSpecification.rootDownloadLocation\n                });\n            }\n            return response;\n        });\n    }\n}\nexports.DefaultArtifactClient = DefaultArtifactClient;\n//# sourceMappingURL=artifact-client.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// The number of concurrent uploads that happens at the same time\nfunction getUploadFileConcurrency() {\n    return 2;\n}\nexports.getUploadFileConcurrency = getUploadFileConcurrency;\n// When uploading large files that can't be uploaded with a single http call, this controls\n// the chunk size that is used during upload\nfunction getUploadChunkSize() {\n    return 8 * 1024 * 1024; // 8 MB Chunks\n}\nexports.getUploadChunkSize = getUploadChunkSize;\n// The maximum number of retries that can be attempted before an upload or download fails\nfunction getRetryLimit() {\n    return 5;\n}\nexports.getRetryLimit = getRetryLimit;\n// With exponential backoff, the larger the retry count, the larger the wait time before another attempt\n// The retry multiplier controls by how much the backOff time increases depending on the number of retries\nfunction getRetryMultiplier() {\n    return 1.5;\n}\nexports.getRetryMultiplier = getRetryMultiplier;\n// The initial wait time if an upload or download fails and a retry is being attempted for the first time\nfunction getInitialRetryIntervalInMilliseconds() {\n    return 3000;\n}\nexports.getInitialRetryIntervalInMilliseconds = getInitialRetryIntervalInMilliseconds;\n// The number of concurrent downloads that happens at the same time\nfunction getDownloadFileConcurrency() {\n    return 2;\n}\nexports.getDownloadFileConcurrency = getDownloadFileConcurrency;\nfunction getRuntimeToken() {\n    const token = process.env['ACTIONS_RUNTIME_TOKEN'];\n    if (!token) {\n        throw new Error('Unable to get ACTIONS_RUNTIME_TOKEN env variable');\n    }\n    return token;\n}\nexports.getRuntimeToken = getRuntimeToken;\nfunction getRuntimeUrl() {\n    const runtimeUrl = process.env['ACTIONS_RUNTIME_URL'];\n    if (!runtimeUrl) {\n        throw new Error('Unable to get ACTIONS_RUNTIME_URL env variable');\n    }\n    return runtimeUrl;\n}\nexports.getRuntimeUrl = getRuntimeUrl;\nfunction getWorkFlowRunId() {\n    const workFlowRunId = process.env['GITHUB_RUN_ID'];\n    if (!workFlowRunId) {\n        throw new Error('Unable to get GITHUB_RUN_ID env variable');\n    }\n    return workFlowRunId;\n}\nexports.getWorkFlowRunId = getWorkFlowRunId;\nfunction getWorkSpaceDirectory() {\n    const workspaceDirectory = process.env['GITHUB_WORKSPACE'];\n    if (!workspaceDirectory) {\n        throw new Error('Unable to get GITHUB_WORKSPACE env variable');\n    }\n    return workspaceDirectory;\n}\nexports.getWorkSpaceDirectory = getWorkSpaceDirectory;\nfunction getRetentionDays() {\n    return process.env['GITHUB_RETENTION_DAYS'];\n}\nexports.getRetentionDays = getRetentionDays;\n//# sourceMappingURL=config-variables.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst fs = __importStar(require(\"fs\"));\nconst core = __importStar(require(\"@actions/core\"));\nconst zlib = __importStar(require(\"zlib\"));\nconst utils_1 = require(\"./utils\");\nconst url_1 = require(\"url\");\nconst status_reporter_1 = require(\"./status-reporter\");\nconst perf_hooks_1 = require(\"perf_hooks\");\nconst http_manager_1 = require(\"./http-manager\");\nconst config_variables_1 = require(\"./config-variables\");\nconst requestUtils_1 = require(\"./requestUtils\");\nclass DownloadHttpClient {\n    constructor() {\n        this.downloadHttpManager = new http_manager_1.HttpManager(config_variables_1.getDownloadFileConcurrency(), '@actions/artifact-download');\n        // downloads are usually significantly faster than uploads so display status information every second\n        this.statusReporter = new status_reporter_1.StatusReporter(1000);\n    }\n    /**\n     * Gets a list of all artifacts that are in a specific container\n     */\n    listArtifacts() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const artifactUrl = utils_1.getArtifactUrl();\n            // use the first client from the httpManager, `keep-alive` is not used so the connection will close immediately\n            const client = this.downloadHttpManager.getClient(0);\n            const headers = utils_1.getDownloadHeaders('application/json');\n            const response = yield requestUtils_1.retryHttpClientRequest('List Artifacts', () => __awaiter(this, void 0, void 0, function* () { return client.get(artifactUrl, headers); }));\n            const body = yield response.readBody();\n            return JSON.parse(body);\n        });\n    }\n    /**\n     * Fetches a set of container items that describe the contents of an artifact\n     * @param artifactName the name of the artifact\n     * @param containerUrl the artifact container URL for the run\n     */\n    getContainerItems(artifactName, containerUrl) {\n        return __awaiter(this, void 0, void 0, function* () {\n            // the itemPath search parameter controls which containers will be returned\n            const resourceUrl = new url_1.URL(containerUrl);\n            resourceUrl.searchParams.append('itemPath', artifactName);\n            // use the first client from the httpManager, `keep-alive` is not used so the connection will close immediately\n            const client = this.downloadHttpManager.getClient(0);\n            const headers = utils_1.getDownloadHeaders('application/json');\n            const response = yield requestUtils_1.retryHttpClientRequest('Get Container Items', () => __awaiter(this, void 0, void 0, function* () { return client.get(resourceUrl.toString(), headers); }));\n            const body = yield response.readBody();\n            return JSON.parse(body);\n        });\n    }\n    /**\n     * Concurrently downloads all the files that are part of an artifact\n     * @param downloadItems information about what items to download and where to save them\n     */\n    downloadSingleArtifact(downloadItems) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const DOWNLOAD_CONCURRENCY = config_variables_1.getDownloadFileConcurrency();\n            // limit the number of files downloaded at a single time\n            core.debug(`Download file concurrency is set to ${DOWNLOAD_CONCURRENCY}`);\n            const parallelDownloads = [...new Array(DOWNLOAD_CONCURRENCY).keys()];\n            let currentFile = 0;\n            let downloadedFiles = 0;\n            core.info(`Total number of files that will be downloaded: ${downloadItems.length}`);\n            this.statusReporter.setTotalNumberOfFilesToProcess(downloadItems.length);\n            this.statusReporter.start();\n            yield Promise.all(parallelDownloads.map((index) => __awaiter(this, void 0, void 0, function* () {\n                while (currentFile < downloadItems.length) {\n                    const currentFileToDownload = downloadItems[currentFile];\n                    currentFile += 1;\n                    const startTime = perf_hooks_1.performance.now();\n                    yield this.downloadIndividualFile(index, currentFileToDownload.sourceLocation, currentFileToDownload.targetPath);\n                    if (core.isDebug()) {\n                        core.debug(`File: ${++downloadedFiles}/${downloadItems.length}. ${currentFileToDownload.targetPath} took ${(perf_hooks_1.performance.now() - startTime).toFixed(3)} milliseconds to finish downloading`);\n                    }\n                    this.statusReporter.incrementProcessedCount();\n                }\n            })))\n                .catch(error => {\n                throw new Error(`Unable to download the artifact: ${error}`);\n            })\n                .finally(() => {\n                this.statusReporter.stop();\n                // safety dispose all connections\n                this.downloadHttpManager.disposeAndReplaceAllClients();\n            });\n        });\n    }\n    /**\n     * Downloads an individual file\n     * @param httpClientIndex the index of the http client that is used to make all of the calls\n     * @param artifactLocation origin location where a file will be downloaded from\n     * @param downloadPath destination location for the file being downloaded\n     */\n    downloadIndividualFile(httpClientIndex, artifactLocation, downloadPath) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let retryCount = 0;\n            const retryLimit = config_variables_1.getRetryLimit();\n            let destinationStream = fs.createWriteStream(downloadPath);\n            const headers = utils_1.getDownloadHeaders('application/json', true, true);\n            // a single GET request is used to download a file\n            const makeDownloadRequest = () => __awaiter(this, void 0, void 0, function* () {\n                const client = this.downloadHttpManager.getClient(httpClientIndex);\n                return yield client.get(artifactLocation, headers);\n            });\n            // check the response headers to determine if the file was compressed using gzip\n            const isGzip = (incomingHeaders) => {\n                return ('content-encoding' in incomingHeaders &&\n                    incomingHeaders['content-encoding'] === 'gzip');\n            };\n            // Increments the current retry count and then checks if the retry limit has been reached\n            // If there have been too many retries, fail so the download stops. If there is a retryAfterValue value provided,\n            // it will be used\n            const backOff = (retryAfterValue) => __awaiter(this, void 0, void 0, function* () {\n                retryCount++;\n                if (retryCount > retryLimit) {\n                    return Promise.reject(new Error(`Retry limit has been reached. Unable to download ${artifactLocation}`));\n                }\n                else {\n                    this.downloadHttpManager.disposeAndReplaceClient(httpClientIndex);\n                    if (retryAfterValue) {\n                        // Back off by waiting the specified time denoted by the retry-after header\n                        core.info(`Backoff due to too many requests, retry #${retryCount}. Waiting for ${retryAfterValue} milliseconds before continuing the download`);\n                        yield utils_1.sleep(retryAfterValue);\n                    }\n                    else {\n                        // Back off using an exponential value that depends on the retry count\n                        const backoffTime = utils_1.getExponentialRetryTimeInMilliseconds(retryCount);\n                        core.info(`Exponential backoff for retry #${retryCount}. Waiting for ${backoffTime} milliseconds before continuing the download`);\n                        yield utils_1.sleep(backoffTime);\n                    }\n                    core.info(`Finished backoff for retry #${retryCount}, continuing with download`);\n                }\n            });\n            const isAllBytesReceived = (expected, received) => {\n                // be lenient, if any input is missing, assume success, i.e. not truncated\n                if (!expected ||\n                    !received ||\n                    process.env['ACTIONS_ARTIFACT_SKIP_DOWNLOAD_VALIDATION']) {\n                    core.info('Skipping download validation.');\n                    return true;\n                }\n                return parseInt(expected) === received;\n            };\n            const resetDestinationStream = (fileDownloadPath) => __awaiter(this, void 0, void 0, function* () {\n                destinationStream.close();\n                yield utils_1.rmFile(fileDownloadPath);\n                destinationStream = fs.createWriteStream(fileDownloadPath);\n            });\n            // keep trying to download a file until a retry limit has been reached\n            while (retryCount <= retryLimit) {\n                let response;\n                try {\n                    response = yield makeDownloadRequest();\n                    if (core.isDebug()) {\n                        utils_1.displayHttpDiagnostics(response);\n                    }\n                }\n                catch (error) {\n                    // if an error is caught, it is usually indicative of a timeout so retry the download\n                    core.info('An error occurred while attempting to download a file');\n                    // eslint-disable-next-line no-console\n                    console.log(error);\n                    // increment the retryCount and use exponential backoff to wait before making the next request\n                    yield backOff();\n                    continue;\n                }\n                let forceRetry = false;\n                if (utils_1.isSuccessStatusCode(response.message.statusCode)) {\n                    // The body contains the contents of the file however calling response.readBody() causes all the content to be converted to a string\n                    // which can cause some gzip encoded data to be lost\n                    // Instead of using response.readBody(), response.message is a readableStream that can be directly used to get the raw body contents\n                    try {\n                        const isGzipped = isGzip(response.message.headers);\n                        yield this.pipeResponseToFile(response, destinationStream, isGzipped);\n                        if (isGzipped ||\n                            isAllBytesReceived(response.message.headers['content-length'], yield utils_1.getFileSize(downloadPath))) {\n                            return;\n                        }\n                        else {\n                            forceRetry = true;\n                        }\n                    }\n                    catch (error) {\n                        // retry on error, most likely streams were corrupted\n                        forceRetry = true;\n                    }\n                }\n                if (forceRetry || utils_1.isRetryableStatusCode(response.message.statusCode)) {\n                    core.info(`A ${response.message.statusCode} response code has been received while attempting to download an artifact`);\n                    resetDestinationStream(downloadPath);\n                    // if a throttled status code is received, try to get the retryAfter header value, else differ to standard exponential backoff\n                    utils_1.isThrottledStatusCode(response.message.statusCode)\n                        ? yield backOff(utils_1.tryGetRetryAfterValueTimeInMilliseconds(response.message.headers))\n                        : yield backOff();\n                }\n                else {\n                    // Some unexpected response code, fail immediately and stop the download\n                    utils_1.displayHttpDiagnostics(response);\n                    return Promise.reject(new Error(`Unexpected http ${response.message.statusCode} during download for ${artifactLocation}`));\n                }\n            }\n        });\n    }\n    /**\n     * Pipes the response from downloading an individual file to the appropriate destination stream while decoding gzip content if necessary\n     * @param response the http response received when downloading a file\n     * @param destinationStream the stream where the file should be written to\n     * @param isGzip a boolean denoting if the content is compressed using gzip and if we need to decode it\n     */\n    pipeResponseToFile(response, destinationStream, isGzip) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield new Promise((resolve, reject) => {\n                if (isGzip) {\n                    const gunzip = zlib.createGunzip();\n                    response.message\n                        .on('error', error => {\n                        core.error(`An error occurred while attempting to read the response stream`);\n                        gunzip.close();\n                        destinationStream.close();\n                        reject(error);\n                    })\n                        .pipe(gunzip)\n                        .on('error', error => {\n                        core.error(`An error occurred while attempting to decompress the response stream`);\n                        destinationStream.close();\n                        reject(error);\n                    })\n                        .pipe(destinationStream)\n                        .on('close', () => {\n                        resolve();\n                    })\n                        .on('error', error => {\n                        core.error(`An error occurred while writing a downloaded file to ${destinationStream.path}`);\n                        reject(error);\n                    });\n                }\n                else {\n                    response.message\n                        .on('error', error => {\n                        core.error(`An error occurred while attempting to read the response stream`);\n                        destinationStream.close();\n                        reject(error);\n                    })\n                        .pipe(destinationStream)\n                        .on('close', () => {\n                        resolve();\n                    })\n                        .on('error', error => {\n                        core.error(`An error occurred while writing a downloaded file to ${destinationStream.path}`);\n                        reject(error);\n                    });\n                }\n            });\n            return;\n        });\n    }\n}\nexports.DownloadHttpClient = DownloadHttpClient;\n//# sourceMappingURL=download-http-client.js.map","\"use strict\";\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst path = __importStar(require(\"path\"));\n/**\n * Creates a specification for a set of files that will be downloaded\n * @param artifactName the name of the artifact\n * @param artifactEntries a set of container entries that describe that files that make up an artifact\n * @param downloadPath the path where the artifact will be downloaded to\n * @param includeRootDirectory specifies if there should be an extra directory (denoted by the artifact name) where the artifact files should be downloaded to\n */\nfunction getDownloadSpecification(artifactName, artifactEntries, downloadPath, includeRootDirectory) {\n    // use a set for the directory paths so that there are no duplicates\n    const directories = new Set();\n    const specifications = {\n        rootDownloadLocation: includeRootDirectory\n            ? path.join(downloadPath, artifactName)\n            : downloadPath,\n        directoryStructure: [],\n        emptyFilesToCreate: [],\n        filesToDownload: []\n    };\n    for (const entry of artifactEntries) {\n        // Ignore artifacts in the container that don't begin with the same name\n        if (entry.path.startsWith(`${artifactName}/`) ||\n            entry.path.startsWith(`${artifactName}\\\\`)) {\n            // normalize all separators to the local OS\n            const normalizedPathEntry = path.normalize(entry.path);\n            // entry.path always starts with the artifact name, if includeRootDirectory is false, remove the name from the beginning of the path\n            const filePath = path.join(downloadPath, includeRootDirectory\n                ? normalizedPathEntry\n                : normalizedPathEntry.replace(artifactName, ''));\n            // Case insensitive folder structure maintained in the backend, not every folder is created so the 'folder'\n            // itemType cannot be relied upon. The file must be used to determine the directory structure\n            if (entry.itemType === 'file') {\n                // Get the directories that we need to create from the filePath for each individual file\n                directories.add(path.dirname(filePath));\n                if (entry.fileLength === 0) {\n                    // An empty file was uploaded, create the empty files locally so that no extra http calls are made\n                    specifications.emptyFilesToCreate.push(filePath);\n                }\n                else {\n                    specifications.filesToDownload.push({\n                        sourceLocation: entry.contentLocation,\n                        targetPath: filePath\n                    });\n                }\n            }\n        }\n    }\n    specifications.directoryStructure = Array.from(directories);\n    return specifications;\n}\nexports.getDownloadSpecification = getDownloadSpecification;\n//# sourceMappingURL=download-specification.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst utils_1 = require(\"./utils\");\n/**\n * Used for managing http clients during either upload or download\n */\nclass HttpManager {\n    constructor(clientCount, userAgent) {\n        if (clientCount < 1) {\n            throw new Error('There must be at least one client');\n        }\n        this.userAgent = userAgent;\n        this.clients = new Array(clientCount).fill(utils_1.createHttpClient(userAgent));\n    }\n    getClient(index) {\n        return this.clients[index];\n    }\n    // client disposal is necessary if a keep-alive connection is used to properly close the connection\n    // for more information see: https://github.com/actions/http-client/blob/04e5ad73cd3fd1f5610a32116b0759eddf6570d2/index.ts#L292\n    disposeAndReplaceClient(index) {\n        this.clients[index].dispose();\n        this.clients[index] = utils_1.createHttpClient(this.userAgent);\n    }\n    disposeAndReplaceAllClients() {\n        for (const [index] of this.clients.entries()) {\n            this.disposeAndReplaceClient(index);\n        }\n    }\n}\nexports.HttpManager = HttpManager;\n//# sourceMappingURL=http-manager.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst utils_1 = require(\"./utils\");\nconst core = __importStar(require(\"@actions/core\"));\nconst config_variables_1 = require(\"./config-variables\");\nfunction retry(name, operation, customErrorMessages, maxAttempts) {\n    return __awaiter(this, void 0, void 0, function* () {\n        let response = undefined;\n        let statusCode = undefined;\n        let isRetryable = false;\n        let errorMessage = '';\n        let customErrorInformation = undefined;\n        let attempt = 1;\n        while (attempt <= maxAttempts) {\n            try {\n                response = yield operation();\n                statusCode = response.message.statusCode;\n                if (utils_1.isSuccessStatusCode(statusCode)) {\n                    return response;\n                }\n                // Extra error information that we want to display if a particular response code is hit\n                if (statusCode) {\n                    customErrorInformation = customErrorMessages.get(statusCode);\n                }\n                isRetryable = utils_1.isRetryableStatusCode(statusCode);\n                errorMessage = `Artifact service responded with ${statusCode}`;\n            }\n            catch (error) {\n                isRetryable = true;\n                errorMessage = error.message;\n            }\n            if (!isRetryable) {\n                core.info(`${name} - Error is not retryable`);\n                if (response) {\n                    utils_1.displayHttpDiagnostics(response);\n                }\n                break;\n            }\n            core.info(`${name} - Attempt ${attempt} of ${maxAttempts} failed with error: ${errorMessage}`);\n            yield utils_1.sleep(utils_1.getExponentialRetryTimeInMilliseconds(attempt));\n            attempt++;\n        }\n        if (response) {\n            utils_1.displayHttpDiagnostics(response);\n        }\n        if (customErrorInformation) {\n            throw Error(`${name} failed: ${customErrorInformation}`);\n        }\n        throw Error(`${name} failed: ${errorMessage}`);\n    });\n}\nexports.retry = retry;\nfunction retryHttpClientRequest(name, method, customErrorMessages = new Map(), maxAttempts = config_variables_1.getRetryLimit()) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return yield retry(name, method, customErrorMessages, maxAttempts);\n    });\n}\nexports.retryHttpClientRequest = retryHttpClientRequest;\n//# sourceMappingURL=requestUtils.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst core_1 = require(\"@actions/core\");\n/**\n * Status Reporter that displays information about the progress/status of an artifact that is being uploaded or downloaded\n *\n * Variable display time that can be adjusted using the displayFrequencyInMilliseconds variable\n * The total status of the upload/download gets displayed according to this value\n * If there is a large file that is being uploaded, extra information about the individual status can also be displayed using the updateLargeFileStatus function\n */\nclass StatusReporter {\n    constructor(displayFrequencyInMilliseconds) {\n        this.totalNumberOfFilesToProcess = 0;\n        this.processedCount = 0;\n        this.largeFiles = new Map();\n        this.totalFileStatus = undefined;\n        this.largeFileStatus = undefined;\n        this.displayFrequencyInMilliseconds = displayFrequencyInMilliseconds;\n    }\n    setTotalNumberOfFilesToProcess(fileTotal) {\n        this.totalNumberOfFilesToProcess = fileTotal;\n    }\n    start() {\n        // displays information about the total upload/download status\n        this.totalFileStatus = setInterval(() => {\n            // display 1 decimal place without any rounding\n            const percentage = this.formatPercentage(this.processedCount, this.totalNumberOfFilesToProcess);\n            core_1.info(`Total file count: ${this.totalNumberOfFilesToProcess} ---- Processed file #${this.processedCount} (${percentage.slice(0, percentage.indexOf('.') + 2)}%)`);\n        }, this.displayFrequencyInMilliseconds);\n        // displays extra information about any large files that take a significant amount of time to upload or download every 1 second\n        this.largeFileStatus = setInterval(() => {\n            for (const value of Array.from(this.largeFiles.values())) {\n                core_1.info(value);\n            }\n            // delete all entries in the map after displaying the information so it will not be displayed again unless explicitly added\n            this.largeFiles.clear();\n        }, 1000);\n    }\n    // if there is a large file that is being uploaded in chunks, this is used to display extra information about the status of the upload\n    updateLargeFileStatus(fileName, numerator, denominator) {\n        // display 1 decimal place without any rounding\n        const percentage = this.formatPercentage(numerator, denominator);\n        const displayInformation = `Uploading ${fileName} (${percentage.slice(0, percentage.indexOf('.') + 2)}%)`;\n        // any previously added display information should be overwritten for the specific large file because a map is being used\n        this.largeFiles.set(fileName, displayInformation);\n    }\n    stop() {\n        if (this.totalFileStatus) {\n            clearInterval(this.totalFileStatus);\n        }\n        if (this.largeFileStatus) {\n            clearInterval(this.largeFileStatus);\n        }\n    }\n    incrementProcessedCount() {\n        this.processedCount++;\n    }\n    formatPercentage(numerator, denominator) {\n        // toFixed() rounds, so use extra precision to display accurate information even though 4 decimal places are not displayed\n        return ((numerator / denominator) * 100).toFixed(4).toString();\n    }\n}\nexports.StatusReporter = StatusReporter;\n//# sourceMappingURL=status-reporter.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __asyncValues = (this && this.__asyncValues) || function (o) {\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n    var m = o[Symbol.asyncIterator], i;\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\n};\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst fs = __importStar(require(\"fs\"));\nconst zlib = __importStar(require(\"zlib\"));\nconst util_1 = require(\"util\");\nconst stat = util_1.promisify(fs.stat);\n/**\n * Creates a Gzip compressed file of an original file at the provided temporary filepath location\n * @param {string} originalFilePath filepath of whatever will be compressed. The original file will be unmodified\n * @param {string} tempFilePath the location of where the Gzip file will be created\n * @returns the size of gzip file that gets created\n */\nfunction createGZipFileOnDisk(originalFilePath, tempFilePath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return new Promise((resolve, reject) => {\n            const inputStream = fs.createReadStream(originalFilePath);\n            const gzip = zlib.createGzip();\n            const outputStream = fs.createWriteStream(tempFilePath);\n            inputStream.pipe(gzip).pipe(outputStream);\n            outputStream.on('finish', () => __awaiter(this, void 0, void 0, function* () {\n                // wait for stream to finish before calculating the size which is needed as part of the Content-Length header when starting an upload\n                const size = (yield stat(tempFilePath)).size;\n                resolve(size);\n            }));\n            outputStream.on('error', error => {\n                // eslint-disable-next-line no-console\n                console.log(error);\n                reject;\n            });\n        });\n    });\n}\nexports.createGZipFileOnDisk = createGZipFileOnDisk;\n/**\n * Creates a GZip file in memory using a buffer. Should be used for smaller files to reduce disk I/O\n * @param originalFilePath the path to the original file that is being GZipped\n * @returns a buffer with the GZip file\n */\nfunction createGZipFileInBuffer(originalFilePath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {\n            var e_1, _a;\n            const inputStream = fs.createReadStream(originalFilePath);\n            const gzip = zlib.createGzip();\n            inputStream.pipe(gzip);\n            // read stream into buffer, using experimental async iterators see https://github.com/nodejs/readable-stream/issues/403#issuecomment-479069043\n            const chunks = [];\n            try {\n                for (var gzip_1 = __asyncValues(gzip), gzip_1_1; gzip_1_1 = yield gzip_1.next(), !gzip_1_1.done;) {\n                    const chunk = gzip_1_1.value;\n                    chunks.push(chunk);\n                }\n            }\n            catch (e_1_1) { e_1 = { error: e_1_1 }; }\n            finally {\n                try {\n                    if (gzip_1_1 && !gzip_1_1.done && (_a = gzip_1.return)) yield _a.call(gzip_1);\n                }\n                finally { if (e_1) throw e_1.error; }\n            }\n            resolve(Buffer.concat(chunks));\n        }));\n    });\n}\nexports.createGZipFileInBuffer = createGZipFileInBuffer;\n//# sourceMappingURL=upload-gzip.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst fs = __importStar(require(\"fs\"));\nconst core = __importStar(require(\"@actions/core\"));\nconst tmp = __importStar(require(\"tmp-promise\"));\nconst stream = __importStar(require(\"stream\"));\nconst utils_1 = require(\"./utils\");\nconst config_variables_1 = require(\"./config-variables\");\nconst util_1 = require(\"util\");\nconst url_1 = require(\"url\");\nconst perf_hooks_1 = require(\"perf_hooks\");\nconst status_reporter_1 = require(\"./status-reporter\");\nconst http_client_1 = require(\"@actions/http-client\");\nconst http_manager_1 = require(\"./http-manager\");\nconst upload_gzip_1 = require(\"./upload-gzip\");\nconst requestUtils_1 = require(\"./requestUtils\");\nconst stat = util_1.promisify(fs.stat);\nclass UploadHttpClient {\n    constructor() {\n        this.uploadHttpManager = new http_manager_1.HttpManager(config_variables_1.getUploadFileConcurrency(), '@actions/artifact-upload');\n        this.statusReporter = new status_reporter_1.StatusReporter(10000);\n    }\n    /**\n     * Creates a file container for the new artifact in the remote blob storage/file service\n     * @param {string} artifactName Name of the artifact being created\n     * @returns The response from the Artifact Service if the file container was successfully created\n     */\n    createArtifactInFileContainer(artifactName, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const parameters = {\n                Type: 'actions_storage',\n                Name: artifactName\n            };\n            // calculate retention period\n            if (options && options.retentionDays) {\n                const maxRetentionStr = config_variables_1.getRetentionDays();\n                parameters.RetentionDays = utils_1.getProperRetention(options.retentionDays, maxRetentionStr);\n            }\n            const data = JSON.stringify(parameters, null, 2);\n            const artifactUrl = utils_1.getArtifactUrl();\n            // use the first client from the httpManager, `keep-alive` is not used so the connection will close immediately\n            const client = this.uploadHttpManager.getClient(0);\n            const headers = utils_1.getUploadHeaders('application/json', false);\n            // Extra information to display when a particular HTTP code is returned\n            // If a 403 is returned when trying to create a file container, the customer has exceeded\n            // their storage quota so no new artifact containers can be created\n            const customErrorMessages = new Map([\n                [\n                    http_client_1.HttpCodes.Forbidden,\n                    'Artifact storage quota has been hit. Unable to upload any new artifacts'\n                ],\n                [\n                    http_client_1.HttpCodes.BadRequest,\n                    `The artifact name ${artifactName} is not valid. Request URL ${artifactUrl}`\n                ]\n            ]);\n            const response = yield requestUtils_1.retryHttpClientRequest('Create Artifact Container', () => __awaiter(this, void 0, void 0, function* () { return client.post(artifactUrl, data, headers); }), customErrorMessages);\n            const body = yield response.readBody();\n            return JSON.parse(body);\n        });\n    }\n    /**\n     * Concurrently upload all of the files in chunks\n     * @param {string} uploadUrl Base Url for the artifact that was created\n     * @param {SearchResult[]} filesToUpload A list of information about the files being uploaded\n     * @returns The size of all the files uploaded in bytes\n     */\n    uploadArtifactToFileContainer(uploadUrl, filesToUpload, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const FILE_CONCURRENCY = config_variables_1.getUploadFileConcurrency();\n            const MAX_CHUNK_SIZE = config_variables_1.getUploadChunkSize();\n            core.debug(`File Concurrency: ${FILE_CONCURRENCY}, and Chunk Size: ${MAX_CHUNK_SIZE}`);\n            const parameters = [];\n            // by default, file uploads will continue if there is an error unless specified differently in the options\n            let continueOnError = true;\n            if (options) {\n                if (options.continueOnError === false) {\n                    continueOnError = false;\n                }\n            }\n            // prepare the necessary parameters to upload all the files\n            for (const file of filesToUpload) {\n                const resourceUrl = new url_1.URL(uploadUrl);\n                resourceUrl.searchParams.append('itemPath', file.uploadFilePath);\n                parameters.push({\n                    file: file.absoluteFilePath,\n                    resourceUrl: resourceUrl.toString(),\n                    maxChunkSize: MAX_CHUNK_SIZE,\n                    continueOnError\n                });\n            }\n            const parallelUploads = [...new Array(FILE_CONCURRENCY).keys()];\n            const failedItemsToReport = [];\n            let currentFile = 0;\n            let completedFiles = 0;\n            let uploadFileSize = 0;\n            let totalFileSize = 0;\n            let abortPendingFileUploads = false;\n            this.statusReporter.setTotalNumberOfFilesToProcess(filesToUpload.length);\n            this.statusReporter.start();\n            // only allow a certain amount of files to be uploaded at once, this is done to reduce potential errors\n            yield Promise.all(parallelUploads.map((index) => __awaiter(this, void 0, void 0, function* () {\n                while (currentFile < filesToUpload.length) {\n                    const currentFileParameters = parameters[currentFile];\n                    currentFile += 1;\n                    if (abortPendingFileUploads) {\n                        failedItemsToReport.push(currentFileParameters.file);\n                        continue;\n                    }\n                    const startTime = perf_hooks_1.performance.now();\n                    const uploadFileResult = yield this.uploadFileAsync(index, currentFileParameters);\n                    if (core.isDebug()) {\n                        core.debug(`File: ${++completedFiles}/${filesToUpload.length}. ${currentFileParameters.file} took ${(perf_hooks_1.performance.now() - startTime).toFixed(3)} milliseconds to finish upload`);\n                    }\n                    uploadFileSize += uploadFileResult.successfulUploadSize;\n                    totalFileSize += uploadFileResult.totalSize;\n                    if (uploadFileResult.isSuccess === false) {\n                        failedItemsToReport.push(currentFileParameters.file);\n                        if (!continueOnError) {\n                            // fail fast\n                            core.error(`aborting artifact upload`);\n                            abortPendingFileUploads = true;\n                        }\n                    }\n                    this.statusReporter.incrementProcessedCount();\n                }\n            })));\n            this.statusReporter.stop();\n            // done uploading, safety dispose all connections\n            this.uploadHttpManager.disposeAndReplaceAllClients();\n            core.info(`Total size of all the files uploaded is ${uploadFileSize} bytes`);\n            return {\n                uploadSize: uploadFileSize,\n                totalSize: totalFileSize,\n                failedItems: failedItemsToReport\n            };\n        });\n    }\n    /**\n     * Asynchronously uploads a file. The file is compressed and uploaded using GZip if it is determined to save space.\n     * If the upload file is bigger than the max chunk size it will be uploaded via multiple calls\n     * @param {number} httpClientIndex The index of the httpClient that is being used to make all of the calls\n     * @param {UploadFileParameters} parameters Information about the file that needs to be uploaded\n     * @returns The size of the file that was uploaded in bytes along with any failed uploads\n     */\n    uploadFileAsync(httpClientIndex, parameters) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const totalFileSize = (yield stat(parameters.file)).size;\n            let offset = 0;\n            let isUploadSuccessful = true;\n            let failedChunkSizes = 0;\n            let uploadFileSize = 0;\n            let isGzip = true;\n            // the file that is being uploaded is less than 64k in size, to increase throughput and to minimize disk I/O\n            // for creating a new GZip file, an in-memory buffer is used for compression\n            if (totalFileSize < 65536) {\n                const buffer = yield upload_gzip_1.createGZipFileInBuffer(parameters.file);\n                //An open stream is needed in the event of a failure and we need to retry. If a NodeJS.ReadableStream is directly passed in,\n                // it will not properly get reset to the start of the stream if a chunk upload needs to be retried\n                let openUploadStream;\n                if (totalFileSize < buffer.byteLength) {\n                    // compression did not help with reducing the size, use a readable stream from the original file for upload\n                    openUploadStream = () => fs.createReadStream(parameters.file);\n                    isGzip = false;\n                    uploadFileSize = totalFileSize;\n                }\n                else {\n                    // create a readable stream using a PassThrough stream that is both readable and writable\n                    openUploadStream = () => {\n                        const passThrough = new stream.PassThrough();\n                        passThrough.end(buffer);\n                        return passThrough;\n                    };\n                    uploadFileSize = buffer.byteLength;\n                }\n                const result = yield this.uploadChunk(httpClientIndex, parameters.resourceUrl, openUploadStream, 0, uploadFileSize - 1, uploadFileSize, isGzip, totalFileSize);\n                if (!result) {\n                    // chunk failed to upload\n                    isUploadSuccessful = false;\n                    failedChunkSizes += uploadFileSize;\n                    core.warning(`Aborting upload for ${parameters.file} due to failure`);\n                }\n                return {\n                    isSuccess: isUploadSuccessful,\n                    successfulUploadSize: uploadFileSize - failedChunkSizes,\n                    totalSize: totalFileSize\n                };\n            }\n            else {\n                // the file that is being uploaded is greater than 64k in size, a temporary file gets created on disk using the\n                // npm tmp-promise package and this file gets used to create a GZipped file\n                const tempFile = yield tmp.file();\n                // create a GZip file of the original file being uploaded, the original file should not be modified in any way\n                uploadFileSize = yield upload_gzip_1.createGZipFileOnDisk(parameters.file, tempFile.path);\n                let uploadFilePath = tempFile.path;\n                // compression did not help with size reduction, use the original file for upload and delete the temp GZip file\n                if (totalFileSize < uploadFileSize) {\n                    uploadFileSize = totalFileSize;\n                    uploadFilePath = parameters.file;\n                    isGzip = false;\n                }\n                let abortFileUpload = false;\n                // upload only a single chunk at a time\n                while (offset < uploadFileSize) {\n                    const chunkSize = Math.min(uploadFileSize - offset, parameters.maxChunkSize);\n                    // if an individual file is greater than 100MB (1024*1024*100) in size, display extra information about the upload status\n                    if (uploadFileSize > 104857600) {\n                        this.statusReporter.updateLargeFileStatus(parameters.file, offset, uploadFileSize);\n                    }\n                    const start = offset;\n                    const end = offset + chunkSize - 1;\n                    offset += parameters.maxChunkSize;\n                    if (abortFileUpload) {\n                        // if we don't want to continue in the event of an error, any pending upload chunks will be marked as failed\n                        failedChunkSizes += chunkSize;\n                        continue;\n                    }\n                    const result = yield this.uploadChunk(httpClientIndex, parameters.resourceUrl, () => fs.createReadStream(uploadFilePath, {\n                        start,\n                        end,\n                        autoClose: false\n                    }), start, end, uploadFileSize, isGzip, totalFileSize);\n                    if (!result) {\n                        // Chunk failed to upload, report as failed and do not continue uploading any more chunks for the file. It is possible that part of a chunk was\n                        // successfully uploaded so the server may report a different size for what was uploaded\n                        isUploadSuccessful = false;\n                        failedChunkSizes += chunkSize;\n                        core.warning(`Aborting upload for ${parameters.file} due to failure`);\n                        abortFileUpload = true;\n                    }\n                }\n                // Delete the temporary file that was created as part of the upload. If the temp file does not get manually deleted by\n                // calling cleanup, it gets removed when the node process exits. For more info see: https://www.npmjs.com/package/tmp-promise#about\n                yield tempFile.cleanup();\n                return {\n                    isSuccess: isUploadSuccessful,\n                    successfulUploadSize: uploadFileSize - failedChunkSizes,\n                    totalSize: totalFileSize\n                };\n            }\n        });\n    }\n    /**\n     * Uploads a chunk of an individual file to the specified resourceUrl. If the upload fails and the status code\n     * indicates a retryable status, we try to upload the chunk as well\n     * @param {number} httpClientIndex The index of the httpClient being used to make all the necessary calls\n     * @param {string} resourceUrl Url of the resource that the chunk will be uploaded to\n     * @param {NodeJS.ReadableStream} openStream Stream of the file that will be uploaded\n     * @param {number} start Starting byte index of file that the chunk belongs to\n     * @param {number} end Ending byte index of file that the chunk belongs to\n     * @param {number} uploadFileSize Total size of the file in bytes that is being uploaded\n     * @param {boolean} isGzip Denotes if we are uploading a Gzip compressed stream\n     * @param {number} totalFileSize Original total size of the file that is being uploaded\n     * @returns if the chunk was successfully uploaded\n     */\n    uploadChunk(httpClientIndex, resourceUrl, openStream, start, end, uploadFileSize, isGzip, totalFileSize) {\n        return __awaiter(this, void 0, void 0, function* () {\n            // prepare all the necessary headers before making any http call\n            const headers = utils_1.getUploadHeaders('application/octet-stream', true, isGzip, totalFileSize, end - start + 1, utils_1.getContentRange(start, end, uploadFileSize));\n            const uploadChunkRequest = () => __awaiter(this, void 0, void 0, function* () {\n                const client = this.uploadHttpManager.getClient(httpClientIndex);\n                return yield client.sendStream('PUT', resourceUrl, openStream(), headers);\n            });\n            let retryCount = 0;\n            const retryLimit = config_variables_1.getRetryLimit();\n            // Increments the current retry count and then checks if the retry limit has been reached\n            // If there have been too many retries, fail so the download stops\n            const incrementAndCheckRetryLimit = (response) => {\n                retryCount++;\n                if (retryCount > retryLimit) {\n                    if (response) {\n                        utils_1.displayHttpDiagnostics(response);\n                    }\n                    core.info(`Retry limit has been reached for chunk at offset ${start} to ${resourceUrl}`);\n                    return true;\n                }\n                return false;\n            };\n            const backOff = (retryAfterValue) => __awaiter(this, void 0, void 0, function* () {\n                this.uploadHttpManager.disposeAndReplaceClient(httpClientIndex);\n                if (retryAfterValue) {\n                    core.info(`Backoff due to too many requests, retry #${retryCount}. Waiting for ${retryAfterValue} milliseconds before continuing the upload`);\n                    yield utils_1.sleep(retryAfterValue);\n                }\n                else {\n                    const backoffTime = utils_1.getExponentialRetryTimeInMilliseconds(retryCount);\n                    core.info(`Exponential backoff for retry #${retryCount}. Waiting for ${backoffTime} milliseconds before continuing the upload at offset ${start}`);\n                    yield utils_1.sleep(backoffTime);\n                }\n                core.info(`Finished backoff for retry #${retryCount}, continuing with upload`);\n                return;\n            });\n            // allow for failed chunks to be retried multiple times\n            while (retryCount <= retryLimit) {\n                let response;\n                try {\n                    response = yield uploadChunkRequest();\n                }\n                catch (error) {\n                    // if an error is caught, it is usually indicative of a timeout so retry the upload\n                    core.info(`An error has been caught http-client index ${httpClientIndex}, retrying the upload`);\n                    // eslint-disable-next-line no-console\n                    console.log(error);\n                    if (incrementAndCheckRetryLimit()) {\n                        return false;\n                    }\n                    yield backOff();\n                    continue;\n                }\n                // Always read the body of the response. There is potential for a resource leak if the body is not read which will\n                // result in the connection remaining open along with unintended consequences when trying to dispose of the client\n                yield response.readBody();\n                if (utils_1.isSuccessStatusCode(response.message.statusCode)) {\n                    return true;\n                }\n                else if (utils_1.isRetryableStatusCode(response.message.statusCode)) {\n                    core.info(`A ${response.message.statusCode} status code has been received, will attempt to retry the upload`);\n                    if (incrementAndCheckRetryLimit(response)) {\n                        return false;\n                    }\n                    utils_1.isThrottledStatusCode(response.message.statusCode)\n                        ? yield backOff(utils_1.tryGetRetryAfterValueTimeInMilliseconds(response.message.headers))\n                        : yield backOff();\n                }\n                else {\n                    core.error(`Unexpected response. Unable to upload chunk to ${resourceUrl}`);\n                    utils_1.displayHttpDiagnostics(response);\n                    return false;\n                }\n            }\n            return false;\n        });\n    }\n    /**\n     * Updates the size of the artifact from -1 which was initially set when the container was first created for the artifact.\n     * Updating the size indicates that we are done uploading all the contents of the artifact\n     */\n    patchArtifactSize(size, artifactName) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const resourceUrl = new url_1.URL(utils_1.getArtifactUrl());\n            resourceUrl.searchParams.append('artifactName', artifactName);\n            const parameters = { Size: size };\n            const data = JSON.stringify(parameters, null, 2);\n            core.debug(`URL is ${resourceUrl.toString()}`);\n            // use the first client from the httpManager, `keep-alive` is not used so the connection will close immediately\n            const client = this.uploadHttpManager.getClient(0);\n            const headers = utils_1.getUploadHeaders('application/json', false);\n            // Extra information to display when a particular HTTP code is returned\n            const customErrorMessages = new Map([\n                [\n                    http_client_1.HttpCodes.NotFound,\n                    `An Artifact with the name ${artifactName} was not found`\n                ]\n            ]);\n            // TODO retry for all possible response codes, the artifact upload is pretty much complete so it at all costs we should try to finish this\n            const response = yield requestUtils_1.retryHttpClientRequest('Finalize artifact upload', () => __awaiter(this, void 0, void 0, function* () { return client.patch(resourceUrl.toString(), data, headers); }), customErrorMessages);\n            yield response.readBody();\n            core.debug(`Artifact ${artifactName} has been successfully uploaded, total size in bytes: ${size}`);\n        });\n    }\n}\nexports.UploadHttpClient = UploadHttpClient;\n//# sourceMappingURL=upload-http-client.js.map","\"use strict\";\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst fs = __importStar(require(\"fs\"));\nconst core_1 = require(\"@actions/core\");\nconst path_1 = require(\"path\");\nconst utils_1 = require(\"./utils\");\n/**\n * Creates a specification that describes how each file that is part of the artifact will be uploaded\n * @param artifactName the name of the artifact being uploaded. Used during upload to denote where the artifact is stored on the server\n * @param rootDirectory an absolute file path that denotes the path that should be removed from the beginning of each artifact file\n * @param artifactFiles a list of absolute file paths that denote what should be uploaded as part of the artifact\n */\nfunction getUploadSpecification(artifactName, rootDirectory, artifactFiles) {\n    utils_1.checkArtifactName(artifactName);\n    const specifications = [];\n    if (!fs.existsSync(rootDirectory)) {\n        throw new Error(`Provided rootDirectory ${rootDirectory} does not exist`);\n    }\n    if (!fs.lstatSync(rootDirectory).isDirectory()) {\n        throw new Error(`Provided rootDirectory ${rootDirectory} is not a valid directory`);\n    }\n    // Normalize and resolve, this allows for either absolute or relative paths to be used\n    rootDirectory = path_1.normalize(rootDirectory);\n    rootDirectory = path_1.resolve(rootDirectory);\n    /*\n       Example to demonstrate behavior\n       \n       Input:\n         artifactName: my-artifact\n         rootDirectory: '/home/user/files/plz-upload'\n         artifactFiles: [\n           '/home/user/files/plz-upload/file1.txt',\n           '/home/user/files/plz-upload/file2.txt',\n           '/home/user/files/plz-upload/dir/file3.txt'\n         ]\n       \n       Output:\n         specifications: [\n           ['/home/user/files/plz-upload/file1.txt', 'my-artifact/file1.txt'],\n           ['/home/user/files/plz-upload/file1.txt', 'my-artifact/file2.txt'],\n           ['/home/user/files/plz-upload/file1.txt', 'my-artifact/dir/file3.txt']\n         ]\n    */\n    for (let file of artifactFiles) {\n        if (!fs.existsSync(file)) {\n            throw new Error(`File ${file} does not exist`);\n        }\n        if (!fs.lstatSync(file).isDirectory()) {\n            // Normalize and resolve, this allows for either absolute or relative paths to be used\n            file = path_1.normalize(file);\n            file = path_1.resolve(file);\n            if (!file.startsWith(rootDirectory)) {\n                throw new Error(`The rootDirectory: ${rootDirectory} is not a parent directory of the file: ${file}`);\n            }\n            // Check for forbidden characters in file paths that will be rejected during upload\n            const uploadPath = file.replace(rootDirectory, '');\n            utils_1.checkArtifactFilePath(uploadPath);\n            /*\n              uploadFilePath denotes where the file will be uploaded in the file container on the server. During a run, if multiple artifacts are uploaded, they will all\n              be saved in the same container. The artifact name is used as the root directory in the container to separate and distinguish uploaded artifacts\n      \n              path.join handles all the following cases and would return 'artifact-name/file-to-upload.txt\n                join('artifact-name/', 'file-to-upload.txt')\n                join('artifact-name/', '/file-to-upload.txt')\n                join('artifact-name', 'file-to-upload.txt')\n                join('artifact-name', '/file-to-upload.txt')\n            */\n            specifications.push({\n                absoluteFilePath: file,\n                uploadFilePath: path_1.join(artifactName, uploadPath)\n            });\n        }\n        else {\n            // Directories are rejected by the server during upload\n            core_1.debug(`Removing ${file} from rawSearchResults because it is a directory`);\n        }\n    }\n    return specifications;\n}\nexports.getUploadSpecification = getUploadSpecification;\n//# sourceMappingURL=upload-specification.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst core_1 = require(\"@actions/core\");\nconst fs_1 = require(\"fs\");\nconst http_client_1 = require(\"@actions/http-client\");\nconst auth_1 = require(\"@actions/http-client/auth\");\nconst config_variables_1 = require(\"./config-variables\");\n/**\n * Returns a retry time in milliseconds that exponentially gets larger\n * depending on the amount of retries that have been attempted\n */\nfunction getExponentialRetryTimeInMilliseconds(retryCount) {\n    if (retryCount < 0) {\n        throw new Error('RetryCount should not be negative');\n    }\n    else if (retryCount === 0) {\n        return config_variables_1.getInitialRetryIntervalInMilliseconds();\n    }\n    const minTime = config_variables_1.getInitialRetryIntervalInMilliseconds() * config_variables_1.getRetryMultiplier() * retryCount;\n    const maxTime = minTime * config_variables_1.getRetryMultiplier();\n    // returns a random number between the minTime (inclusive) and the maxTime (exclusive)\n    return Math.random() * (maxTime - minTime) + minTime;\n}\nexports.getExponentialRetryTimeInMilliseconds = getExponentialRetryTimeInMilliseconds;\n/**\n * Parses a env variable that is a number\n */\nfunction parseEnvNumber(key) {\n    const value = Number(process.env[key]);\n    if (Number.isNaN(value) || value < 0) {\n        return undefined;\n    }\n    return value;\n}\nexports.parseEnvNumber = parseEnvNumber;\n/**\n * Various utility functions to help with the necessary API calls\n */\nfunction getApiVersion() {\n    return '6.0-preview';\n}\nexports.getApiVersion = getApiVersion;\nfunction isSuccessStatusCode(statusCode) {\n    if (!statusCode) {\n        return false;\n    }\n    return statusCode >= 200 && statusCode < 300;\n}\nexports.isSuccessStatusCode = isSuccessStatusCode;\nfunction isForbiddenStatusCode(statusCode) {\n    if (!statusCode) {\n        return false;\n    }\n    return statusCode === http_client_1.HttpCodes.Forbidden;\n}\nexports.isForbiddenStatusCode = isForbiddenStatusCode;\nfunction isRetryableStatusCode(statusCode) {\n    if (!statusCode) {\n        return false;\n    }\n    const retryableStatusCodes = [\n        http_client_1.HttpCodes.BadGateway,\n        http_client_1.HttpCodes.GatewayTimeout,\n        http_client_1.HttpCodes.InternalServerError,\n        http_client_1.HttpCodes.ServiceUnavailable,\n        http_client_1.HttpCodes.TooManyRequests,\n        413 // Payload Too Large\n    ];\n    return retryableStatusCodes.includes(statusCode);\n}\nexports.isRetryableStatusCode = isRetryableStatusCode;\nfunction isThrottledStatusCode(statusCode) {\n    if (!statusCode) {\n        return false;\n    }\n    return statusCode === http_client_1.HttpCodes.TooManyRequests;\n}\nexports.isThrottledStatusCode = isThrottledStatusCode;\n/**\n * Attempts to get the retry-after value from a set of http headers. The retry time\n * is originally denoted in seconds, so if present, it is converted to milliseconds\n * @param headers all the headers received when making an http call\n */\nfunction tryGetRetryAfterValueTimeInMilliseconds(headers) {\n    if (headers['retry-after']) {\n        const retryTime = Number(headers['retry-after']);\n        if (!isNaN(retryTime)) {\n            core_1.info(`Retry-After header is present with a value of ${retryTime}`);\n            return retryTime * 1000;\n        }\n        core_1.info(`Returned retry-after header value: ${retryTime} is non-numeric and cannot be used`);\n        return undefined;\n    }\n    core_1.info(`No retry-after header was found. Dumping all headers for diagnostic purposes`);\n    // eslint-disable-next-line no-console\n    console.log(headers);\n    return undefined;\n}\nexports.tryGetRetryAfterValueTimeInMilliseconds = tryGetRetryAfterValueTimeInMilliseconds;\nfunction getContentRange(start, end, total) {\n    // Format: `bytes start-end/fileSize\n    // start and end are inclusive\n    // For a 200 byte chunk starting at byte 0:\n    // Content-Range: bytes 0-199/200\n    return `bytes ${start}-${end}/${total}`;\n}\nexports.getContentRange = getContentRange;\n/**\n * Sets all the necessary headers when downloading an artifact\n * @param {string} contentType the type of content being uploaded\n * @param {boolean} isKeepAlive is the same connection being used to make multiple calls\n * @param {boolean} acceptGzip can we accept a gzip encoded response\n * @param {string} acceptType the type of content that we can accept\n * @returns appropriate headers to make a specific http call during artifact download\n */\nfunction getDownloadHeaders(contentType, isKeepAlive, acceptGzip) {\n    const requestOptions = {};\n    if (contentType) {\n        requestOptions['Content-Type'] = contentType;\n    }\n    if (isKeepAlive) {\n        requestOptions['Connection'] = 'Keep-Alive';\n        // keep alive for at least 10 seconds before closing the connection\n        requestOptions['Keep-Alive'] = '10';\n    }\n    if (acceptGzip) {\n        // if we are expecting a response with gzip encoding, it should be using an octet-stream in the accept header\n        requestOptions['Accept-Encoding'] = 'gzip';\n        requestOptions['Accept'] = `application/octet-stream;api-version=${getApiVersion()}`;\n    }\n    else {\n        // default to application/json if we are not working with gzip content\n        requestOptions['Accept'] = `application/json;api-version=${getApiVersion()}`;\n    }\n    return requestOptions;\n}\nexports.getDownloadHeaders = getDownloadHeaders;\n/**\n * Sets all the necessary headers when uploading an artifact\n * @param {string} contentType the type of content being uploaded\n * @param {boolean} isKeepAlive is the same connection being used to make multiple calls\n * @param {boolean} isGzip is the connection being used to upload GZip compressed content\n * @param {number} uncompressedLength the original size of the content if something is being uploaded that has been compressed\n * @param {number} contentLength the length of the content that is being uploaded\n * @param {string} contentRange the range of the content that is being uploaded\n * @returns appropriate headers to make a specific http call during artifact upload\n */\nfunction getUploadHeaders(contentType, isKeepAlive, isGzip, uncompressedLength, contentLength, contentRange) {\n    const requestOptions = {};\n    requestOptions['Accept'] = `application/json;api-version=${getApiVersion()}`;\n    if (contentType) {\n        requestOptions['Content-Type'] = contentType;\n    }\n    if (isKeepAlive) {\n        requestOptions['Connection'] = 'Keep-Alive';\n        // keep alive for at least 10 seconds before closing the connection\n        requestOptions['Keep-Alive'] = '10';\n    }\n    if (isGzip) {\n        requestOptions['Content-Encoding'] = 'gzip';\n        requestOptions['x-tfs-filelength'] = uncompressedLength;\n    }\n    if (contentLength) {\n        requestOptions['Content-Length'] = contentLength;\n    }\n    if (contentRange) {\n        requestOptions['Content-Range'] = contentRange;\n    }\n    return requestOptions;\n}\nexports.getUploadHeaders = getUploadHeaders;\nfunction createHttpClient(userAgent) {\n    return new http_client_1.HttpClient(userAgent, [\n        new auth_1.BearerCredentialHandler(config_variables_1.getRuntimeToken())\n    ]);\n}\nexports.createHttpClient = createHttpClient;\nfunction getArtifactUrl() {\n    const artifactUrl = `${config_variables_1.getRuntimeUrl()}_apis/pipelines/workflows/${config_variables_1.getWorkFlowRunId()}/artifacts?api-version=${getApiVersion()}`;\n    core_1.debug(`Artifact Url: ${artifactUrl}`);\n    return artifactUrl;\n}\nexports.getArtifactUrl = getArtifactUrl;\n/**\n * Uh oh! Something might have gone wrong during either upload or download. The IHtttpClientResponse object contains information\n * about the http call that was made by the actions http client. This information might be useful to display for diagnostic purposes, but\n * this entire object is really big and most of the information is not really useful. This function takes the response object and displays only\n * the information that we want.\n *\n * Certain information such as the TLSSocket and the Readable state are not really useful for diagnostic purposes so they can be avoided.\n * Other information such as the headers, the response code and message might be useful, so this is displayed.\n */\nfunction displayHttpDiagnostics(response) {\n    core_1.info(`##### Begin Diagnostic HTTP information #####\nStatus Code: ${response.message.statusCode}\nStatus Message: ${response.message.statusMessage}\nHeader Information: ${JSON.stringify(response.message.headers, undefined, 2)}\n###### End Diagnostic HTTP information ######`);\n}\nexports.displayHttpDiagnostics = displayHttpDiagnostics;\n/**\n * Invalid characters that cannot be in the artifact name or an uploaded file. Will be rejected\n * from the server if attempted to be sent over. These characters are not allowed due to limitations with certain\n * file systems such as NTFS. To maintain platform-agnostic behavior, all characters that are not supported by an\n * individual filesystem/platform will not be supported on all fileSystems/platforms\n *\n * FilePaths can include characters such as \\ and / which are not permitted in the artifact name alone\n */\nconst invalidArtifactFilePathCharacters = ['\"', ':', '<', '>', '|', '*', '?'];\nconst invalidArtifactNameCharacters = [\n    ...invalidArtifactFilePathCharacters,\n    '\\\\',\n    '/'\n];\n/**\n * Scans the name of the artifact to make sure there are no illegal characters\n */\nfunction checkArtifactName(name) {\n    if (!name) {\n        throw new Error(`Artifact name: ${name}, is incorrectly provided`);\n    }\n    for (const invalidChar of invalidArtifactNameCharacters) {\n        if (name.includes(invalidChar)) {\n            throw new Error(`Artifact name is not valid: ${name}. Contains character: \"${invalidChar}\". Invalid artifact name characters include: ${invalidArtifactNameCharacters.toString()}.`);\n        }\n    }\n}\nexports.checkArtifactName = checkArtifactName;\n/**\n * Scans the name of the filePath used to make sure there are no illegal characters\n */\nfunction checkArtifactFilePath(path) {\n    if (!path) {\n        throw new Error(`Artifact path: ${path}, is incorrectly provided`);\n    }\n    for (const invalidChar of invalidArtifactFilePathCharacters) {\n        if (path.includes(invalidChar)) {\n            throw new Error(`Artifact path is not valid: ${path}. Contains character: \"${invalidChar}\". Invalid characters include: ${invalidArtifactFilePathCharacters.toString()}.`);\n        }\n    }\n}\nexports.checkArtifactFilePath = checkArtifactFilePath;\nfunction createDirectoriesForArtifact(directories) {\n    return __awaiter(this, void 0, void 0, function* () {\n        for (const directory of directories) {\n            yield fs_1.promises.mkdir(directory, {\n                recursive: true\n            });\n        }\n    });\n}\nexports.createDirectoriesForArtifact = createDirectoriesForArtifact;\nfunction createEmptyFilesForArtifact(emptyFilesToCreate) {\n    return __awaiter(this, void 0, void 0, function* () {\n        for (const filePath of emptyFilesToCreate) {\n            yield (yield fs_1.promises.open(filePath, 'w')).close();\n        }\n    });\n}\nexports.createEmptyFilesForArtifact = createEmptyFilesForArtifact;\nfunction getFileSize(filePath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const stats = yield fs_1.promises.stat(filePath);\n        core_1.debug(`${filePath} size:(${stats.size}) blksize:(${stats.blksize}) blocks:(${stats.blocks})`);\n        return stats.size;\n    });\n}\nexports.getFileSize = getFileSize;\nfunction rmFile(filePath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        yield fs_1.promises.unlink(filePath);\n    });\n}\nexports.rmFile = rmFile;\nfunction getProperRetention(retentionInput, retentionSetting) {\n    if (retentionInput < 0) {\n        throw new Error('Invalid retention, minimum value is 1.');\n    }\n    let retention = retentionInput;\n    if (retentionSetting) {\n        const maxRetention = parseInt(retentionSetting);\n        if (!isNaN(maxRetention) && maxRetention < retention) {\n            core_1.warning(`Retention days is greater than the max value allowed by the repository setting, reduce retention to ${maxRetention} days`);\n            retention = maxRetention;\n        }\n    }\n    return retention;\n}\nexports.getProperRetention = getProperRetention;\nfunction sleep(milliseconds) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return new Promise(resolve => setTimeout(resolve, milliseconds));\n    });\n}\nexports.sleep = sleep;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issue = exports.issueCommand = void 0;\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\n/**\n * Commands\n *\n * Command Format:\n *   ::name key=value,key=value::message\n *\n * Examples:\n *   ::warning::This is the message\n *   ::set-env name=MY_VAR::some value\n */\nfunction issueCommand(command, properties, message) {\n    const cmd = new Command(command, properties, message);\n    process.stdout.write(cmd.toString() + os.EOL);\n}\nexports.issueCommand = issueCommand;\nfunction issue(name, message = '') {\n    issueCommand(name, {}, message);\n}\nexports.issue = issue;\nconst CMD_STRING = '::';\nclass Command {\n    constructor(command, properties, message) {\n        if (!command) {\n            command = 'missing.command';\n        }\n        this.command = command;\n        this.properties = properties;\n        this.message = message;\n    }\n    toString() {\n        let cmdStr = CMD_STRING + this.command;\n        if (this.properties && Object.keys(this.properties).length > 0) {\n            cmdStr += ' ';\n            let first = true;\n            for (const key in this.properties) {\n                if (this.properties.hasOwnProperty(key)) {\n                    const val = this.properties[key];\n                    if (val) {\n                        if (first) {\n                            first = false;\n                        }\n                        else {\n                            cmdStr += ',';\n                        }\n                        cmdStr += `${key}=${escapeProperty(val)}`;\n                    }\n                }\n            }\n        }\n        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;\n        return cmdStr;\n    }\n}\nfunction escapeData(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A');\n}\nfunction escapeProperty(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A')\n        .replace(/:/g, '%3A')\n        .replace(/,/g, '%2C');\n}\n//# sourceMappingURL=command.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getIDToken = exports.getState = exports.saveState = exports.group = exports.endGroup = exports.startGroup = exports.info = exports.notice = exports.warning = exports.error = exports.debug = exports.isDebug = exports.setFailed = exports.setCommandEcho = exports.setOutput = exports.getBooleanInput = exports.getMultilineInput = exports.getInput = exports.addPath = exports.setSecret = exports.exportVariable = exports.ExitCode = void 0;\nconst command_1 = require(\"./command\");\nconst file_command_1 = require(\"./file-command\");\nconst utils_1 = require(\"./utils\");\nconst os = __importStar(require(\"os\"));\nconst path = __importStar(require(\"path\"));\nconst oidc_utils_1 = require(\"./oidc-utils\");\n/**\n * The code to exit an action\n */\nvar ExitCode;\n(function (ExitCode) {\n    /**\n     * A code indicating that the action was successful\n     */\n    ExitCode[ExitCode[\"Success\"] = 0] = \"Success\";\n    /**\n     * A code indicating that the action was a failure\n     */\n    ExitCode[ExitCode[\"Failure\"] = 1] = \"Failure\";\n})(ExitCode = exports.ExitCode || (exports.ExitCode = {}));\n//-----------------------------------------------------------------------\n// Variables\n//-----------------------------------------------------------------------\n/**\n * Sets env variable for this action and future actions in the job\n * @param name the name of the variable to set\n * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction exportVariable(name, val) {\n    const convertedVal = utils_1.toCommandValue(val);\n    process.env[name] = convertedVal;\n    const filePath = process.env['GITHUB_ENV'] || '';\n    if (filePath) {\n        const delimiter = '_GitHubActionsFileCommandDelimeter_';\n        const commandValue = `${name}<<${delimiter}${os.EOL}${convertedVal}${os.EOL}${delimiter}`;\n        file_command_1.issueCommand('ENV', commandValue);\n    }\n    else {\n        command_1.issueCommand('set-env', { name }, convertedVal);\n    }\n}\nexports.exportVariable = exportVariable;\n/**\n * Registers a secret which will get masked from logs\n * @param secret value of the secret\n */\nfunction setSecret(secret) {\n    command_1.issueCommand('add-mask', {}, secret);\n}\nexports.setSecret = setSecret;\n/**\n * Prepends inputPath to the PATH (for this action and future actions)\n * @param inputPath\n */\nfunction addPath(inputPath) {\n    const filePath = process.env['GITHUB_PATH'] || '';\n    if (filePath) {\n        file_command_1.issueCommand('PATH', inputPath);\n    }\n    else {\n        command_1.issueCommand('add-path', {}, inputPath);\n    }\n    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;\n}\nexports.addPath = addPath;\n/**\n * Gets the value of an input.\n * Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.\n * Returns an empty string if the value is not defined.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string\n */\nfunction getInput(name, options) {\n    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';\n    if (options && options.required && !val) {\n        throw new Error(`Input required and not supplied: ${name}`);\n    }\n    if (options && options.trimWhitespace === false) {\n        return val;\n    }\n    return val.trim();\n}\nexports.getInput = getInput;\n/**\n * Gets the values of an multiline input.  Each value is also trimmed.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string[]\n *\n */\nfunction getMultilineInput(name, options) {\n    const inputs = getInput(name, options)\n        .split('\\n')\n        .filter(x => x !== '');\n    return inputs;\n}\nexports.getMultilineInput = getMultilineInput;\n/**\n * Gets the input value of the boolean type in the YAML 1.2 \"core schema\" specification.\n * Support boolean input list: `true | True | TRUE | false | False | FALSE` .\n * The return value is also in boolean type.\n * ref: https://yaml.org/spec/1.2/spec.html#id2804923\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   boolean\n */\nfunction getBooleanInput(name, options) {\n    const trueValue = ['true', 'True', 'TRUE'];\n    const falseValue = ['false', 'False', 'FALSE'];\n    const val = getInput(name, options);\n    if (trueValue.includes(val))\n        return true;\n    if (falseValue.includes(val))\n        return false;\n    throw new TypeError(`Input does not meet YAML 1.2 \"Core Schema\" specification: ${name}\\n` +\n        `Support boolean input list: \\`true | True | TRUE | false | False | FALSE\\``);\n}\nexports.getBooleanInput = getBooleanInput;\n/**\n * Sets the value of an output.\n *\n * @param     name     name of the output to set\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction setOutput(name, value) {\n    process.stdout.write(os.EOL);\n    command_1.issueCommand('set-output', { name }, value);\n}\nexports.setOutput = setOutput;\n/**\n * Enables or disables the echoing of commands into stdout for the rest of the step.\n * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.\n *\n */\nfunction setCommandEcho(enabled) {\n    command_1.issue('echo', enabled ? 'on' : 'off');\n}\nexports.setCommandEcho = setCommandEcho;\n//-----------------------------------------------------------------------\n// Results\n//-----------------------------------------------------------------------\n/**\n * Sets the action status to failed.\n * When the action exits it will be with an exit code of 1\n * @param message add error issue message\n */\nfunction setFailed(message) {\n    process.exitCode = ExitCode.Failure;\n    error(message);\n}\nexports.setFailed = setFailed;\n//-----------------------------------------------------------------------\n// Logging Commands\n//-----------------------------------------------------------------------\n/**\n * Gets whether Actions Step Debug is on or not\n */\nfunction isDebug() {\n    return process.env['RUNNER_DEBUG'] === '1';\n}\nexports.isDebug = isDebug;\n/**\n * Writes debug message to user log\n * @param message debug message\n */\nfunction debug(message) {\n    command_1.issueCommand('debug', {}, message);\n}\nexports.debug = debug;\n/**\n * Adds an error issue\n * @param message error issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction error(message, properties = {}) {\n    command_1.issueCommand('error', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.error = error;\n/**\n * Adds a warning issue\n * @param message warning issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction warning(message, properties = {}) {\n    command_1.issueCommand('warning', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.warning = warning;\n/**\n * Adds a notice issue\n * @param message notice issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction notice(message, properties = {}) {\n    command_1.issueCommand('notice', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.notice = notice;\n/**\n * Writes info to log with console.log.\n * @param message info message\n */\nfunction info(message) {\n    process.stdout.write(message + os.EOL);\n}\nexports.info = info;\n/**\n * Begin an output group.\n *\n * Output until the next `groupEnd` will be foldable in this group\n *\n * @param name The name of the output group\n */\nfunction startGroup(name) {\n    command_1.issue('group', name);\n}\nexports.startGroup = startGroup;\n/**\n * End an output group.\n */\nfunction endGroup() {\n    command_1.issue('endgroup');\n}\nexports.endGroup = endGroup;\n/**\n * Wrap an asynchronous function call in a group.\n *\n * Returns the same type as the function itself.\n *\n * @param name The name of the group\n * @param fn The function to wrap in the group\n */\nfunction group(name, fn) {\n    return __awaiter(this, void 0, void 0, function* () {\n        startGroup(name);\n        let result;\n        try {\n            result = yield fn();\n        }\n        finally {\n            endGroup();\n        }\n        return result;\n    });\n}\nexports.group = group;\n//-----------------------------------------------------------------------\n// Wrapper action state\n//-----------------------------------------------------------------------\n/**\n * Saves state for current action, the state can only be retrieved by this action's post job execution.\n *\n * @param     name     name of the state to store\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction saveState(name, value) {\n    command_1.issueCommand('save-state', { name }, value);\n}\nexports.saveState = saveState;\n/**\n * Gets the value of an state set by this action's main execution.\n *\n * @param     name     name of the state to get\n * @returns   string\n */\nfunction getState(name) {\n    return process.env[`STATE_${name}`] || '';\n}\nexports.getState = getState;\nfunction getIDToken(aud) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return yield oidc_utils_1.OidcClient.getIDToken(aud);\n    });\n}\nexports.getIDToken = getIDToken;\n//# sourceMappingURL=core.js.map","\"use strict\";\n// For internal use, subject to change.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issueCommand = void 0;\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nconst fs = __importStar(require(\"fs\"));\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\nfunction issueCommand(command, message) {\n    const filePath = process.env[`GITHUB_${command}`];\n    if (!filePath) {\n        throw new Error(`Unable to find environment variable for file command ${command}`);\n    }\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Missing file at path: ${filePath}`);\n    }\n    fs.appendFileSync(filePath, `${utils_1.toCommandValue(message)}${os.EOL}`, {\n        encoding: 'utf8'\n    });\n}\nexports.issueCommand = issueCommand;\n//# sourceMappingURL=file-command.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.OidcClient = void 0;\nconst http_client_1 = require(\"@actions/http-client\");\nconst auth_1 = require(\"@actions/http-client/auth\");\nconst core_1 = require(\"./core\");\nclass OidcClient {\n    static createHttpClient(allowRetry = true, maxRetry = 10) {\n        const requestOptions = {\n            allowRetries: allowRetry,\n            maxRetries: maxRetry\n        };\n        return new http_client_1.HttpClient('actions/oidc-client', [new auth_1.BearerCredentialHandler(OidcClient.getRequestToken())], requestOptions);\n    }\n    static getRequestToken() {\n        const token = process.env['ACTIONS_ID_TOKEN_REQUEST_TOKEN'];\n        if (!token) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_TOKEN env variable');\n        }\n        return token;\n    }\n    static getIDTokenUrl() {\n        const runtimeUrl = process.env['ACTIONS_ID_TOKEN_REQUEST_URL'];\n        if (!runtimeUrl) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_URL env variable');\n        }\n        return runtimeUrl;\n    }\n    static getCall(id_token_url) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            const httpclient = OidcClient.createHttpClient();\n            const res = yield httpclient\n                .getJson(id_token_url)\n                .catch(error => {\n                throw new Error(`Failed to get ID Token. \\n \n        Error Code : ${error.statusCode}\\n \n        Error Message: ${error.result.message}`);\n            });\n            const id_token = (_a = res.result) === null || _a === void 0 ? void 0 : _a.value;\n            if (!id_token) {\n                throw new Error('Response json body do not have ID Token field');\n            }\n            return id_token;\n        });\n    }\n    static getIDToken(audience) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                // New ID Token is requested from action service\n                let id_token_url = OidcClient.getIDTokenUrl();\n                if (audience) {\n                    const encodedAudience = encodeURIComponent(audience);\n                    id_token_url = `${id_token_url}&audience=${encodedAudience}`;\n                }\n                core_1.debug(`ID token url is ${id_token_url}`);\n                const id_token = yield OidcClient.getCall(id_token_url);\n                core_1.setSecret(id_token);\n                return id_token;\n            }\n            catch (error) {\n                throw new Error(`Error message: ${error.message}`);\n            }\n        });\n    }\n}\nexports.OidcClient = OidcClient;\n//# sourceMappingURL=oidc-utils.js.map","\"use strict\";\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toCommandProperties = exports.toCommandValue = void 0;\n/**\n * Sanitizes an input into a string so it can be passed into issueCommand safely\n * @param input input to sanitize into a string\n */\nfunction toCommandValue(input) {\n    if (input === null || input === undefined) {\n        return '';\n    }\n    else if (typeof input === 'string' || input instanceof String) {\n        return input;\n    }\n    return JSON.stringify(input);\n}\nexports.toCommandValue = toCommandValue;\n/**\n *\n * @param annotationProperties\n * @returns The command properties to send with the actual annotation command\n * See IssueCommandProperties: https://github.com/actions/runner/blob/main/src/Runner.Worker/ActionCommandManager.cs#L646\n */\nfunction toCommandProperties(annotationProperties) {\n    if (!Object.keys(annotationProperties).length) {\n        return {};\n    }\n    return {\n        title: annotationProperties.title,\n        file: annotationProperties.file,\n        line: annotationProperties.startLine,\n        endLine: annotationProperties.endLine,\n        col: annotationProperties.startColumn,\n        endColumn: annotationProperties.endColumn\n    };\n}\nexports.toCommandProperties = toCommandProperties;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass BasicCredentialHandler {\n    constructor(username, password) {\n        this.username = username;\n        this.password = password;\n    }\n    prepareRequest(options) {\n        options.headers['Authorization'] =\n            'Basic ' +\n                Buffer.from(this.username + ':' + this.password).toString('base64');\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication(response) {\n        return false;\n    }\n    handleAuthentication(httpClient, requestInfo, objs) {\n        return null;\n    }\n}\nexports.BasicCredentialHandler = BasicCredentialHandler;\nclass BearerCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        options.headers['Authorization'] = 'Bearer ' + this.token;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication(response) {\n        return false;\n    }\n    handleAuthentication(httpClient, requestInfo, objs) {\n        return null;\n    }\n}\nexports.BearerCredentialHandler = BearerCredentialHandler;\nclass PersonalAccessTokenCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        options.headers['Authorization'] =\n            'Basic ' + Buffer.from('PAT:' + this.token).toString('base64');\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication(response) {\n        return false;\n    }\n    handleAuthentication(httpClient, requestInfo, objs) {\n        return null;\n    }\n}\nexports.PersonalAccessTokenCredentialHandler = PersonalAccessTokenCredentialHandler;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst http = require(\"http\");\nconst https = require(\"https\");\nconst pm = require(\"./proxy\");\nlet tunnel;\nvar HttpCodes;\n(function (HttpCodes) {\n    HttpCodes[HttpCodes[\"OK\"] = 200] = \"OK\";\n    HttpCodes[HttpCodes[\"MultipleChoices\"] = 300] = \"MultipleChoices\";\n    HttpCodes[HttpCodes[\"MovedPermanently\"] = 301] = \"MovedPermanently\";\n    HttpCodes[HttpCodes[\"ResourceMoved\"] = 302] = \"ResourceMoved\";\n    HttpCodes[HttpCodes[\"SeeOther\"] = 303] = \"SeeOther\";\n    HttpCodes[HttpCodes[\"NotModified\"] = 304] = \"NotModified\";\n    HttpCodes[HttpCodes[\"UseProxy\"] = 305] = \"UseProxy\";\n    HttpCodes[HttpCodes[\"SwitchProxy\"] = 306] = \"SwitchProxy\";\n    HttpCodes[HttpCodes[\"TemporaryRedirect\"] = 307] = \"TemporaryRedirect\";\n    HttpCodes[HttpCodes[\"PermanentRedirect\"] = 308] = \"PermanentRedirect\";\n    HttpCodes[HttpCodes[\"BadRequest\"] = 400] = \"BadRequest\";\n    HttpCodes[HttpCodes[\"Unauthorized\"] = 401] = \"Unauthorized\";\n    HttpCodes[HttpCodes[\"PaymentRequired\"] = 402] = \"PaymentRequired\";\n    HttpCodes[HttpCodes[\"Forbidden\"] = 403] = \"Forbidden\";\n    HttpCodes[HttpCodes[\"NotFound\"] = 404] = \"NotFound\";\n    HttpCodes[HttpCodes[\"MethodNotAllowed\"] = 405] = \"MethodNotAllowed\";\n    HttpCodes[HttpCodes[\"NotAcceptable\"] = 406] = \"NotAcceptable\";\n    HttpCodes[HttpCodes[\"ProxyAuthenticationRequired\"] = 407] = \"ProxyAuthenticationRequired\";\n    HttpCodes[HttpCodes[\"RequestTimeout\"] = 408] = \"RequestTimeout\";\n    HttpCodes[HttpCodes[\"Conflict\"] = 409] = \"Conflict\";\n    HttpCodes[HttpCodes[\"Gone\"] = 410] = \"Gone\";\n    HttpCodes[HttpCodes[\"TooManyRequests\"] = 429] = \"TooManyRequests\";\n    HttpCodes[HttpCodes[\"InternalServerError\"] = 500] = \"InternalServerError\";\n    HttpCodes[HttpCodes[\"NotImplemented\"] = 501] = \"NotImplemented\";\n    HttpCodes[HttpCodes[\"BadGateway\"] = 502] = \"BadGateway\";\n    HttpCodes[HttpCodes[\"ServiceUnavailable\"] = 503] = \"ServiceUnavailable\";\n    HttpCodes[HttpCodes[\"GatewayTimeout\"] = 504] = \"GatewayTimeout\";\n})(HttpCodes = exports.HttpCodes || (exports.HttpCodes = {}));\nvar Headers;\n(function (Headers) {\n    Headers[\"Accept\"] = \"accept\";\n    Headers[\"ContentType\"] = \"content-type\";\n})(Headers = exports.Headers || (exports.Headers = {}));\nvar MediaTypes;\n(function (MediaTypes) {\n    MediaTypes[\"ApplicationJson\"] = \"application/json\";\n})(MediaTypes = exports.MediaTypes || (exports.MediaTypes = {}));\n/**\n * Returns the proxy URL, depending upon the supplied url and proxy environment variables.\n * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n */\nfunction getProxyUrl(serverUrl) {\n    let proxyUrl = pm.getProxyUrl(new URL(serverUrl));\n    return proxyUrl ? proxyUrl.href : '';\n}\nexports.getProxyUrl = getProxyUrl;\nconst HttpRedirectCodes = [\n    HttpCodes.MovedPermanently,\n    HttpCodes.ResourceMoved,\n    HttpCodes.SeeOther,\n    HttpCodes.TemporaryRedirect,\n    HttpCodes.PermanentRedirect\n];\nconst HttpResponseRetryCodes = [\n    HttpCodes.BadGateway,\n    HttpCodes.ServiceUnavailable,\n    HttpCodes.GatewayTimeout\n];\nconst RetryableHttpVerbs = ['OPTIONS', 'GET', 'DELETE', 'HEAD'];\nconst ExponentialBackoffCeiling = 10;\nconst ExponentialBackoffTimeSlice = 5;\nclass HttpClientError extends Error {\n    constructor(message, statusCode) {\n        super(message);\n        this.name = 'HttpClientError';\n        this.statusCode = statusCode;\n        Object.setPrototypeOf(this, HttpClientError.prototype);\n    }\n}\nexports.HttpClientError = HttpClientError;\nclass HttpClientResponse {\n    constructor(message) {\n        this.message = message;\n    }\n    readBody() {\n        return new Promise(async (resolve, reject) => {\n            let output = Buffer.alloc(0);\n            this.message.on('data', (chunk) => {\n                output = Buffer.concat([output, chunk]);\n            });\n            this.message.on('end', () => {\n                resolve(output.toString());\n            });\n        });\n    }\n}\nexports.HttpClientResponse = HttpClientResponse;\nfunction isHttps(requestUrl) {\n    let parsedUrl = new URL(requestUrl);\n    return parsedUrl.protocol === 'https:';\n}\nexports.isHttps = isHttps;\nclass HttpClient {\n    constructor(userAgent, handlers, requestOptions) {\n        this._ignoreSslError = false;\n        this._allowRedirects = true;\n        this._allowRedirectDowngrade = false;\n        this._maxRedirects = 50;\n        this._allowRetries = false;\n        this._maxRetries = 1;\n        this._keepAlive = false;\n        this._disposed = false;\n        this.userAgent = userAgent;\n        this.handlers = handlers || [];\n        this.requestOptions = requestOptions;\n        if (requestOptions) {\n            if (requestOptions.ignoreSslError != null) {\n                this._ignoreSslError = requestOptions.ignoreSslError;\n            }\n            this._socketTimeout = requestOptions.socketTimeout;\n            if (requestOptions.allowRedirects != null) {\n                this._allowRedirects = requestOptions.allowRedirects;\n            }\n            if (requestOptions.allowRedirectDowngrade != null) {\n                this._allowRedirectDowngrade = requestOptions.allowRedirectDowngrade;\n            }\n            if (requestOptions.maxRedirects != null) {\n                this._maxRedirects = Math.max(requestOptions.maxRedirects, 0);\n            }\n            if (requestOptions.keepAlive != null) {\n                this._keepAlive = requestOptions.keepAlive;\n            }\n            if (requestOptions.allowRetries != null) {\n                this._allowRetries = requestOptions.allowRetries;\n            }\n            if (requestOptions.maxRetries != null) {\n                this._maxRetries = requestOptions.maxRetries;\n            }\n        }\n    }\n    options(requestUrl, additionalHeaders) {\n        return this.request('OPTIONS', requestUrl, null, additionalHeaders || {});\n    }\n    get(requestUrl, additionalHeaders) {\n        return this.request('GET', requestUrl, null, additionalHeaders || {});\n    }\n    del(requestUrl, additionalHeaders) {\n        return this.request('DELETE', requestUrl, null, additionalHeaders || {});\n    }\n    post(requestUrl, data, additionalHeaders) {\n        return this.request('POST', requestUrl, data, additionalHeaders || {});\n    }\n    patch(requestUrl, data, additionalHeaders) {\n        return this.request('PATCH', requestUrl, data, additionalHeaders || {});\n    }\n    put(requestUrl, data, additionalHeaders) {\n        return this.request('PUT', requestUrl, data, additionalHeaders || {});\n    }\n    head(requestUrl, additionalHeaders) {\n        return this.request('HEAD', requestUrl, null, additionalHeaders || {});\n    }\n    sendStream(verb, requestUrl, stream, additionalHeaders) {\n        return this.request(verb, requestUrl, stream, additionalHeaders);\n    }\n    /**\n     * Gets a typed object from an endpoint\n     * Be aware that not found returns a null.  Other errors (4xx, 5xx) reject the promise\n     */\n    async getJson(requestUrl, additionalHeaders = {}) {\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        let res = await this.get(requestUrl, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    async postJson(requestUrl, obj, additionalHeaders = {}) {\n        let data = JSON.stringify(obj, null, 2);\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n        let res = await this.post(requestUrl, data, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    async putJson(requestUrl, obj, additionalHeaders = {}) {\n        let data = JSON.stringify(obj, null, 2);\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n        let res = await this.put(requestUrl, data, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    async patchJson(requestUrl, obj, additionalHeaders = {}) {\n        let data = JSON.stringify(obj, null, 2);\n        additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n        additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n        let res = await this.patch(requestUrl, data, additionalHeaders);\n        return this._processResponse(res, this.requestOptions);\n    }\n    /**\n     * Makes a raw http request.\n     * All other methods such as get, post, patch, and request ultimately call this.\n     * Prefer get, del, post and patch\n     */\n    async request(verb, requestUrl, data, headers) {\n        if (this._disposed) {\n            throw new Error('Client has already been disposed.');\n        }\n        let parsedUrl = new URL(requestUrl);\n        let info = this._prepareRequest(verb, parsedUrl, headers);\n        // Only perform retries on reads since writes may not be idempotent.\n        let maxTries = this._allowRetries && RetryableHttpVerbs.indexOf(verb) != -1\n            ? this._maxRetries + 1\n            : 1;\n        let numTries = 0;\n        let response;\n        while (numTries < maxTries) {\n            response = await this.requestRaw(info, data);\n            // Check if it's an authentication challenge\n            if (response &&\n                response.message &&\n                response.message.statusCode === HttpCodes.Unauthorized) {\n                let authenticationHandler;\n                for (let i = 0; i < this.handlers.length; i++) {\n                    if (this.handlers[i].canHandleAuthentication(response)) {\n                        authenticationHandler = this.handlers[i];\n                        break;\n                    }\n                }\n                if (authenticationHandler) {\n                    return authenticationHandler.handleAuthentication(this, info, data);\n                }\n                else {\n                    // We have received an unauthorized response but have no handlers to handle it.\n                    // Let the response return to the caller.\n                    return response;\n                }\n            }\n            let redirectsRemaining = this._maxRedirects;\n            while (HttpRedirectCodes.indexOf(response.message.statusCode) != -1 &&\n                this._allowRedirects &&\n                redirectsRemaining > 0) {\n                const redirectUrl = response.message.headers['location'];\n                if (!redirectUrl) {\n                    // if there's no location to redirect to, we won't\n                    break;\n                }\n                let parsedRedirectUrl = new URL(redirectUrl);\n                if (parsedUrl.protocol == 'https:' &&\n                    parsedUrl.protocol != parsedRedirectUrl.protocol &&\n                    !this._allowRedirectDowngrade) {\n                    throw new Error('Redirect from HTTPS to HTTP protocol. This downgrade is not allowed for security reasons. If you want to allow this behavior, set the allowRedirectDowngrade option to true.');\n                }\n                // we need to finish reading the response before reassigning response\n                // which will leak the open socket.\n                await response.readBody();\n                // strip authorization header if redirected to a different hostname\n                if (parsedRedirectUrl.hostname !== parsedUrl.hostname) {\n                    for (let header in headers) {\n                        // header names are case insensitive\n                        if (header.toLowerCase() === 'authorization') {\n                            delete headers[header];\n                        }\n                    }\n                }\n                // let's make the request with the new redirectUrl\n                info = this._prepareRequest(verb, parsedRedirectUrl, headers);\n                response = await this.requestRaw(info, data);\n                redirectsRemaining--;\n            }\n            if (HttpResponseRetryCodes.indexOf(response.message.statusCode) == -1) {\n                // If not a retry code, return immediately instead of retrying\n                return response;\n            }\n            numTries += 1;\n            if (numTries < maxTries) {\n                await response.readBody();\n                await this._performExponentialBackoff(numTries);\n            }\n        }\n        return response;\n    }\n    /**\n     * Needs to be called if keepAlive is set to true in request options.\n     */\n    dispose() {\n        if (this._agent) {\n            this._agent.destroy();\n        }\n        this._disposed = true;\n    }\n    /**\n     * Raw request.\n     * @param info\n     * @param data\n     */\n    requestRaw(info, data) {\n        return new Promise((resolve, reject) => {\n            let callbackForResult = function (err, res) {\n                if (err) {\n                    reject(err);\n                }\n                resolve(res);\n            };\n            this.requestRawWithCallback(info, data, callbackForResult);\n        });\n    }\n    /**\n     * Raw request with callback.\n     * @param info\n     * @param data\n     * @param onResult\n     */\n    requestRawWithCallback(info, data, onResult) {\n        let socket;\n        if (typeof data === 'string') {\n            info.options.headers['Content-Length'] = Buffer.byteLength(data, 'utf8');\n        }\n        let callbackCalled = false;\n        let handleResult = (err, res) => {\n            if (!callbackCalled) {\n                callbackCalled = true;\n                onResult(err, res);\n            }\n        };\n        let req = info.httpModule.request(info.options, (msg) => {\n            let res = new HttpClientResponse(msg);\n            handleResult(null, res);\n        });\n        req.on('socket', sock => {\n            socket = sock;\n        });\n        // If we ever get disconnected, we want the socket to timeout eventually\n        req.setTimeout(this._socketTimeout || 3 * 60000, () => {\n            if (socket) {\n                socket.end();\n            }\n            handleResult(new Error('Request timeout: ' + info.options.path), null);\n        });\n        req.on('error', function (err) {\n            // err has statusCode property\n            // res should have headers\n            handleResult(err, null);\n        });\n        if (data && typeof data === 'string') {\n            req.write(data, 'utf8');\n        }\n        if (data && typeof data !== 'string') {\n            data.on('close', function () {\n                req.end();\n            });\n            data.pipe(req);\n        }\n        else {\n            req.end();\n        }\n    }\n    /**\n     * Gets an http agent. This function is useful when you need an http agent that handles\n     * routing through a proxy server - depending upon the url and proxy environment variables.\n     * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n     */\n    getAgent(serverUrl) {\n        let parsedUrl = new URL(serverUrl);\n        return this._getAgent(parsedUrl);\n    }\n    _prepareRequest(method, requestUrl, headers) {\n        const info = {};\n        info.parsedUrl = requestUrl;\n        const usingSsl = info.parsedUrl.protocol === 'https:';\n        info.httpModule = usingSsl ? https : http;\n        const defaultPort = usingSsl ? 443 : 80;\n        info.options = {};\n        info.options.host = info.parsedUrl.hostname;\n        info.options.port = info.parsedUrl.port\n            ? parseInt(info.parsedUrl.port)\n            : defaultPort;\n        info.options.path =\n            (info.parsedUrl.pathname || '') + (info.parsedUrl.search || '');\n        info.options.method = method;\n        info.options.headers = this._mergeHeaders(headers);\n        if (this.userAgent != null) {\n            info.options.headers['user-agent'] = this.userAgent;\n        }\n        info.options.agent = this._getAgent(info.parsedUrl);\n        // gives handlers an opportunity to participate\n        if (this.handlers) {\n            this.handlers.forEach(handler => {\n                handler.prepareRequest(info.options);\n            });\n        }\n        return info;\n    }\n    _mergeHeaders(headers) {\n        const lowercaseKeys = obj => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n        if (this.requestOptions && this.requestOptions.headers) {\n            return Object.assign({}, lowercaseKeys(this.requestOptions.headers), lowercaseKeys(headers));\n        }\n        return lowercaseKeys(headers || {});\n    }\n    _getExistingOrDefaultHeader(additionalHeaders, header, _default) {\n        const lowercaseKeys = obj => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n        let clientHeader;\n        if (this.requestOptions && this.requestOptions.headers) {\n            clientHeader = lowercaseKeys(this.requestOptions.headers)[header];\n        }\n        return additionalHeaders[header] || clientHeader || _default;\n    }\n    _getAgent(parsedUrl) {\n        let agent;\n        let proxyUrl = pm.getProxyUrl(parsedUrl);\n        let useProxy = proxyUrl && proxyUrl.hostname;\n        if (this._keepAlive && useProxy) {\n            agent = this._proxyAgent;\n        }\n        if (this._keepAlive && !useProxy) {\n            agent = this._agent;\n        }\n        // if agent is already assigned use that agent.\n        if (!!agent) {\n            return agent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        let maxSockets = 100;\n        if (!!this.requestOptions) {\n            maxSockets = this.requestOptions.maxSockets || http.globalAgent.maxSockets;\n        }\n        if (useProxy) {\n            // If using proxy, need tunnel\n            if (!tunnel) {\n                tunnel = require('tunnel');\n            }\n            const agentOptions = {\n                maxSockets: maxSockets,\n                keepAlive: this._keepAlive,\n                proxy: {\n                    ...((proxyUrl.username || proxyUrl.password) && {\n                        proxyAuth: `${proxyUrl.username}:${proxyUrl.password}`\n                    }),\n                    host: proxyUrl.hostname,\n                    port: proxyUrl.port\n                }\n            };\n            let tunnelAgent;\n            const overHttps = proxyUrl.protocol === 'https:';\n            if (usingSsl) {\n                tunnelAgent = overHttps ? tunnel.httpsOverHttps : tunnel.httpsOverHttp;\n            }\n            else {\n                tunnelAgent = overHttps ? tunnel.httpOverHttps : tunnel.httpOverHttp;\n            }\n            agent = tunnelAgent(agentOptions);\n            this._proxyAgent = agent;\n        }\n        // if reusing agent across request and tunneling agent isn't assigned create a new agent\n        if (this._keepAlive && !agent) {\n            const options = { keepAlive: this._keepAlive, maxSockets: maxSockets };\n            agent = usingSsl ? new https.Agent(options) : new http.Agent(options);\n            this._agent = agent;\n        }\n        // if not using private agent and tunnel agent isn't setup then use global agent\n        if (!agent) {\n            agent = usingSsl ? https.globalAgent : http.globalAgent;\n        }\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            agent.options = Object.assign(agent.options || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return agent;\n    }\n    _performExponentialBackoff(retryNumber) {\n        retryNumber = Math.min(ExponentialBackoffCeiling, retryNumber);\n        const ms = ExponentialBackoffTimeSlice * Math.pow(2, retryNumber);\n        return new Promise(resolve => setTimeout(() => resolve(), ms));\n    }\n    static dateTimeDeserializer(key, value) {\n        if (typeof value === 'string') {\n            let a = new Date(value);\n            if (!isNaN(a.valueOf())) {\n                return a;\n            }\n        }\n        return value;\n    }\n    async _processResponse(res, options) {\n        return new Promise(async (resolve, reject) => {\n            const statusCode = res.message.statusCode;\n            const response = {\n                statusCode: statusCode,\n                result: null,\n                headers: {}\n            };\n            // not found leads to null obj returned\n            if (statusCode == HttpCodes.NotFound) {\n                resolve(response);\n            }\n            let obj;\n            let contents;\n            // get the result from the body\n            try {\n                contents = await res.readBody();\n                if (contents && contents.length > 0) {\n                    if (options && options.deserializeDates) {\n                        obj = JSON.parse(contents, HttpClient.dateTimeDeserializer);\n                    }\n                    else {\n                        obj = JSON.parse(contents);\n                    }\n                    response.result = obj;\n                }\n                response.headers = res.message.headers;\n            }\n            catch (err) {\n                // Invalid resource (contents not json);  leaving result obj null\n            }\n            // note that 3xx redirects are handled by the http layer.\n            if (statusCode > 299) {\n                let msg;\n                // if exception/error in body, attempt to get better error\n                if (obj && obj.message) {\n                    msg = obj.message;\n                }\n                else if (contents && contents.length > 0) {\n                    // it may be the case that the exception is in the body message as string\n                    msg = contents;\n                }\n                else {\n                    msg = 'Failed request: (' + statusCode + ')';\n                }\n                let err = new HttpClientError(msg, statusCode);\n                err.result = response.result;\n                reject(err);\n            }\n            else {\n                resolve(response);\n            }\n        });\n    }\n}\nexports.HttpClient = HttpClient;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction getProxyUrl(reqUrl) {\n    let usingSsl = reqUrl.protocol === 'https:';\n    let proxyUrl;\n    if (checkBypass(reqUrl)) {\n        return proxyUrl;\n    }\n    let proxyVar;\n    if (usingSsl) {\n        proxyVar = process.env['https_proxy'] || process.env['HTTPS_PROXY'];\n    }\n    else {\n        proxyVar = process.env['http_proxy'] || process.env['HTTP_PROXY'];\n    }\n    if (proxyVar) {\n        proxyUrl = new URL(proxyVar);\n    }\n    return proxyUrl;\n}\nexports.getProxyUrl = getProxyUrl;\nfunction checkBypass(reqUrl) {\n    if (!reqUrl.hostname) {\n        return false;\n    }\n    let noProxy = process.env['no_proxy'] || process.env['NO_PROXY'] || '';\n    if (!noProxy) {\n        return false;\n    }\n    // Determine the request port\n    let reqPort;\n    if (reqUrl.port) {\n        reqPort = Number(reqUrl.port);\n    }\n    else if (reqUrl.protocol === 'http:') {\n        reqPort = 80;\n    }\n    else if (reqUrl.protocol === 'https:') {\n        reqPort = 443;\n    }\n    // Format the request hostname and hostname with port\n    let upperReqHosts = [reqUrl.hostname.toUpperCase()];\n    if (typeof reqPort === 'number') {\n        upperReqHosts.push(`${upperReqHosts[0]}:${reqPort}`);\n    }\n    // Compare request host against noproxy\n    for (let upperNoProxyItem of noProxy\n        .split(',')\n        .map(x => x.trim().toUpperCase())\n        .filter(x => x)) {\n        if (upperReqHosts.some(x => x === upperNoProxyItem)) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.checkBypass = checkBypass;\n","'use strict';\nmodule.exports = balanced;\nfunction balanced(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n\n  var r = range(a, b, str);\n\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced.range = range;\nfunction range(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    if(a===b) {\n      return [ai, bi];\n    }\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [ begs.pop(), bi ];\n      } else {\n        beg = begs.pop();\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [ left, right ];\n    }\n  }\n\n  return result;\n}\n","var concatMap = require('concat-map');\nvar balanced = require('balanced-match');\n\nmodule.exports = expandTop;\n\nvar escSlash = '\\0SLASH'+Math.random()+'\\0';\nvar escOpen = '\\0OPEN'+Math.random()+'\\0';\nvar escClose = '\\0CLOSE'+Math.random()+'\\0';\nvar escComma = '\\0COMMA'+Math.random()+'\\0';\nvar escPeriod = '\\0PERIOD'+Math.random()+'\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str\n    ? parseInt(str, 10)\n    : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash)\n            .split('\\\\{').join(escOpen)\n            .split('\\\\}').join(escClose)\n            .split('\\\\,').join(escComma)\n            .split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\')\n            .split(escOpen).join('{')\n            .split(escClose).join('}')\n            .split(escComma).join(',')\n            .split(escPeriod).join('.');\n}\n\n\n// Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\nfunction parseCommaParts(str) {\n  if (!str)\n    return [''];\n\n  var parts = [];\n  var m = balanced('{', '}', str);\n\n  if (!m)\n    return str.split(',');\n\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n\n  p[p.length-1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n  if (post.length) {\n    p[p.length-1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str)\n    return [];\n\n  // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction identity(e) {\n  return e;\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand(str, isTop) {\n  var expansions = [];\n\n  var m = balanced('{', '}', str);\n  if (!m || /\\$$/.test(m.pre)) return [str];\n\n  var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isSequence = isNumericSequence || isAlphaSequence;\n  var isOptions = m.body.indexOf(',') >= 0;\n  if (!isSequence && !isOptions) {\n    // {a},b}\n    if (m.post.match(/,.*\\}/)) {\n      str = m.pre + '{' + m.body + escClose + m.post;\n      return expand(str);\n    }\n    return [str];\n  }\n\n  var n;\n  if (isSequence) {\n    n = m.body.split(/\\.\\./);\n  } else {\n    n = parseCommaParts(m.body);\n    if (n.length === 1) {\n      // x{{a,b}}y ==> x{a}y x{b}y\n      n = expand(n[0], false).map(embrace);\n      if (n.length === 1) {\n        var post = m.post.length\n          ? expand(m.post, false)\n          : [''];\n        return post.map(function(p) {\n          return m.pre + n[0] + p;\n        });\n      }\n    }\n  }\n\n  // at this point, n is the parts, and we know it's not a comma set\n  // with a single entry.\n\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n  var pre = m.pre;\n  var post = m.post.length\n    ? expand(m.post, false)\n    : [''];\n\n  var N;\n\n  if (isSequence) {\n    var x = numeric(n[0]);\n    var y = numeric(n[1]);\n    var width = Math.max(n[0].length, n[1].length)\n    var incr = n.length == 3\n      ? Math.abs(numeric(n[2]))\n      : 1;\n    var test = lte;\n    var reverse = y < x;\n    if (reverse) {\n      incr *= -1;\n      test = gte;\n    }\n    var pad = n.some(isPadded);\n\n    N = [];\n\n    for (var i = x; test(i, y); i += incr) {\n      var c;\n      if (isAlphaSequence) {\n        c = String.fromCharCode(i);\n        if (c === '\\\\')\n          c = '';\n      } else {\n        c = String(i);\n        if (pad) {\n          var need = width - c.length;\n          if (need > 0) {\n            var z = new Array(need + 1).join('0');\n            if (i < 0)\n              c = '-' + z + c.slice(1);\n            else\n              c = z + c;\n          }\n        }\n      }\n      N.push(c);\n    }\n  } else {\n    N = concatMap(n, function(el) { return expand(el, false) });\n  }\n\n  for (var j = 0; j < N.length; j++) {\n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre + N[j] + post[k];\n      if (!isTop || isSequence || expansion)\n        expansions.push(expansion);\n    }\n  }\n\n  return expansions;\n}\n\n","module.exports = function (xs, fn) {\n    var res = [];\n    for (var i = 0; i < xs.length; i++) {\n        var x = fn(xs[i], i);\n        if (isArray(x)) res.push.apply(res, x);\n        else res.push(x);\n    }\n    return res;\n};\n\nvar isArray = Array.isArray || function (xs) {\n    return Object.prototype.toString.call(xs) === '[object Array]';\n};\n","\"use strict\";\n/**\n * Returns a `Buffer` instance from the given data URI `uri`.\n *\n * @param {String} uri Data URI to turn into a Buffer instance\n * @return {Buffer} Buffer instance from Data URI\n * @api public\n */\nfunction dataUriToBuffer(uri) {\n    if (!/^data:/i.test(uri)) {\n        throw new TypeError('`uri` does not appear to be a Data URI (must begin with \"data:\")');\n    }\n    // strip newlines\n    uri = uri.replace(/\\r?\\n/g, '');\n    // split the URI up into the \"metadata\" and the \"data\" portions\n    const firstComma = uri.indexOf(',');\n    if (firstComma === -1 || firstComma <= 4) {\n        throw new TypeError('malformed data: URI');\n    }\n    // remove the \"data:\" scheme and parse the metadata\n    const meta = uri.substring(5, firstComma).split(';');\n    let charset = '';\n    let base64 = false;\n    const type = meta[0] || 'text/plain';\n    let typeFull = type;\n    for (let i = 1; i < meta.length; i++) {\n        if (meta[i] === 'base64') {\n            base64 = true;\n        }\n        else {\n            typeFull += `;${meta[i]}`;\n            if (meta[i].indexOf('charset=') === 0) {\n                charset = meta[i].substring(8);\n            }\n        }\n    }\n    // defaults to US-ASCII only if type is not provided\n    if (!meta[0] && !charset.length) {\n        typeFull += ';charset=US-ASCII';\n        charset = 'US-ASCII';\n    }\n    // get the encoded data portion and decode URI-encoded chars\n    const encoding = base64 ? 'base64' : 'ascii';\n    const data = unescape(uri.substring(firstComma + 1));\n    const buffer = Buffer.from(data, encoding);\n    // set `.type` and `.typeFull` properties to MIME type\n    buffer.type = type;\n    buffer.typeFull = typeFull;\n    // set the `.charset` property\n    buffer.charset = charset;\n    return buffer;\n}\nmodule.exports = dataUriToBuffer;\n//# sourceMappingURL=index.js.map","module.exports = realpath\nrealpath.realpath = realpath\nrealpath.sync = realpathSync\nrealpath.realpathSync = realpathSync\nrealpath.monkeypatch = monkeypatch\nrealpath.unmonkeypatch = unmonkeypatch\n\nvar fs = require('fs')\nvar origRealpath = fs.realpath\nvar origRealpathSync = fs.realpathSync\n\nvar version = process.version\nvar ok = /^v[0-5]\\./.test(version)\nvar old = require('./old.js')\n\nfunction newError (er) {\n  return er && er.syscall === 'realpath' && (\n    er.code === 'ELOOP' ||\n    er.code === 'ENOMEM' ||\n    er.code === 'ENAMETOOLONG'\n  )\n}\n\nfunction realpath (p, cache, cb) {\n  if (ok) {\n    return origRealpath(p, cache, cb)\n  }\n\n  if (typeof cache === 'function') {\n    cb = cache\n    cache = null\n  }\n  origRealpath(p, cache, function (er, result) {\n    if (newError(er)) {\n      old.realpath(p, cache, cb)\n    } else {\n      cb(er, result)\n    }\n  })\n}\n\nfunction realpathSync (p, cache) {\n  if (ok) {\n    return origRealpathSync(p, cache)\n  }\n\n  try {\n    return origRealpathSync(p, cache)\n  } catch (er) {\n    if (newError(er)) {\n      return old.realpathSync(p, cache)\n    } else {\n      throw er\n    }\n  }\n}\n\nfunction monkeypatch () {\n  fs.realpath = realpath\n  fs.realpathSync = realpathSync\n}\n\nfunction unmonkeypatch () {\n  fs.realpath = origRealpath\n  fs.realpathSync = origRealpathSync\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar pathModule = require('path');\nvar isWindows = process.platform === 'win32';\nvar fs = require('fs');\n\n// JavaScript implementation of realpath, ported from node pre-v6\n\nvar DEBUG = process.env.NODE_DEBUG && /fs/.test(process.env.NODE_DEBUG);\n\nfunction rethrow() {\n  // Only enable in debug mode. A backtrace uses ~1000 bytes of heap space and\n  // is fairly slow to generate.\n  var callback;\n  if (DEBUG) {\n    var backtrace = new Error;\n    callback = debugCallback;\n  } else\n    callback = missingCallback;\n\n  return callback;\n\n  function debugCallback(err) {\n    if (err) {\n      backtrace.message = err.message;\n      err = backtrace;\n      missingCallback(err);\n    }\n  }\n\n  function missingCallback(err) {\n    if (err) {\n      if (process.throwDeprecation)\n        throw err;  // Forgot a callback but don't know where? Use NODE_DEBUG=fs\n      else if (!process.noDeprecation) {\n        var msg = 'fs: missing callback ' + (err.stack || err.message);\n        if (process.traceDeprecation)\n          console.trace(msg);\n        else\n          console.error(msg);\n      }\n    }\n  }\n}\n\nfunction maybeCallback(cb) {\n  return typeof cb === 'function' ? cb : rethrow();\n}\n\nvar normalize = pathModule.normalize;\n\n// Regexp that finds the next partion of a (partial) path\n// result is [base_with_slash, base], e.g. ['somedir/', 'somedir']\nif (isWindows) {\n  var nextPartRe = /(.*?)(?:[\\/\\\\]+|$)/g;\n} else {\n  var nextPartRe = /(.*?)(?:[\\/]+|$)/g;\n}\n\n// Regex to find the device root, including trailing slash. E.g. 'c:\\\\'.\nif (isWindows) {\n  var splitRootRe = /^(?:[a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/][^\\\\\\/]+)?[\\\\\\/]*/;\n} else {\n  var splitRootRe = /^[\\/]*/;\n}\n\nexports.realpathSync = function realpathSync(p, cache) {\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return cache[p];\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows && !knownHard[base]) {\n      fs.lstatSync(base);\n      knownHard[base] = true;\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  // NB: p.length changes.\n  while (pos < p.length) {\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      continue;\n    }\n\n    var resolvedLink;\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // some known symbolic link.  no need to stat again.\n      resolvedLink = cache[base];\n    } else {\n      var stat = fs.lstatSync(base);\n      if (!stat.isSymbolicLink()) {\n        knownHard[base] = true;\n        if (cache) cache[base] = base;\n        continue;\n      }\n\n      // read the link if it wasn't read before\n      // dev/ino always return 0 on windows, so skip the check.\n      var linkTarget = null;\n      if (!isWindows) {\n        var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n        if (seenLinks.hasOwnProperty(id)) {\n          linkTarget = seenLinks[id];\n        }\n      }\n      if (linkTarget === null) {\n        fs.statSync(base);\n        linkTarget = fs.readlinkSync(base);\n      }\n      resolvedLink = pathModule.resolve(previous, linkTarget);\n      // track this, if given a cache.\n      if (cache) cache[base] = resolvedLink;\n      if (!isWindows) seenLinks[id] = linkTarget;\n    }\n\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n\n  if (cache) cache[original] = p;\n\n  return p;\n};\n\n\nexports.realpath = function realpath(p, cache, cb) {\n  if (typeof cb !== 'function') {\n    cb = maybeCallback(cache);\n    cache = null;\n  }\n\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return process.nextTick(cb.bind(null, null, cache[p]));\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows && !knownHard[base]) {\n      fs.lstat(base, function(err) {\n        if (err) return cb(err);\n        knownHard[base] = true;\n        LOOP();\n      });\n    } else {\n      process.nextTick(LOOP);\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  function LOOP() {\n    // stop if scanned past end of path\n    if (pos >= p.length) {\n      if (cache) cache[original] = p;\n      return cb(null, p);\n    }\n\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      return process.nextTick(LOOP);\n    }\n\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // known symbolic link.  no need to stat again.\n      return gotResolvedLink(cache[base]);\n    }\n\n    return fs.lstat(base, gotStat);\n  }\n\n  function gotStat(err, stat) {\n    if (err) return cb(err);\n\n    // if not a symlink, skip to the next path part\n    if (!stat.isSymbolicLink()) {\n      knownHard[base] = true;\n      if (cache) cache[base] = base;\n      return process.nextTick(LOOP);\n    }\n\n    // stat & read the link if not read before\n    // call gotTarget as soon as the link target is known\n    // dev/ino always return 0 on windows, so skip the check.\n    if (!isWindows) {\n      var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n      if (seenLinks.hasOwnProperty(id)) {\n        return gotTarget(null, seenLinks[id], base);\n      }\n    }\n    fs.stat(base, function(err) {\n      if (err) return cb(err);\n\n      fs.readlink(base, function(err, target) {\n        if (!isWindows) seenLinks[id] = target;\n        gotTarget(err, target);\n      });\n    });\n  }\n\n  function gotTarget(err, target, base) {\n    if (err) return cb(err);\n\n    var resolvedLink = pathModule.resolve(previous, target);\n    if (cache) cache[base] = resolvedLink;\n    gotResolvedLink(resolvedLink);\n  }\n\n  function gotResolvedLink(resolvedLink) {\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n};\n","exports.setopts = setopts\nexports.ownProp = ownProp\nexports.makeAbs = makeAbs\nexports.finish = finish\nexports.mark = mark\nexports.isIgnored = isIgnored\nexports.childrenIgnored = childrenIgnored\n\nfunction ownProp (obj, field) {\n  return Object.prototype.hasOwnProperty.call(obj, field)\n}\n\nvar fs = require(\"fs\")\nvar path = require(\"path\")\nvar minimatch = require(\"minimatch\")\nvar isAbsolute = require(\"path-is-absolute\")\nvar Minimatch = minimatch.Minimatch\n\nfunction alphasort (a, b) {\n  return a.localeCompare(b, 'en')\n}\n\nfunction setupIgnores (self, options) {\n  self.ignore = options.ignore || []\n\n  if (!Array.isArray(self.ignore))\n    self.ignore = [self.ignore]\n\n  if (self.ignore.length) {\n    self.ignore = self.ignore.map(ignoreMap)\n  }\n}\n\n// ignore patterns are always in dot:true mode.\nfunction ignoreMap (pattern) {\n  var gmatcher = null\n  if (pattern.slice(-3) === '/**') {\n    var gpattern = pattern.replace(/(\\/\\*\\*)+$/, '')\n    gmatcher = new Minimatch(gpattern, { dot: true })\n  }\n\n  return {\n    matcher: new Minimatch(pattern, { dot: true }),\n    gmatcher: gmatcher\n  }\n}\n\nfunction setopts (self, pattern, options) {\n  if (!options)\n    options = {}\n\n  // base-matching: just use globstar for that.\n  if (options.matchBase && -1 === pattern.indexOf(\"/\")) {\n    if (options.noglobstar) {\n      throw new Error(\"base matching requires globstar\")\n    }\n    pattern = \"**/\" + pattern\n  }\n\n  self.silent = !!options.silent\n  self.pattern = pattern\n  self.strict = options.strict !== false\n  self.realpath = !!options.realpath\n  self.realpathCache = options.realpathCache || Object.create(null)\n  self.follow = !!options.follow\n  self.dot = !!options.dot\n  self.mark = !!options.mark\n  self.nodir = !!options.nodir\n  if (self.nodir)\n    self.mark = true\n  self.sync = !!options.sync\n  self.nounique = !!options.nounique\n  self.nonull = !!options.nonull\n  self.nosort = !!options.nosort\n  self.nocase = !!options.nocase\n  self.stat = !!options.stat\n  self.noprocess = !!options.noprocess\n  self.absolute = !!options.absolute\n  self.fs = options.fs || fs\n\n  self.maxLength = options.maxLength || Infinity\n  self.cache = options.cache || Object.create(null)\n  self.statCache = options.statCache || Object.create(null)\n  self.symlinks = options.symlinks || Object.create(null)\n\n  setupIgnores(self, options)\n\n  self.changedCwd = false\n  var cwd = process.cwd()\n  if (!ownProp(options, \"cwd\"))\n    self.cwd = cwd\n  else {\n    self.cwd = path.resolve(options.cwd)\n    self.changedCwd = self.cwd !== cwd\n  }\n\n  self.root = options.root || path.resolve(self.cwd, \"/\")\n  self.root = path.resolve(self.root)\n  if (process.platform === \"win32\")\n    self.root = self.root.replace(/\\\\/g, \"/\")\n\n  // TODO: is an absolute `cwd` supposed to be resolved against `root`?\n  // e.g. { cwd: '/test', root: __dirname } === path.join(__dirname, '/test')\n  self.cwdAbs = isAbsolute(self.cwd) ? self.cwd : makeAbs(self, self.cwd)\n  if (process.platform === \"win32\")\n    self.cwdAbs = self.cwdAbs.replace(/\\\\/g, \"/\")\n  self.nomount = !!options.nomount\n\n  // disable comments and negation in Minimatch.\n  // Note that they are not supported in Glob itself anyway.\n  options.nonegate = true\n  options.nocomment = true\n\n  self.minimatch = new Minimatch(pattern, options)\n  self.options = self.minimatch.options\n}\n\nfunction finish (self) {\n  var nou = self.nounique\n  var all = nou ? [] : Object.create(null)\n\n  for (var i = 0, l = self.matches.length; i < l; i ++) {\n    var matches = self.matches[i]\n    if (!matches || Object.keys(matches).length === 0) {\n      if (self.nonull) {\n        // do like the shell, and spit out the literal glob\n        var literal = self.minimatch.globSet[i]\n        if (nou)\n          all.push(literal)\n        else\n          all[literal] = true\n      }\n    } else {\n      // had matches\n      var m = Object.keys(matches)\n      if (nou)\n        all.push.apply(all, m)\n      else\n        m.forEach(function (m) {\n          all[m] = true\n        })\n    }\n  }\n\n  if (!nou)\n    all = Object.keys(all)\n\n  if (!self.nosort)\n    all = all.sort(alphasort)\n\n  // at *some* point we statted all of these\n  if (self.mark) {\n    for (var i = 0; i < all.length; i++) {\n      all[i] = self._mark(all[i])\n    }\n    if (self.nodir) {\n      all = all.filter(function (e) {\n        var notDir = !(/\\/$/.test(e))\n        var c = self.cache[e] || self.cache[makeAbs(self, e)]\n        if (notDir && c)\n          notDir = c !== 'DIR' && !Array.isArray(c)\n        return notDir\n      })\n    }\n  }\n\n  if (self.ignore.length)\n    all = all.filter(function(m) {\n      return !isIgnored(self, m)\n    })\n\n  self.found = all\n}\n\nfunction mark (self, p) {\n  var abs = makeAbs(self, p)\n  var c = self.cache[abs]\n  var m = p\n  if (c) {\n    var isDir = c === 'DIR' || Array.isArray(c)\n    var slash = p.slice(-1) === '/'\n\n    if (isDir && !slash)\n      m += '/'\n    else if (!isDir && slash)\n      m = m.slice(0, -1)\n\n    if (m !== p) {\n      var mabs = makeAbs(self, m)\n      self.statCache[mabs] = self.statCache[abs]\n      self.cache[mabs] = self.cache[abs]\n    }\n  }\n\n  return m\n}\n\n// lotta situps...\nfunction makeAbs (self, f) {\n  var abs = f\n  if (f.charAt(0) === '/') {\n    abs = path.join(self.root, f)\n  } else if (isAbsolute(f) || f === '') {\n    abs = f\n  } else if (self.changedCwd) {\n    abs = path.resolve(self.cwd, f)\n  } else {\n    abs = path.resolve(f)\n  }\n\n  if (process.platform === 'win32')\n    abs = abs.replace(/\\\\/g, '/')\n\n  return abs\n}\n\n\n// Return true, if pattern ends with globstar '**', for the accompanying parent directory.\n// Ex:- If node_modules/** is the pattern, add 'node_modules' to ignore list along with it's contents\nfunction isIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return item.matcher.match(path) || !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n\nfunction childrenIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n","// Approach:\n//\n// 1. Get the minimatch set\n// 2. For each pattern in the set, PROCESS(pattern, false)\n// 3. Store matches per-set, then uniq them\n//\n// PROCESS(pattern, inGlobStar)\n// Get the first [n] items from pattern that are all strings\n// Join these together.  This is PREFIX.\n//   If there is no more remaining, then stat(PREFIX) and\n//   add to matches if it succeeds.  END.\n//\n// If inGlobStar and PREFIX is symlink and points to dir\n//   set ENTRIES = []\n// else readdir(PREFIX) as ENTRIES\n//   If fail, END\n//\n// with ENTRIES\n//   If pattern[n] is GLOBSTAR\n//     // handle the case where the globstar match is empty\n//     // by pruning it out, and testing the resulting pattern\n//     PROCESS(pattern[0..n] + pattern[n+1 .. $], false)\n//     // handle other cases.\n//     for ENTRY in ENTRIES (not dotfiles)\n//       // attach globstar + tail onto the entry\n//       // Mark that this entry is a globstar match\n//       PROCESS(pattern[0..n] + ENTRY + pattern[n .. $], true)\n//\n//   else // not globstar\n//     for ENTRY in ENTRIES (not dotfiles, unless pattern[n] is dot)\n//       Test ENTRY against pattern[n]\n//       If fails, continue\n//       If passes, PROCESS(pattern[0..n] + item + pattern[n+1 .. $])\n//\n// Caveat:\n//   Cache all stats and readdirs results to minimize syscall.  Since all\n//   we ever care about is existence and directory-ness, we can just keep\n//   `true` for files, and [children,...] for directories, or `false` for\n//   things that don't exist.\n\nmodule.exports = glob\n\nvar rp = require('fs.realpath')\nvar minimatch = require('minimatch')\nvar Minimatch = minimatch.Minimatch\nvar inherits = require('inherits')\nvar EE = require('events').EventEmitter\nvar path = require('path')\nvar assert = require('assert')\nvar isAbsolute = require('path-is-absolute')\nvar globSync = require('./sync.js')\nvar common = require('./common.js')\nvar setopts = common.setopts\nvar ownProp = common.ownProp\nvar inflight = require('inflight')\nvar util = require('util')\nvar childrenIgnored = common.childrenIgnored\nvar isIgnored = common.isIgnored\n\nvar once = require('once')\n\nfunction glob (pattern, options, cb) {\n  if (typeof options === 'function') cb = options, options = {}\n  if (!options) options = {}\n\n  if (options.sync) {\n    if (cb)\n      throw new TypeError('callback provided to sync glob')\n    return globSync(pattern, options)\n  }\n\n  return new Glob(pattern, options, cb)\n}\n\nglob.sync = globSync\nvar GlobSync = glob.GlobSync = globSync.GlobSync\n\n// old api surface\nglob.glob = glob\n\nfunction extend (origin, add) {\n  if (add === null || typeof add !== 'object') {\n    return origin\n  }\n\n  var keys = Object.keys(add)\n  var i = keys.length\n  while (i--) {\n    origin[keys[i]] = add[keys[i]]\n  }\n  return origin\n}\n\nglob.hasMagic = function (pattern, options_) {\n  var options = extend({}, options_)\n  options.noprocess = true\n\n  var g = new Glob(pattern, options)\n  var set = g.minimatch.set\n\n  if (!pattern)\n    return false\n\n  if (set.length > 1)\n    return true\n\n  for (var j = 0; j < set[0].length; j++) {\n    if (typeof set[0][j] !== 'string')\n      return true\n  }\n\n  return false\n}\n\nglob.Glob = Glob\ninherits(Glob, EE)\nfunction Glob (pattern, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = null\n  }\n\n  if (options && options.sync) {\n    if (cb)\n      throw new TypeError('callback provided to sync glob')\n    return new GlobSync(pattern, options)\n  }\n\n  if (!(this instanceof Glob))\n    return new Glob(pattern, options, cb)\n\n  setopts(this, pattern, options)\n  this._didRealPath = false\n\n  // process each pattern in the minimatch set\n  var n = this.minimatch.set.length\n\n  // The matches are stored as {<filename>: true,...} so that\n  // duplicates are automagically pruned.\n  // Later, we do an Object.keys() on these.\n  // Keep them as a list so we can fill in when nonull is set.\n  this.matches = new Array(n)\n\n  if (typeof cb === 'function') {\n    cb = once(cb)\n    this.on('error', cb)\n    this.on('end', function (matches) {\n      cb(null, matches)\n    })\n  }\n\n  var self = this\n  this._processing = 0\n\n  this._emitQueue = []\n  this._processQueue = []\n  this.paused = false\n\n  if (this.noprocess)\n    return this\n\n  if (n === 0)\n    return done()\n\n  var sync = true\n  for (var i = 0; i < n; i ++) {\n    this._process(this.minimatch.set[i], i, false, done)\n  }\n  sync = false\n\n  function done () {\n    --self._processing\n    if (self._processing <= 0) {\n      if (sync) {\n        process.nextTick(function () {\n          self._finish()\n        })\n      } else {\n        self._finish()\n      }\n    }\n  }\n}\n\nGlob.prototype._finish = function () {\n  assert(this instanceof Glob)\n  if (this.aborted)\n    return\n\n  if (this.realpath && !this._didRealpath)\n    return this._realpath()\n\n  common.finish(this)\n  this.emit('end', this.found)\n}\n\nGlob.prototype._realpath = function () {\n  if (this._didRealpath)\n    return\n\n  this._didRealpath = true\n\n  var n = this.matches.length\n  if (n === 0)\n    return this._finish()\n\n  var self = this\n  for (var i = 0; i < this.matches.length; i++)\n    this._realpathSet(i, next)\n\n  function next () {\n    if (--n === 0)\n      self._finish()\n  }\n}\n\nGlob.prototype._realpathSet = function (index, cb) {\n  var matchset = this.matches[index]\n  if (!matchset)\n    return cb()\n\n  var found = Object.keys(matchset)\n  var self = this\n  var n = found.length\n\n  if (n === 0)\n    return cb()\n\n  var set = this.matches[index] = Object.create(null)\n  found.forEach(function (p, i) {\n    // If there's a problem with the stat, then it means that\n    // one or more of the links in the realpath couldn't be\n    // resolved.  just return the abs value in that case.\n    p = self._makeAbs(p)\n    rp.realpath(p, self.realpathCache, function (er, real) {\n      if (!er)\n        set[real] = true\n      else if (er.syscall === 'stat')\n        set[p] = true\n      else\n        self.emit('error', er) // srsly wtf right here\n\n      if (--n === 0) {\n        self.matches[index] = set\n        cb()\n      }\n    })\n  })\n}\n\nGlob.prototype._mark = function (p) {\n  return common.mark(this, p)\n}\n\nGlob.prototype._makeAbs = function (f) {\n  return common.makeAbs(this, f)\n}\n\nGlob.prototype.abort = function () {\n  this.aborted = true\n  this.emit('abort')\n}\n\nGlob.prototype.pause = function () {\n  if (!this.paused) {\n    this.paused = true\n    this.emit('pause')\n  }\n}\n\nGlob.prototype.resume = function () {\n  if (this.paused) {\n    this.emit('resume')\n    this.paused = false\n    if (this._emitQueue.length) {\n      var eq = this._emitQueue.slice(0)\n      this._emitQueue.length = 0\n      for (var i = 0; i < eq.length; i ++) {\n        var e = eq[i]\n        this._emitMatch(e[0], e[1])\n      }\n    }\n    if (this._processQueue.length) {\n      var pq = this._processQueue.slice(0)\n      this._processQueue.length = 0\n      for (var i = 0; i < pq.length; i ++) {\n        var p = pq[i]\n        this._processing--\n        this._process(p[0], p[1], p[2], p[3])\n      }\n    }\n  }\n}\n\nGlob.prototype._process = function (pattern, index, inGlobStar, cb) {\n  assert(this instanceof Glob)\n  assert(typeof cb === 'function')\n\n  if (this.aborted)\n    return\n\n  this._processing++\n  if (this.paused) {\n    this._processQueue.push([pattern, index, inGlobStar, cb])\n    return\n  }\n\n  //console.error('PROCESS %d', this._processing, pattern)\n\n  // Get the first [n] parts of pattern that are all strings.\n  var n = 0\n  while (typeof pattern[n] === 'string') {\n    n ++\n  }\n  // now n is the index of the first one that is *not* a string.\n\n  // see if there's anything else\n  var prefix\n  switch (n) {\n    // if not, then this is rather simple\n    case pattern.length:\n      this._processSimple(pattern.join('/'), index, cb)\n      return\n\n    case 0:\n      // pattern *starts* with some non-trivial item.\n      // going to readdir(cwd), but not include the prefix in matches.\n      prefix = null\n      break\n\n    default:\n      // pattern has some string bits in the front.\n      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n      // or 'relative' like '../baz'\n      prefix = pattern.slice(0, n).join('/')\n      break\n  }\n\n  var remain = pattern.slice(n)\n\n  // get the list of entries.\n  var read\n  if (prefix === null)\n    read = '.'\n  else if (isAbsolute(prefix) || isAbsolute(pattern.join('/'))) {\n    if (!prefix || !isAbsolute(prefix))\n      prefix = '/' + prefix\n    read = prefix\n  } else\n    read = prefix\n\n  var abs = this._makeAbs(read)\n\n  //if ignored, skip _processing\n  if (childrenIgnored(this, read))\n    return cb()\n\n  var isGlobStar = remain[0] === minimatch.GLOBSTAR\n  if (isGlobStar)\n    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar, cb)\n  else\n    this._processReaddir(prefix, read, abs, remain, index, inGlobStar, cb)\n}\n\nGlob.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n  var self = this\n  this._readdir(abs, inGlobStar, function (er, entries) {\n    return self._processReaddir2(prefix, read, abs, remain, index, inGlobStar, entries, cb)\n  })\n}\n\nGlob.prototype._processReaddir2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n\n  // if the abs isn't a dir, then nothing can match!\n  if (!entries)\n    return cb()\n\n  // It will only match dot entries if it starts with a dot, or if\n  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n  var pn = remain[0]\n  var negate = !!this.minimatch.negate\n  var rawGlob = pn._glob\n  var dotOk = this.dot || rawGlob.charAt(0) === '.'\n\n  var matchedEntries = []\n  for (var i = 0; i < entries.length; i++) {\n    var e = entries[i]\n    if (e.charAt(0) !== '.' || dotOk) {\n      var m\n      if (negate && !prefix) {\n        m = !e.match(pn)\n      } else {\n        m = e.match(pn)\n      }\n      if (m)\n        matchedEntries.push(e)\n    }\n  }\n\n  //console.error('prd2', prefix, entries, remain[0]._glob, matchedEntries)\n\n  var len = matchedEntries.length\n  // If there are no matched entries, then nothing matches.\n  if (len === 0)\n    return cb()\n\n  // if this is the last remaining pattern bit, then no need for\n  // an additional stat *unless* the user has specified mark or\n  // stat explicitly.  We know they exist, since readdir returned\n  // them.\n\n  if (remain.length === 1 && !this.mark && !this.stat) {\n    if (!this.matches[index])\n      this.matches[index] = Object.create(null)\n\n    for (var i = 0; i < len; i ++) {\n      var e = matchedEntries[i]\n      if (prefix) {\n        if (prefix !== '/')\n          e = prefix + '/' + e\n        else\n          e = prefix + e\n      }\n\n      if (e.charAt(0) === '/' && !this.nomount) {\n        e = path.join(this.root, e)\n      }\n      this._emitMatch(index, e)\n    }\n    // This was the last one, and no stats were needed\n    return cb()\n  }\n\n  // now test all matched entries as stand-ins for that part\n  // of the pattern.\n  remain.shift()\n  for (var i = 0; i < len; i ++) {\n    var e = matchedEntries[i]\n    var newPattern\n    if (prefix) {\n      if (prefix !== '/')\n        e = prefix + '/' + e\n      else\n        e = prefix + e\n    }\n    this._process([e].concat(remain), index, inGlobStar, cb)\n  }\n  cb()\n}\n\nGlob.prototype._emitMatch = function (index, e) {\n  if (this.aborted)\n    return\n\n  if (isIgnored(this, e))\n    return\n\n  if (this.paused) {\n    this._emitQueue.push([index, e])\n    return\n  }\n\n  var abs = isAbsolute(e) ? e : this._makeAbs(e)\n\n  if (this.mark)\n    e = this._mark(e)\n\n  if (this.absolute)\n    e = abs\n\n  if (this.matches[index][e])\n    return\n\n  if (this.nodir) {\n    var c = this.cache[abs]\n    if (c === 'DIR' || Array.isArray(c))\n      return\n  }\n\n  this.matches[index][e] = true\n\n  var st = this.statCache[abs]\n  if (st)\n    this.emit('stat', e, st)\n\n  this.emit('match', e)\n}\n\nGlob.prototype._readdirInGlobStar = function (abs, cb) {\n  if (this.aborted)\n    return\n\n  // follow all symlinked directories forever\n  // just proceed as if this is a non-globstar situation\n  if (this.follow)\n    return this._readdir(abs, false, cb)\n\n  var lstatkey = 'lstat\\0' + abs\n  var self = this\n  var lstatcb = inflight(lstatkey, lstatcb_)\n\n  if (lstatcb)\n    self.fs.lstat(abs, lstatcb)\n\n  function lstatcb_ (er, lstat) {\n    if (er && er.code === 'ENOENT')\n      return cb()\n\n    var isSym = lstat && lstat.isSymbolicLink()\n    self.symlinks[abs] = isSym\n\n    // If it's not a symlink or a dir, then it's definitely a regular file.\n    // don't bother doing a readdir in that case.\n    if (!isSym && lstat && !lstat.isDirectory()) {\n      self.cache[abs] = 'FILE'\n      cb()\n    } else\n      self._readdir(abs, false, cb)\n  }\n}\n\nGlob.prototype._readdir = function (abs, inGlobStar, cb) {\n  if (this.aborted)\n    return\n\n  cb = inflight('readdir\\0'+abs+'\\0'+inGlobStar, cb)\n  if (!cb)\n    return\n\n  //console.error('RD %j %j', +inGlobStar, abs)\n  if (inGlobStar && !ownProp(this.symlinks, abs))\n    return this._readdirInGlobStar(abs, cb)\n\n  if (ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n    if (!c || c === 'FILE')\n      return cb()\n\n    if (Array.isArray(c))\n      return cb(null, c)\n  }\n\n  var self = this\n  self.fs.readdir(abs, readdirCb(this, abs, cb))\n}\n\nfunction readdirCb (self, abs, cb) {\n  return function (er, entries) {\n    if (er)\n      self._readdirError(abs, er, cb)\n    else\n      self._readdirEntries(abs, entries, cb)\n  }\n}\n\nGlob.prototype._readdirEntries = function (abs, entries, cb) {\n  if (this.aborted)\n    return\n\n  // if we haven't asked to stat everything, then just\n  // assume that everything in there exists, so we can avoid\n  // having to stat it a second time.\n  if (!this.mark && !this.stat) {\n    for (var i = 0; i < entries.length; i ++) {\n      var e = entries[i]\n      if (abs === '/')\n        e = abs + e\n      else\n        e = abs + '/' + e\n      this.cache[e] = true\n    }\n  }\n\n  this.cache[abs] = entries\n  return cb(null, entries)\n}\n\nGlob.prototype._readdirError = function (f, er, cb) {\n  if (this.aborted)\n    return\n\n  // handle errors, and cache the information\n  switch (er.code) {\n    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n    case 'ENOTDIR': // totally normal. means it *does* exist.\n      var abs = this._makeAbs(f)\n      this.cache[abs] = 'FILE'\n      if (abs === this.cwdAbs) {\n        var error = new Error(er.code + ' invalid cwd ' + this.cwd)\n        error.path = this.cwd\n        error.code = er.code\n        this.emit('error', error)\n        this.abort()\n      }\n      break\n\n    case 'ENOENT': // not terribly unusual\n    case 'ELOOP':\n    case 'ENAMETOOLONG':\n    case 'UNKNOWN':\n      this.cache[this._makeAbs(f)] = false\n      break\n\n    default: // some unusual error.  Treat as failure.\n      this.cache[this._makeAbs(f)] = false\n      if (this.strict) {\n        this.emit('error', er)\n        // If the error is handled, then we abort\n        // if not, we threw out of here\n        this.abort()\n      }\n      if (!this.silent)\n        console.error('glob error', er)\n      break\n  }\n\n  return cb()\n}\n\nGlob.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n  var self = this\n  this._readdir(abs, inGlobStar, function (er, entries) {\n    self._processGlobStar2(prefix, read, abs, remain, index, inGlobStar, entries, cb)\n  })\n}\n\n\nGlob.prototype._processGlobStar2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n  //console.error('pgs2', prefix, remain[0], entries)\n\n  // no entries means not a dir, so it can never have matches\n  // foo.txt/** doesn't match foo.txt\n  if (!entries)\n    return cb()\n\n  // test without the globstar, and with every child both below\n  // and replacing the globstar.\n  var remainWithoutGlobStar = remain.slice(1)\n  var gspref = prefix ? [ prefix ] : []\n  var noGlobStar = gspref.concat(remainWithoutGlobStar)\n\n  // the noGlobStar pattern exits the inGlobStar state\n  this._process(noGlobStar, index, false, cb)\n\n  var isSym = this.symlinks[abs]\n  var len = entries.length\n\n  // If it's a symlink, and we're in a globstar, then stop\n  if (isSym && inGlobStar)\n    return cb()\n\n  for (var i = 0; i < len; i++) {\n    var e = entries[i]\n    if (e.charAt(0) === '.' && !this.dot)\n      continue\n\n    // these two cases enter the inGlobStar state\n    var instead = gspref.concat(entries[i], remainWithoutGlobStar)\n    this._process(instead, index, true, cb)\n\n    var below = gspref.concat(entries[i], remain)\n    this._process(below, index, true, cb)\n  }\n\n  cb()\n}\n\nGlob.prototype._processSimple = function (prefix, index, cb) {\n  // XXX review this.  Shouldn't it be doing the mounting etc\n  // before doing stat?  kinda weird?\n  var self = this\n  this._stat(prefix, function (er, exists) {\n    self._processSimple2(prefix, index, er, exists, cb)\n  })\n}\nGlob.prototype._processSimple2 = function (prefix, index, er, exists, cb) {\n\n  //console.error('ps2', prefix, exists)\n\n  if (!this.matches[index])\n    this.matches[index] = Object.create(null)\n\n  // If it doesn't exist, then just mark the lack of results\n  if (!exists)\n    return cb()\n\n  if (prefix && isAbsolute(prefix) && !this.nomount) {\n    var trail = /[\\/\\\\]$/.test(prefix)\n    if (prefix.charAt(0) === '/') {\n      prefix = path.join(this.root, prefix)\n    } else {\n      prefix = path.resolve(this.root, prefix)\n      if (trail)\n        prefix += '/'\n    }\n  }\n\n  if (process.platform === 'win32')\n    prefix = prefix.replace(/\\\\/g, '/')\n\n  // Mark this as a match\n  this._emitMatch(index, prefix)\n  cb()\n}\n\n// Returns either 'DIR', 'FILE', or false\nGlob.prototype._stat = function (f, cb) {\n  var abs = this._makeAbs(f)\n  var needDir = f.slice(-1) === '/'\n\n  if (f.length > this.maxLength)\n    return cb()\n\n  if (!this.stat && ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n\n    if (Array.isArray(c))\n      c = 'DIR'\n\n    // It exists, but maybe not how we need it\n    if (!needDir || c === 'DIR')\n      return cb(null, c)\n\n    if (needDir && c === 'FILE')\n      return cb()\n\n    // otherwise we have to stat, because maybe c=true\n    // if we know it exists, but not what it is.\n  }\n\n  var exists\n  var stat = this.statCache[abs]\n  if (stat !== undefined) {\n    if (stat === false)\n      return cb(null, stat)\n    else {\n      var type = stat.isDirectory() ? 'DIR' : 'FILE'\n      if (needDir && type === 'FILE')\n        return cb()\n      else\n        return cb(null, type, stat)\n    }\n  }\n\n  var self = this\n  var statcb = inflight('stat\\0' + abs, lstatcb_)\n  if (statcb)\n    self.fs.lstat(abs, statcb)\n\n  function lstatcb_ (er, lstat) {\n    if (lstat && lstat.isSymbolicLink()) {\n      // If it's a symlink, then treat it as the target, unless\n      // the target does not exist, then treat it as a file.\n      return self.fs.stat(abs, function (er, stat) {\n        if (er)\n          self._stat2(f, abs, null, lstat, cb)\n        else\n          self._stat2(f, abs, er, stat, cb)\n      })\n    } else {\n      self._stat2(f, abs, er, lstat, cb)\n    }\n  }\n}\n\nGlob.prototype._stat2 = function (f, abs, er, stat, cb) {\n  if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n    this.statCache[abs] = false\n    return cb()\n  }\n\n  var needDir = f.slice(-1) === '/'\n  this.statCache[abs] = stat\n\n  if (abs.slice(-1) === '/' && stat && !stat.isDirectory())\n    return cb(null, false, stat)\n\n  var c = true\n  if (stat)\n    c = stat.isDirectory() ? 'DIR' : 'FILE'\n  this.cache[abs] = this.cache[abs] || c\n\n  if (needDir && c === 'FILE')\n    return cb()\n\n  return cb(null, c, stat)\n}\n","module.exports = globSync\nglobSync.GlobSync = GlobSync\n\nvar rp = require('fs.realpath')\nvar minimatch = require('minimatch')\nvar Minimatch = minimatch.Minimatch\nvar Glob = require('./glob.js').Glob\nvar util = require('util')\nvar path = require('path')\nvar assert = require('assert')\nvar isAbsolute = require('path-is-absolute')\nvar common = require('./common.js')\nvar setopts = common.setopts\nvar ownProp = common.ownProp\nvar childrenIgnored = common.childrenIgnored\nvar isIgnored = common.isIgnored\n\nfunction globSync (pattern, options) {\n  if (typeof options === 'function' || arguments.length === 3)\n    throw new TypeError('callback provided to sync glob\\n'+\n                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n  return new GlobSync(pattern, options).found\n}\n\nfunction GlobSync (pattern, options) {\n  if (!pattern)\n    throw new Error('must provide pattern')\n\n  if (typeof options === 'function' || arguments.length === 3)\n    throw new TypeError('callback provided to sync glob\\n'+\n                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n  if (!(this instanceof GlobSync))\n    return new GlobSync(pattern, options)\n\n  setopts(this, pattern, options)\n\n  if (this.noprocess)\n    return this\n\n  var n = this.minimatch.set.length\n  this.matches = new Array(n)\n  for (var i = 0; i < n; i ++) {\n    this._process(this.minimatch.set[i], i, false)\n  }\n  this._finish()\n}\n\nGlobSync.prototype._finish = function () {\n  assert(this instanceof GlobSync)\n  if (this.realpath) {\n    var self = this\n    this.matches.forEach(function (matchset, index) {\n      var set = self.matches[index] = Object.create(null)\n      for (var p in matchset) {\n        try {\n          p = self._makeAbs(p)\n          var real = rp.realpathSync(p, self.realpathCache)\n          set[real] = true\n        } catch (er) {\n          if (er.syscall === 'stat')\n            set[self._makeAbs(p)] = true\n          else\n            throw er\n        }\n      }\n    })\n  }\n  common.finish(this)\n}\n\n\nGlobSync.prototype._process = function (pattern, index, inGlobStar) {\n  assert(this instanceof GlobSync)\n\n  // Get the first [n] parts of pattern that are all strings.\n  var n = 0\n  while (typeof pattern[n] === 'string') {\n    n ++\n  }\n  // now n is the index of the first one that is *not* a string.\n\n  // See if there's anything else\n  var prefix\n  switch (n) {\n    // if not, then this is rather simple\n    case pattern.length:\n      this._processSimple(pattern.join('/'), index)\n      return\n\n    case 0:\n      // pattern *starts* with some non-trivial item.\n      // going to readdir(cwd), but not include the prefix in matches.\n      prefix = null\n      break\n\n    default:\n      // pattern has some string bits in the front.\n      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n      // or 'relative' like '../baz'\n      prefix = pattern.slice(0, n).join('/')\n      break\n  }\n\n  var remain = pattern.slice(n)\n\n  // get the list of entries.\n  var read\n  if (prefix === null)\n    read = '.'\n  else if (isAbsolute(prefix) || isAbsolute(pattern.join('/'))) {\n    if (!prefix || !isAbsolute(prefix))\n      prefix = '/' + prefix\n    read = prefix\n  } else\n    read = prefix\n\n  var abs = this._makeAbs(read)\n\n  //if ignored, skip processing\n  if (childrenIgnored(this, read))\n    return\n\n  var isGlobStar = remain[0] === minimatch.GLOBSTAR\n  if (isGlobStar)\n    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar)\n  else\n    this._processReaddir(prefix, read, abs, remain, index, inGlobStar)\n}\n\n\nGlobSync.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar) {\n  var entries = this._readdir(abs, inGlobStar)\n\n  // if the abs isn't a dir, then nothing can match!\n  if (!entries)\n    return\n\n  // It will only match dot entries if it starts with a dot, or if\n  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n  var pn = remain[0]\n  var negate = !!this.minimatch.negate\n  var rawGlob = pn._glob\n  var dotOk = this.dot || rawGlob.charAt(0) === '.'\n\n  var matchedEntries = []\n  for (var i = 0; i < entries.length; i++) {\n    var e = entries[i]\n    if (e.charAt(0) !== '.' || dotOk) {\n      var m\n      if (negate && !prefix) {\n        m = !e.match(pn)\n      } else {\n        m = e.match(pn)\n      }\n      if (m)\n        matchedEntries.push(e)\n    }\n  }\n\n  var len = matchedEntries.length\n  // If there are no matched entries, then nothing matches.\n  if (len === 0)\n    return\n\n  // if this is the last remaining pattern bit, then no need for\n  // an additional stat *unless* the user has specified mark or\n  // stat explicitly.  We know they exist, since readdir returned\n  // them.\n\n  if (remain.length === 1 && !this.mark && !this.stat) {\n    if (!this.matches[index])\n      this.matches[index] = Object.create(null)\n\n    for (var i = 0; i < len; i ++) {\n      var e = matchedEntries[i]\n      if (prefix) {\n        if (prefix.slice(-1) !== '/')\n          e = prefix + '/' + e\n        else\n          e = prefix + e\n      }\n\n      if (e.charAt(0) === '/' && !this.nomount) {\n        e = path.join(this.root, e)\n      }\n      this._emitMatch(index, e)\n    }\n    // This was the last one, and no stats were needed\n    return\n  }\n\n  // now test all matched entries as stand-ins for that part\n  // of the pattern.\n  remain.shift()\n  for (var i = 0; i < len; i ++) {\n    var e = matchedEntries[i]\n    var newPattern\n    if (prefix)\n      newPattern = [prefix, e]\n    else\n      newPattern = [e]\n    this._process(newPattern.concat(remain), index, inGlobStar)\n  }\n}\n\n\nGlobSync.prototype._emitMatch = function (index, e) {\n  if (isIgnored(this, e))\n    return\n\n  var abs = this._makeAbs(e)\n\n  if (this.mark)\n    e = this._mark(e)\n\n  if (this.absolute) {\n    e = abs\n  }\n\n  if (this.matches[index][e])\n    return\n\n  if (this.nodir) {\n    var c = this.cache[abs]\n    if (c === 'DIR' || Array.isArray(c))\n      return\n  }\n\n  this.matches[index][e] = true\n\n  if (this.stat)\n    this._stat(e)\n}\n\n\nGlobSync.prototype._readdirInGlobStar = function (abs) {\n  // follow all symlinked directories forever\n  // just proceed as if this is a non-globstar situation\n  if (this.follow)\n    return this._readdir(abs, false)\n\n  var entries\n  var lstat\n  var stat\n  try {\n    lstat = this.fs.lstatSync(abs)\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      // lstat failed, doesn't exist\n      return null\n    }\n  }\n\n  var isSym = lstat && lstat.isSymbolicLink()\n  this.symlinks[abs] = isSym\n\n  // If it's not a symlink or a dir, then it's definitely a regular file.\n  // don't bother doing a readdir in that case.\n  if (!isSym && lstat && !lstat.isDirectory())\n    this.cache[abs] = 'FILE'\n  else\n    entries = this._readdir(abs, false)\n\n  return entries\n}\n\nGlobSync.prototype._readdir = function (abs, inGlobStar) {\n  var entries\n\n  if (inGlobStar && !ownProp(this.symlinks, abs))\n    return this._readdirInGlobStar(abs)\n\n  if (ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n    if (!c || c === 'FILE')\n      return null\n\n    if (Array.isArray(c))\n      return c\n  }\n\n  try {\n    return this._readdirEntries(abs, this.fs.readdirSync(abs))\n  } catch (er) {\n    this._readdirError(abs, er)\n    return null\n  }\n}\n\nGlobSync.prototype._readdirEntries = function (abs, entries) {\n  // if we haven't asked to stat everything, then just\n  // assume that everything in there exists, so we can avoid\n  // having to stat it a second time.\n  if (!this.mark && !this.stat) {\n    for (var i = 0; i < entries.length; i ++) {\n      var e = entries[i]\n      if (abs === '/')\n        e = abs + e\n      else\n        e = abs + '/' + e\n      this.cache[e] = true\n    }\n  }\n\n  this.cache[abs] = entries\n\n  // mark and cache dir-ness\n  return entries\n}\n\nGlobSync.prototype._readdirError = function (f, er) {\n  // handle errors, and cache the information\n  switch (er.code) {\n    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n    case 'ENOTDIR': // totally normal. means it *does* exist.\n      var abs = this._makeAbs(f)\n      this.cache[abs] = 'FILE'\n      if (abs === this.cwdAbs) {\n        var error = new Error(er.code + ' invalid cwd ' + this.cwd)\n        error.path = this.cwd\n        error.code = er.code\n        throw error\n      }\n      break\n\n    case 'ENOENT': // not terribly unusual\n    case 'ELOOP':\n    case 'ENAMETOOLONG':\n    case 'UNKNOWN':\n      this.cache[this._makeAbs(f)] = false\n      break\n\n    default: // some unusual error.  Treat as failure.\n      this.cache[this._makeAbs(f)] = false\n      if (this.strict)\n        throw er\n      if (!this.silent)\n        console.error('glob error', er)\n      break\n  }\n}\n\nGlobSync.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar) {\n\n  var entries = this._readdir(abs, inGlobStar)\n\n  // no entries means not a dir, so it can never have matches\n  // foo.txt/** doesn't match foo.txt\n  if (!entries)\n    return\n\n  // test without the globstar, and with every child both below\n  // and replacing the globstar.\n  var remainWithoutGlobStar = remain.slice(1)\n  var gspref = prefix ? [ prefix ] : []\n  var noGlobStar = gspref.concat(remainWithoutGlobStar)\n\n  // the noGlobStar pattern exits the inGlobStar state\n  this._process(noGlobStar, index, false)\n\n  var len = entries.length\n  var isSym = this.symlinks[abs]\n\n  // If it's a symlink, and we're in a globstar, then stop\n  if (isSym && inGlobStar)\n    return\n\n  for (var i = 0; i < len; i++) {\n    var e = entries[i]\n    if (e.charAt(0) === '.' && !this.dot)\n      continue\n\n    // these two cases enter the inGlobStar state\n    var instead = gspref.concat(entries[i], remainWithoutGlobStar)\n    this._process(instead, index, true)\n\n    var below = gspref.concat(entries[i], remain)\n    this._process(below, index, true)\n  }\n}\n\nGlobSync.prototype._processSimple = function (prefix, index) {\n  // XXX review this.  Shouldn't it be doing the mounting etc\n  // before doing stat?  kinda weird?\n  var exists = this._stat(prefix)\n\n  if (!this.matches[index])\n    this.matches[index] = Object.create(null)\n\n  // If it doesn't exist, then just mark the lack of results\n  if (!exists)\n    return\n\n  if (prefix && isAbsolute(prefix) && !this.nomount) {\n    var trail = /[\\/\\\\]$/.test(prefix)\n    if (prefix.charAt(0) === '/') {\n      prefix = path.join(this.root, prefix)\n    } else {\n      prefix = path.resolve(this.root, prefix)\n      if (trail)\n        prefix += '/'\n    }\n  }\n\n  if (process.platform === 'win32')\n    prefix = prefix.replace(/\\\\/g, '/')\n\n  // Mark this as a match\n  this._emitMatch(index, prefix)\n}\n\n// Returns either 'DIR', 'FILE', or false\nGlobSync.prototype._stat = function (f) {\n  var abs = this._makeAbs(f)\n  var needDir = f.slice(-1) === '/'\n\n  if (f.length > this.maxLength)\n    return false\n\n  if (!this.stat && ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n\n    if (Array.isArray(c))\n      c = 'DIR'\n\n    // It exists, but maybe not how we need it\n    if (!needDir || c === 'DIR')\n      return c\n\n    if (needDir && c === 'FILE')\n      return false\n\n    // otherwise we have to stat, because maybe c=true\n    // if we know it exists, but not what it is.\n  }\n\n  var exists\n  var stat = this.statCache[abs]\n  if (!stat) {\n    var lstat\n    try {\n      lstat = this.fs.lstatSync(abs)\n    } catch (er) {\n      if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n        this.statCache[abs] = false\n        return false\n      }\n    }\n\n    if (lstat && lstat.isSymbolicLink()) {\n      try {\n        stat = this.fs.statSync(abs)\n      } catch (er) {\n        stat = lstat\n      }\n    } else {\n      stat = lstat\n    }\n  }\n\n  this.statCache[abs] = stat\n\n  var c = true\n  if (stat)\n    c = stat.isDirectory() ? 'DIR' : 'FILE'\n\n  this.cache[abs] = this.cache[abs] || c\n\n  if (needDir && c === 'FILE')\n    return false\n\n  return c\n}\n\nGlobSync.prototype._mark = function (p) {\n  return common.mark(this, p)\n}\n\nGlobSync.prototype._makeAbs = function (f) {\n  return common.makeAbs(this, f)\n}\n","var wrappy = require('wrappy')\nvar reqs = Object.create(null)\nvar once = require('once')\n\nmodule.exports = wrappy(inflight)\n\nfunction inflight (key, cb) {\n  if (reqs[key]) {\n    reqs[key].push(cb)\n    return null\n  } else {\n    reqs[key] = [cb]\n    return makeres(key)\n  }\n}\n\nfunction makeres (key) {\n  return once(function RES () {\n    var cbs = reqs[key]\n    var len = cbs.length\n    var args = slice(arguments)\n\n    // XXX It's somewhat ambiguous whether a new callback added in this\n    // pass should be queued for later execution if something in the\n    // list of callbacks throws, or if it should just be discarded.\n    // However, it's such an edge case that it hardly matters, and either\n    // choice is likely as surprising as the other.\n    // As it happens, we do go ahead and schedule it for later execution.\n    try {\n      for (var i = 0; i < len; i++) {\n        cbs[i].apply(null, args)\n      }\n    } finally {\n      if (cbs.length > len) {\n        // added more in the interim.\n        // de-zalgo, just in case, but don't call again.\n        cbs.splice(0, len)\n        process.nextTick(function () {\n          RES.apply(null, args)\n        })\n      } else {\n        delete reqs[key]\n      }\n    }\n  })\n}\n\nfunction slice (args) {\n  var length = args.length\n  var array = []\n\n  for (var i = 0; i < length; i++) array[i] = args[i]\n  return array\n}\n","try {\n  var util = require('util');\n  /* istanbul ignore next */\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  /* istanbul ignore next */\n  module.exports = require('./inherits_browser.js');\n}\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n","module.exports = minimatch\nminimatch.Minimatch = Minimatch\n\nvar path = { sep: '/' }\ntry {\n  path = require('path')\n} catch (er) {}\n\nvar GLOBSTAR = minimatch.GLOBSTAR = Minimatch.GLOBSTAR = {}\nvar expand = require('brace-expansion')\n\nvar plTypes = {\n  '!': { open: '(?:(?!(?:', close: '))[^/]*?)'},\n  '?': { open: '(?:', close: ')?' },\n  '+': { open: '(?:', close: ')+' },\n  '*': { open: '(?:', close: ')*' },\n  '@': { open: '(?:', close: ')' }\n}\n\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nvar qmark = '[^/]'\n\n// * => any number of characters\nvar star = qmark + '*?'\n\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nvar twoStarDot = '(?:(?!(?:\\\\\\/|^)(?:\\\\.{1,2})($|\\\\\\/)).)*?'\n\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nvar twoStarNoDot = '(?:(?!(?:\\\\\\/|^)\\\\.).)*?'\n\n// characters that need to be escaped in RegExp.\nvar reSpecials = charSet('().*{}+?[]^$\\\\!')\n\n// \"abc\" -> { a:true, b:true, c:true }\nfunction charSet (s) {\n  return s.split('').reduce(function (set, c) {\n    set[c] = true\n    return set\n  }, {})\n}\n\n// normalizes slashes.\nvar slashSplit = /\\/+/\n\nminimatch.filter = filter\nfunction filter (pattern, options) {\n  options = options || {}\n  return function (p, i, list) {\n    return minimatch(p, pattern, options)\n  }\n}\n\nfunction ext (a, b) {\n  a = a || {}\n  b = b || {}\n  var t = {}\n  Object.keys(b).forEach(function (k) {\n    t[k] = b[k]\n  })\n  Object.keys(a).forEach(function (k) {\n    t[k] = a[k]\n  })\n  return t\n}\n\nminimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return minimatch\n\n  var orig = minimatch\n\n  var m = function minimatch (p, pattern, options) {\n    return orig.minimatch(p, pattern, ext(def, options))\n  }\n\n  m.Minimatch = function Minimatch (pattern, options) {\n    return new orig.Minimatch(pattern, ext(def, options))\n  }\n\n  return m\n}\n\nMinimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return Minimatch\n  return minimatch.defaults(def).Minimatch\n}\n\nfunction minimatch (p, pattern, options) {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n\n  // shortcut: comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false\n  }\n\n  // \"\" only matches \"\"\n  if (pattern.trim() === '') return p === ''\n\n  return new Minimatch(pattern, options).match(p)\n}\n\nfunction Minimatch (pattern, options) {\n  if (!(this instanceof Minimatch)) {\n    return new Minimatch(pattern, options)\n  }\n\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n  pattern = pattern.trim()\n\n  // windows support: need to use /, not \\\n  if (path.sep !== '/') {\n    pattern = pattern.split(path.sep).join('/')\n  }\n\n  this.options = options\n  this.set = []\n  this.pattern = pattern\n  this.regexp = null\n  this.negate = false\n  this.comment = false\n  this.empty = false\n\n  // make the set of regexps etc.\n  this.make()\n}\n\nMinimatch.prototype.debug = function () {}\n\nMinimatch.prototype.make = make\nfunction make () {\n  // don't do it more than once.\n  if (this._made) return\n\n  var pattern = this.pattern\n  var options = this.options\n\n  // empty patterns and comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    this.comment = true\n    return\n  }\n  if (!pattern) {\n    this.empty = true\n    return\n  }\n\n  // step 1: figure out negation, etc.\n  this.parseNegate()\n\n  // step 2: expand braces\n  var set = this.globSet = this.braceExpand()\n\n  if (options.debug) this.debug = console.error\n\n  this.debug(this.pattern, set)\n\n  // step 3: now we have a set, so turn each one into a series of path-portion\n  // matching patterns.\n  // These will be regexps, except in the case of \"**\", which is\n  // set to the GLOBSTAR object for globstar behavior,\n  // and will not contain any / characters\n  set = this.globParts = set.map(function (s) {\n    return s.split(slashSplit)\n  })\n\n  this.debug(this.pattern, set)\n\n  // glob --> regexps\n  set = set.map(function (s, si, set) {\n    return s.map(this.parse, this)\n  }, this)\n\n  this.debug(this.pattern, set)\n\n  // filter out everything that didn't compile properly.\n  set = set.filter(function (s) {\n    return s.indexOf(false) === -1\n  })\n\n  this.debug(this.pattern, set)\n\n  this.set = set\n}\n\nMinimatch.prototype.parseNegate = parseNegate\nfunction parseNegate () {\n  var pattern = this.pattern\n  var negate = false\n  var options = this.options\n  var negateOffset = 0\n\n  if (options.nonegate) return\n\n  for (var i = 0, l = pattern.length\n    ; i < l && pattern.charAt(i) === '!'\n    ; i++) {\n    negate = !negate\n    negateOffset++\n  }\n\n  if (negateOffset) this.pattern = pattern.substr(negateOffset)\n  this.negate = negate\n}\n\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nminimatch.braceExpand = function (pattern, options) {\n  return braceExpand(pattern, options)\n}\n\nMinimatch.prototype.braceExpand = braceExpand\n\nfunction braceExpand (pattern, options) {\n  if (!options) {\n    if (this instanceof Minimatch) {\n      options = this.options\n    } else {\n      options = {}\n    }\n  }\n\n  pattern = typeof pattern === 'undefined'\n    ? this.pattern : pattern\n\n  if (typeof pattern === 'undefined') {\n    throw new TypeError('undefined pattern')\n  }\n\n  if (options.nobrace ||\n    !pattern.match(/\\{.*\\}/)) {\n    // shortcut. no need to expand.\n    return [pattern]\n  }\n\n  return expand(pattern)\n}\n\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\nMinimatch.prototype.parse = parse\nvar SUBPARSE = {}\nfunction parse (pattern, isSub) {\n  if (pattern.length > 1024 * 64) {\n    throw new TypeError('pattern is too long')\n  }\n\n  var options = this.options\n\n  // shortcuts\n  if (!options.noglobstar && pattern === '**') return GLOBSTAR\n  if (pattern === '') return ''\n\n  var re = ''\n  var hasMagic = !!options.nocase\n  var escaping = false\n  // ? => one single character\n  var patternListStack = []\n  var negativeLists = []\n  var stateChar\n  var inClass = false\n  var reClassStart = -1\n  var classStart = -1\n  // . and .. never match anything that doesn't start with .,\n  // even when options.dot is set.\n  var patternStart = pattern.charAt(0) === '.' ? '' // anything\n  // not (start or / followed by . or .. followed by / or end)\n  : options.dot ? '(?!(?:^|\\\\\\/)\\\\.{1,2}(?:$|\\\\\\/))'\n  : '(?!\\\\.)'\n  var self = this\n\n  function clearStateChar () {\n    if (stateChar) {\n      // we had some state-tracking character\n      // that wasn't consumed by this pass.\n      switch (stateChar) {\n        case '*':\n          re += star\n          hasMagic = true\n        break\n        case '?':\n          re += qmark\n          hasMagic = true\n        break\n        default:\n          re += '\\\\' + stateChar\n        break\n      }\n      self.debug('clearStateChar %j %j', stateChar, re)\n      stateChar = false\n    }\n  }\n\n  for (var i = 0, len = pattern.length, c\n    ; (i < len) && (c = pattern.charAt(i))\n    ; i++) {\n    this.debug('%s\\t%s %s %j', pattern, i, re, c)\n\n    // skip over any that are escaped.\n    if (escaping && reSpecials[c]) {\n      re += '\\\\' + c\n      escaping = false\n      continue\n    }\n\n    switch (c) {\n      case '/':\n        // completely not allowed, even escaped.\n        // Should already be path-split by now.\n        return false\n\n      case '\\\\':\n        clearStateChar()\n        escaping = true\n      continue\n\n      // the various stateChar values\n      // for the \"extglob\" stuff.\n      case '?':\n      case '*':\n      case '+':\n      case '@':\n      case '!':\n        this.debug('%s\\t%s %s %j <-- stateChar', pattern, i, re, c)\n\n        // all of those are literals inside a class, except that\n        // the glob [!a] means [^a] in regexp\n        if (inClass) {\n          this.debug('  in class')\n          if (c === '!' && i === classStart + 1) c = '^'\n          re += c\n          continue\n        }\n\n        // if we already have a stateChar, then it means\n        // that there was something like ** or +? in there.\n        // Handle the stateChar, then proceed with this one.\n        self.debug('call clearStateChar %j', stateChar)\n        clearStateChar()\n        stateChar = c\n        // if extglob is disabled, then +(asdf|foo) isn't a thing.\n        // just clear the statechar *now*, rather than even diving into\n        // the patternList stuff.\n        if (options.noext) clearStateChar()\n      continue\n\n      case '(':\n        if (inClass) {\n          re += '('\n          continue\n        }\n\n        if (!stateChar) {\n          re += '\\\\('\n          continue\n        }\n\n        patternListStack.push({\n          type: stateChar,\n          start: i - 1,\n          reStart: re.length,\n          open: plTypes[stateChar].open,\n          close: plTypes[stateChar].close\n        })\n        // negation is (?:(?!js)[^/]*)\n        re += stateChar === '!' ? '(?:(?!(?:' : '(?:'\n        this.debug('plType %j %j', stateChar, re)\n        stateChar = false\n      continue\n\n      case ')':\n        if (inClass || !patternListStack.length) {\n          re += '\\\\)'\n          continue\n        }\n\n        clearStateChar()\n        hasMagic = true\n        var pl = patternListStack.pop()\n        // negation is (?:(?!js)[^/]*)\n        // The others are (?:<pattern>)<type>\n        re += pl.close\n        if (pl.type === '!') {\n          negativeLists.push(pl)\n        }\n        pl.reEnd = re.length\n      continue\n\n      case '|':\n        if (inClass || !patternListStack.length || escaping) {\n          re += '\\\\|'\n          escaping = false\n          continue\n        }\n\n        clearStateChar()\n        re += '|'\n      continue\n\n      // these are mostly the same in regexp and glob\n      case '[':\n        // swallow any state-tracking char before the [\n        clearStateChar()\n\n        if (inClass) {\n          re += '\\\\' + c\n          continue\n        }\n\n        inClass = true\n        classStart = i\n        reClassStart = re.length\n        re += c\n      continue\n\n      case ']':\n        //  a right bracket shall lose its special\n        //  meaning and represent itself in\n        //  a bracket expression if it occurs\n        //  first in the list.  -- POSIX.2 2.8.3.2\n        if (i === classStart + 1 || !inClass) {\n          re += '\\\\' + c\n          escaping = false\n          continue\n        }\n\n        // handle the case where we left a class open.\n        // \"[z-a]\" is valid, equivalent to \"\\[z-a\\]\"\n        if (inClass) {\n          // split where the last [ was, make sure we don't have\n          // an invalid re. if so, re-walk the contents of the\n          // would-be class to re-translate any characters that\n          // were passed through as-is\n          // TODO: It would probably be faster to determine this\n          // without a try/catch and a new RegExp, but it's tricky\n          // to do safely.  For now, this is safe and works.\n          var cs = pattern.substring(classStart + 1, i)\n          try {\n            RegExp('[' + cs + ']')\n          } catch (er) {\n            // not a valid class!\n            var sp = this.parse(cs, SUBPARSE)\n            re = re.substr(0, reClassStart) + '\\\\[' + sp[0] + '\\\\]'\n            hasMagic = hasMagic || sp[1]\n            inClass = false\n            continue\n          }\n        }\n\n        // finish up the class.\n        hasMagic = true\n        inClass = false\n        re += c\n      continue\n\n      default:\n        // swallow any state char that wasn't consumed\n        clearStateChar()\n\n        if (escaping) {\n          // no need\n          escaping = false\n        } else if (reSpecials[c]\n          && !(c === '^' && inClass)) {\n          re += '\\\\'\n        }\n\n        re += c\n\n    } // switch\n  } // for\n\n  // handle the case where we left a class open.\n  // \"[abc\" is valid, equivalent to \"\\[abc\"\n  if (inClass) {\n    // split where the last [ was, and escape it\n    // this is a huge pita.  We now have to re-walk\n    // the contents of the would-be class to re-translate\n    // any characters that were passed through as-is\n    cs = pattern.substr(classStart + 1)\n    sp = this.parse(cs, SUBPARSE)\n    re = re.substr(0, reClassStart) + '\\\\[' + sp[0]\n    hasMagic = hasMagic || sp[1]\n  }\n\n  // handle the case where we had a +( thing at the *end*\n  // of the pattern.\n  // each pattern list stack adds 3 chars, and we need to go through\n  // and escape any | chars that were passed through as-is for the regexp.\n  // Go through and escape them, taking care not to double-escape any\n  // | chars that were already escaped.\n  for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {\n    var tail = re.slice(pl.reStart + pl.open.length)\n    this.debug('setting tail', re, pl)\n    // maybe some even number of \\, then maybe 1 \\, followed by a |\n    tail = tail.replace(/((?:\\\\{2}){0,64})(\\\\?)\\|/g, function (_, $1, $2) {\n      if (!$2) {\n        // the | isn't already escaped, so escape it.\n        $2 = '\\\\'\n      }\n\n      // need to escape all those slashes *again*, without escaping the\n      // one that we need for escaping the | character.  As it works out,\n      // escaping an even number of slashes can be done by simply repeating\n      // it exactly after itself.  That's why this trick works.\n      //\n      // I am sorry that you have to see this.\n      return $1 + $1 + $2 + '|'\n    })\n\n    this.debug('tail=%j\\n   %s', tail, tail, pl, re)\n    var t = pl.type === '*' ? star\n      : pl.type === '?' ? qmark\n      : '\\\\' + pl.type\n\n    hasMagic = true\n    re = re.slice(0, pl.reStart) + t + '\\\\(' + tail\n  }\n\n  // handle trailing things that only matter at the very end.\n  clearStateChar()\n  if (escaping) {\n    // trailing \\\\\n    re += '\\\\\\\\'\n  }\n\n  // only need to apply the nodot start if the re starts with\n  // something that could conceivably capture a dot\n  var addPatternStart = false\n  switch (re.charAt(0)) {\n    case '.':\n    case '[':\n    case '(': addPatternStart = true\n  }\n\n  // Hack to work around lack of negative lookbehind in JS\n  // A pattern like: *.!(x).!(y|z) needs to ensure that a name\n  // like 'a.xyz.yz' doesn't match.  So, the first negative\n  // lookahead, has to look ALL the way ahead, to the end of\n  // the pattern.\n  for (var n = negativeLists.length - 1; n > -1; n--) {\n    var nl = negativeLists[n]\n\n    var nlBefore = re.slice(0, nl.reStart)\n    var nlFirst = re.slice(nl.reStart, nl.reEnd - 8)\n    var nlLast = re.slice(nl.reEnd - 8, nl.reEnd)\n    var nlAfter = re.slice(nl.reEnd)\n\n    nlLast += nlAfter\n\n    // Handle nested stuff like *(*.js|!(*.json)), where open parens\n    // mean that we should *not* include the ) in the bit that is considered\n    // \"after\" the negated section.\n    var openParensBefore = nlBefore.split('(').length - 1\n    var cleanAfter = nlAfter\n    for (i = 0; i < openParensBefore; i++) {\n      cleanAfter = cleanAfter.replace(/\\)[+*?]?/, '')\n    }\n    nlAfter = cleanAfter\n\n    var dollar = ''\n    if (nlAfter === '' && isSub !== SUBPARSE) {\n      dollar = '$'\n    }\n    var newRe = nlBefore + nlFirst + nlAfter + dollar + nlLast\n    re = newRe\n  }\n\n  // if the re is not \"\" at this point, then we need to make sure\n  // it doesn't match against an empty path part.\n  // Otherwise a/* will match a/, which it should not.\n  if (re !== '' && hasMagic) {\n    re = '(?=.)' + re\n  }\n\n  if (addPatternStart) {\n    re = patternStart + re\n  }\n\n  // parsing just a piece of a larger pattern.\n  if (isSub === SUBPARSE) {\n    return [re, hasMagic]\n  }\n\n  // skip the regexp for non-magical patterns\n  // unescape anything in it, though, so that it'll be\n  // an exact match against a file etc.\n  if (!hasMagic) {\n    return globUnescape(pattern)\n  }\n\n  var flags = options.nocase ? 'i' : ''\n  try {\n    var regExp = new RegExp('^' + re + '$', flags)\n  } catch (er) {\n    // If it was an invalid regular expression, then it can't match\n    // anything.  This trick looks for a character after the end of\n    // the string, which is of course impossible, except in multi-line\n    // mode, but it's not a /m regex.\n    return new RegExp('$.')\n  }\n\n  regExp._glob = pattern\n  regExp._src = re\n\n  return regExp\n}\n\nminimatch.makeRe = function (pattern, options) {\n  return new Minimatch(pattern, options || {}).makeRe()\n}\n\nMinimatch.prototype.makeRe = makeRe\nfunction makeRe () {\n  if (this.regexp || this.regexp === false) return this.regexp\n\n  // at this point, this.set is a 2d array of partial\n  // pattern strings, or \"**\".\n  //\n  // It's better to use .match().  This function shouldn't\n  // be used, really, but it's pretty convenient sometimes,\n  // when you just want to work with a regex.\n  var set = this.set\n\n  if (!set.length) {\n    this.regexp = false\n    return this.regexp\n  }\n  var options = this.options\n\n  var twoStar = options.noglobstar ? star\n    : options.dot ? twoStarDot\n    : twoStarNoDot\n  var flags = options.nocase ? 'i' : ''\n\n  var re = set.map(function (pattern) {\n    return pattern.map(function (p) {\n      return (p === GLOBSTAR) ? twoStar\n      : (typeof p === 'string') ? regExpEscape(p)\n      : p._src\n    }).join('\\\\\\/')\n  }).join('|')\n\n  // must match entire pattern\n  // ending in a * or ** will make it less strict.\n  re = '^(?:' + re + ')$'\n\n  // can match anything, as long as it's not this.\n  if (this.negate) re = '^(?!' + re + ').*$'\n\n  try {\n    this.regexp = new RegExp(re, flags)\n  } catch (ex) {\n    this.regexp = false\n  }\n  return this.regexp\n}\n\nminimatch.match = function (list, pattern, options) {\n  options = options || {}\n  var mm = new Minimatch(pattern, options)\n  list = list.filter(function (f) {\n    return mm.match(f)\n  })\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern)\n  }\n  return list\n}\n\nMinimatch.prototype.match = match\nfunction match (f, partial) {\n  this.debug('match', f, this.pattern)\n  // short-circuit in the case of busted things.\n  // comments, etc.\n  if (this.comment) return false\n  if (this.empty) return f === ''\n\n  if (f === '/' && partial) return true\n\n  var options = this.options\n\n  // windows: need to use /, not \\\n  if (path.sep !== '/') {\n    f = f.split(path.sep).join('/')\n  }\n\n  // treat the test path as a set of pathparts.\n  f = f.split(slashSplit)\n  this.debug(this.pattern, 'split', f)\n\n  // just ONE of the pattern sets in this.set needs to match\n  // in order for it to be valid.  If negating, then just one\n  // match means that we have failed.\n  // Either way, return on the first hit.\n\n  var set = this.set\n  this.debug(this.pattern, 'set', set)\n\n  // Find the basename of the path by looking for the last non-empty segment\n  var filename\n  var i\n  for (i = f.length - 1; i >= 0; i--) {\n    filename = f[i]\n    if (filename) break\n  }\n\n  for (i = 0; i < set.length; i++) {\n    var pattern = set[i]\n    var file = f\n    if (options.matchBase && pattern.length === 1) {\n      file = [filename]\n    }\n    var hit = this.matchOne(file, pattern, partial)\n    if (hit) {\n      if (options.flipNegate) return true\n      return !this.negate\n    }\n  }\n\n  // didn't get any hits.  this is success if it's a negative\n  // pattern, failure otherwise.\n  if (options.flipNegate) return false\n  return this.negate\n}\n\n// set partial to true to test if, for example,\n// \"/a/b\" matches the start of \"/*/b/*/d\"\n// Partial means, if you run out of file before you run\n// out of pattern, then that's fine, as long as all\n// the parts match.\nMinimatch.prototype.matchOne = function (file, pattern, partial) {\n  var options = this.options\n\n  this.debug('matchOne',\n    { 'this': this, file: file, pattern: pattern })\n\n  this.debug('matchOne', file.length, pattern.length)\n\n  for (var fi = 0,\n      pi = 0,\n      fl = file.length,\n      pl = pattern.length\n      ; (fi < fl) && (pi < pl)\n      ; fi++, pi++) {\n    this.debug('matchOne loop')\n    var p = pattern[pi]\n    var f = file[fi]\n\n    this.debug(pattern, p, f)\n\n    // should be impossible.\n    // some invalid regexp stuff in the set.\n    if (p === false) return false\n\n    if (p === GLOBSTAR) {\n      this.debug('GLOBSTAR', [pattern, p, f])\n\n      // \"**\"\n      // a/**/b/**/c would match the following:\n      // a/b/x/y/z/c\n      // a/x/y/z/b/c\n      // a/b/x/b/x/c\n      // a/b/c\n      // To do this, take the rest of the pattern after\n      // the **, and see if it would match the file remainder.\n      // If so, return success.\n      // If not, the ** \"swallows\" a segment, and try again.\n      // This is recursively awful.\n      //\n      // a/**/b/**/c matching a/b/x/y/z/c\n      // - a matches a\n      // - doublestar\n      //   - matchOne(b/x/y/z/c, b/**/c)\n      //     - b matches b\n      //     - doublestar\n      //       - matchOne(x/y/z/c, c) -> no\n      //       - matchOne(y/z/c, c) -> no\n      //       - matchOne(z/c, c) -> no\n      //       - matchOne(c, c) yes, hit\n      var fr = fi\n      var pr = pi + 1\n      if (pr === pl) {\n        this.debug('** at the end')\n        // a ** at the end will just swallow the rest.\n        // We have found a match.\n        // however, it will not swallow /.x, unless\n        // options.dot is set.\n        // . and .. are *never* matched by **, for explosively\n        // exponential reasons.\n        for (; fi < fl; fi++) {\n          if (file[fi] === '.' || file[fi] === '..' ||\n            (!options.dot && file[fi].charAt(0) === '.')) return false\n        }\n        return true\n      }\n\n      // ok, let's see if we can swallow whatever we can.\n      while (fr < fl) {\n        var swallowee = file[fr]\n\n        this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee)\n\n        // XXX remove this slice.  Just pass the start index.\n        if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n          this.debug('globstar found match!', fr, fl, swallowee)\n          // found a match.\n          return true\n        } else {\n          // can't swallow \".\" or \"..\" ever.\n          // can only swallow \".foo\" when explicitly asked.\n          if (swallowee === '.' || swallowee === '..' ||\n            (!options.dot && swallowee.charAt(0) === '.')) {\n            this.debug('dot detected!', file, fr, pattern, pr)\n            break\n          }\n\n          // ** swallows a segment, and continue.\n          this.debug('globstar swallow a segment, and continue')\n          fr++\n        }\n      }\n\n      // no match was found.\n      // However, in partial mode, we can't say this is necessarily over.\n      // If there's more *pattern* left, then\n      if (partial) {\n        // ran out of file\n        this.debug('\\n>>> no match, partial?', file, fr, pattern, pr)\n        if (fr === fl) return true\n      }\n      return false\n    }\n\n    // something other than **\n    // non-magic patterns just have to match exactly\n    // patterns with magic have been turned into regexps.\n    var hit\n    if (typeof p === 'string') {\n      if (options.nocase) {\n        hit = f.toLowerCase() === p.toLowerCase()\n      } else {\n        hit = f === p\n      }\n      this.debug('string match', p, f, hit)\n    } else {\n      hit = f.match(p)\n      this.debug('pattern match', p, f, hit)\n    }\n\n    if (!hit) return false\n  }\n\n  // Note: ending in / means that we'll get a final \"\"\n  // at the end of the pattern.  This can only match a\n  // corresponding \"\" at the end of the file.\n  // If the file ends in /, then it can only match a\n  // a pattern that ends in /, unless the pattern just\n  // doesn't have any more for it. But, a/b/ should *not*\n  // match \"a/b/*\", even though \"\" matches against the\n  // [^/]*? pattern, except in partial mode, where it might\n  // simply not be reached yet.\n  // However, a/b/ should still satisfy a/*\n\n  // now either we fell off the end of the pattern, or we're done.\n  if (fi === fl && pi === pl) {\n    // ran out of pattern and filename at the same time.\n    // an exact hit!\n    return true\n  } else if (fi === fl) {\n    // ran out of file, but still had pattern left.\n    // this is ok if we're doing the match as part of\n    // a glob fs traversal.\n    return partial\n  } else if (pi === pl) {\n    // ran out of pattern, still have file left.\n    // this is only acceptable if we're on the very last\n    // empty segment of a file with a trailing slash.\n    // a/* should match a/b/\n    var emptyFileEnd = (fi === fl - 1) && (file[fi] === '')\n    return emptyFileEnd\n  }\n\n  // should be unreachable.\n  throw new Error('wtf?')\n}\n\n// replace stuff like \\* with *\nfunction globUnescape (s) {\n  return s.replace(/\\\\(.)/g, '$1')\n}\n\nfunction regExpEscape (s) {\n  return s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\n}\n","\n// TODO (jimmywarting): in the feature use conditional loading with top level await (requires 14.x)\n// Node has recently added whatwg stream into core\n\nimport './streams.cjs';\n\n/** @typedef {import('buffer').Blob} NodeBlob} */\n\n// 64 KiB (same size chrome slice theirs blob into Uint8array's)\nconst POOL_SIZE = 65536;\n\n/** @param {(Blob | NodeBlob | Uint8Array)[]} parts */\nasync function * toIterator (parts, clone = true) {\n\tfor (let part of parts) {\n\t\tif ('stream' in part) {\n\t\t\tyield * part.stream();\n\t\t} else if (ArrayBuffer.isView(part)) {\n\t\t\tif (clone) {\n\t\t\t\tlet position = part.byteOffset;\n\t\t\t\tlet end = part.byteOffset + part.byteLength;\n\t\t\t\twhile (position !== end) {\n\t\t\t\t\tconst size = Math.min(end - position, POOL_SIZE);\n\t\t\t\t\tconst chunk = part.buffer.slice(position, position + size);\n\t\t\t\t\tposition += chunk.byteLength;\n\t\t\t\t\tyield new Uint8Array(chunk);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tyield part;\n\t\t\t}\n\t\t} else {\n\t\t\t/* c8 ignore start */\n\t\t\t// For blobs that have arrayBuffer but no stream method (nodes buffer.Blob)\n\t\t\tlet position = 0;\n\t\t\twhile (position !== part.size) {\n\t\t\t\tconst chunk = part.slice(position, Math.min(part.size, position + POOL_SIZE));\n\t\t\t\tconst buffer = await chunk.arrayBuffer();\n\t\t\t\tposition += buffer.byteLength;\n\t\t\t\tyield new Uint8Array(buffer);\n\t\t\t}\n\t\t\t/* c8 ignore end */\n\t\t}\n\t}\n}\n\nconst _Blob = class Blob {\n\n\t/** @type {Array.<(Blob|Uint8Array)>} */\n\t#parts = [];\n\t#type = '';\n\t#size = 0;\n\n\t/**\n\t * The Blob() constructor returns a new Blob object. The content\n\t * of the blob consists of the concatenation of the values given\n\t * in the parameter array.\n\t *\n\t * @param {*} blobParts\n\t * @param {{ type?: string }} [options]\n\t */\n\tconstructor(blobParts = [], options = {}) {\n\t\tlet size = 0;\n\n\t\tconst parts = blobParts.map(element => {\n\t\t\tlet part;\n\t\t\tif (ArrayBuffer.isView(element)) {\n\t\t\t\tpart = new Uint8Array(element.buffer.slice(element.byteOffset, element.byteOffset + element.byteLength));\n\t\t\t} else if (element instanceof ArrayBuffer) {\n\t\t\t\tpart = new Uint8Array(element.slice(0));\n\t\t\t} else if (element instanceof Blob) {\n\t\t\t\tpart = element;\n\t\t\t} else {\n\t\t\t\tpart = new TextEncoder().encode(element);\n\t\t\t}\n\n\t\t\tsize += ArrayBuffer.isView(part) ? part.byteLength : part.size;\n\t\t\treturn part;\n\t\t});\n\n\t\tconst type = options.type === undefined ? '' : String(options.type);\n\n\t\tthis.#type = /[^\\u0020-\\u007E]/.test(type) ? '' : type;\n\t\tthis.#size = size;\n\t\tthis.#parts = parts;\n\t}\n\n\t/**\n\t * The Blob interface's size property returns the\n\t * size of the Blob in bytes.\n\t */\n\tget size() {\n\t\treturn this.#size;\n\t}\n\n\t/**\n\t * The type property of a Blob object returns the MIME type of the file.\n\t */\n\tget type() {\n\t\treturn this.#type;\n\t}\n\n\t/**\n\t * The text() method in the Blob interface returns a Promise\n\t * that resolves with a string containing the contents of\n\t * the blob, interpreted as UTF-8.\n\t *\n\t * @return {Promise<string>}\n\t */\n\tasync text() {\n\t\t// More optimized than using this.arrayBuffer()\n\t\t// that requires twice as much ram\n\t\tconst decoder = new TextDecoder();\n\t\tlet str = '';\n\t\tfor await (let part of toIterator(this.#parts, false)) {\n\t\t\tstr += decoder.decode(part, { stream: true });\n\t\t}\n\t\t// Remaining\n\t\tstr += decoder.decode();\n\t\treturn str;\n\t}\n\n\t/**\n\t * The arrayBuffer() method in the Blob interface returns a\n\t * Promise that resolves with the contents of the blob as\n\t * binary data contained in an ArrayBuffer.\n\t *\n\t * @return {Promise<ArrayBuffer>}\n\t */\n\tasync arrayBuffer() {\n\t\t// Easier way... Just a unnecessary overhead\n\t\t// const view = new Uint8Array(this.size);\n\t\t// await this.stream().getReader({mode: 'byob'}).read(view);\n\t\t// return view.buffer;\n\n\t\tconst data = new Uint8Array(this.size);\n\t\tlet offset = 0;\n\t\tfor await (const chunk of toIterator(this.#parts, false)) {\n\t\t\tdata.set(chunk, offset);\n\t\t\toffset += chunk.length;\n\t\t}\n\n\t\treturn data.buffer;\n\t}\n\n\tstream() {\n\t\tconst it = toIterator(this.#parts, true);\n\n\t\treturn new ReadableStream({\n\t\t\ttype: 'bytes',\n\t\t\tasync pull(ctrl) {\n\t\t\t\tconst chunk = await it.next();\n\t\t\t\tchunk.done ? ctrl.close() : ctrl.enqueue(chunk.value);\n\t\t\t}\n\t\t})\n\t}\n\n\t/**\n\t * The Blob interface's slice() method creates and returns a\n\t * new Blob object which contains data from a subset of the\n\t * blob on which it's called.\n\t *\n\t * @param {number} [start]\n\t * @param {number} [end]\n\t * @param {string} [type]\n\t */\n\tslice(start = 0, end = this.size, type = '') {\n\t\tconst {size} = this;\n\n\t\tlet relativeStart = start < 0 ? Math.max(size + start, 0) : Math.min(start, size);\n\t\tlet relativeEnd = end < 0 ? Math.max(size + end, 0) : Math.min(end, size);\n\n\t\tconst span = Math.max(relativeEnd - relativeStart, 0);\n\t\tconst parts = this.#parts;\n\t\tconst blobParts = [];\n\t\tlet added = 0;\n\n\t\tfor (const part of parts) {\n\t\t\t// don't add the overflow to new blobParts\n\t\t\tif (added >= span) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tconst size = ArrayBuffer.isView(part) ? part.byteLength : part.size;\n\t\t\tif (relativeStart && size <= relativeStart) {\n\t\t\t\t// Skip the beginning and change the relative\n\t\t\t\t// start & end position as we skip the unwanted parts\n\t\t\t\trelativeStart -= size;\n\t\t\t\trelativeEnd -= size;\n\t\t\t} else {\n\t\t\t\tlet chunk\n\t\t\t\tif (ArrayBuffer.isView(part)) {\n\t\t\t\t\tchunk = part.subarray(relativeStart, Math.min(size, relativeEnd));\n\t\t\t\t\tadded += chunk.byteLength\n\t\t\t\t} else {\n\t\t\t\t\tchunk = part.slice(relativeStart, Math.min(size, relativeEnd));\n\t\t\t\t\tadded += chunk.size\n\t\t\t\t}\n\t\t\t\tblobParts.push(chunk);\n\t\t\t\trelativeStart = 0; // All next sequential parts should start at 0\n\t\t\t}\n\t\t}\n\n\t\tconst blob = new Blob([], {type: String(type).toLowerCase()});\n\t\tblob.#size = span;\n\t\tblob.#parts = blobParts;\n\n\t\treturn blob;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Blob';\n\t}\n\n\tstatic [Symbol.hasInstance](object) {\n\t\treturn (\n\t\t\tobject &&\n\t\t\ttypeof object === 'object' &&\n\t\t\ttypeof object.constructor === 'function' &&\n\t\t\t(\n\t\t\t\ttypeof object.stream === 'function' ||\n\t\t\t\ttypeof object.arrayBuffer === 'function'\n\t\t\t) &&\n\t\t\t/^(Blob|File)$/.test(object[Symbol.toStringTag])\n\t\t);\n\t}\n}\n\nObject.defineProperties(_Blob.prototype, {\n\tsize: {enumerable: true},\n\ttype: {enumerable: true},\n\tslice: {enumerable: true}\n});\n\n/** @type {typeof globalThis.Blob} */\nexport const Blob = _Blob;\nexport default Blob;\n","export class FetchBaseError extends Error {\n\tconstructor(message, type) {\n\t\tsuper(message);\n\t\t// Hide custom error implementation details from end-users\n\t\tError.captureStackTrace(this, this.constructor);\n\n\t\tthis.type = type;\n\t}\n\n\tget name() {\n\t\treturn this.constructor.name;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n}\n","\nimport {FetchBaseError} from './base.js';\n\n/**\n * @typedef {{ address?: string, code: string, dest?: string, errno: number, info?: object, message: string, path?: string, port?: number, syscall: string}} SystemError\n*/\n\n/**\n * FetchError interface for operational errors\n */\nexport class FetchError extends FetchBaseError {\n\t/**\n\t * @param  {string} message -      Error message for human\n\t * @param  {string} [type] -        Error type for machine\n\t * @param  {SystemError} [systemError] - For Node.js system error\n\t */\n\tconstructor(message, type, systemError) {\n\t\tsuper(message, type);\n\t\t// When err.type is `system`, err.erroredSysCall contains system error and err.code contains system error code\n\t\tif (systemError) {\n\t\t\t// eslint-disable-next-line no-multi-assign\n\t\t\tthis.code = this.errno = systemError.code;\n\t\t\tthis.erroredSysCall = systemError.syscall;\n\t\t}\n\t}\n}\n","/**\n * Is.js\n *\n * Object type checks.\n */\n\nconst NAME = Symbol.toStringTag;\n\n/**\n * Check if `obj` is a URLSearchParams object\n * ref: https://github.com/node-fetch/node-fetch/issues/296#issuecomment-307598143\n *\n * @param  {*} obj\n * @return {boolean}\n */\nexport const isURLSearchParameters = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.append === 'function' &&\n\t\ttypeof object.delete === 'function' &&\n\t\ttypeof object.get === 'function' &&\n\t\ttypeof object.getAll === 'function' &&\n\t\ttypeof object.has === 'function' &&\n\t\ttypeof object.set === 'function' &&\n\t\ttypeof object.sort === 'function' &&\n\t\tobject[NAME] === 'URLSearchParams'\n\t);\n};\n\n/**\n * Check if `object` is a W3C `Blob` object (which `File` inherits from)\n *\n * @param  {*} obj\n * @return {boolean}\n */\nexport const isBlob = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.arrayBuffer === 'function' &&\n\t\ttypeof object.type === 'string' &&\n\t\ttypeof object.stream === 'function' &&\n\t\ttypeof object.constructor === 'function' &&\n\t\t/^(Blob|File)$/.test(object[NAME])\n\t);\n};\n\n/**\n * Check if `obj` is a spec-compliant `FormData` object\n *\n * @param {*} object\n * @return {boolean}\n */\nexport function isFormData(object) {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.append === 'function' &&\n\t\ttypeof object.set === 'function' &&\n\t\ttypeof object.get === 'function' &&\n\t\ttypeof object.getAll === 'function' &&\n\t\ttypeof object.delete === 'function' &&\n\t\ttypeof object.keys === 'function' &&\n\t\ttypeof object.values === 'function' &&\n\t\ttypeof object.entries === 'function' &&\n\t\ttypeof object.constructor === 'function' &&\n\t\tobject[NAME] === 'FormData'\n\t);\n}\n\n/**\n * Check if `obj` is an instance of AbortSignal.\n *\n * @param  {*} obj\n * @return {boolean}\n */\nexport const isAbortSignal = object => {\n\treturn (\n\t\ttypeof object === 'object' && (\n\t\t\tobject[NAME] === 'AbortSignal' ||\n\t\t\tobject[NAME] === 'EventTarget'\n\t\t)\n\t);\n};\n\n","import {randomBytes} from 'crypto';\n\nimport {isBlob} from './is.js';\n\nconst carriage = '\\r\\n';\nconst dashes = '-'.repeat(2);\nconst carriageLength = Buffer.byteLength(carriage);\n\n/**\n * @param {string} boundary\n */\nconst getFooter = boundary => `${dashes}${boundary}${dashes}${carriage.repeat(2)}`;\n\n/**\n * @param {string} boundary\n * @param {string} name\n * @param {*} field\n *\n * @return {string}\n */\nfunction getHeader(boundary, name, field) {\n\tlet header = '';\n\n\theader += `${dashes}${boundary}${carriage}`;\n\theader += `Content-Disposition: form-data; name=\"${name}\"`;\n\n\tif (isBlob(field)) {\n\t\theader += `; filename=\"${field.name}\"${carriage}`;\n\t\theader += `Content-Type: ${field.type || 'application/octet-stream'}`;\n\t}\n\n\treturn `${header}${carriage.repeat(2)}`;\n}\n\n/**\n * @return {string}\n */\nexport const getBoundary = () => randomBytes(8).toString('hex');\n\n/**\n * @param {FormData} form\n * @param {string} boundary\n */\nexport async function * formDataIterator(form, boundary) {\n\tfor (const [name, value] of form) {\n\t\tyield getHeader(boundary, name, value);\n\n\t\tif (isBlob(value)) {\n\t\t\tyield * value.stream();\n\t\t} else {\n\t\t\tyield value;\n\t\t}\n\n\t\tyield carriage;\n\t}\n\n\tyield getFooter(boundary);\n}\n\n/**\n * @param {FormData} form\n * @param {string} boundary\n */\nexport function getFormDataLength(form, boundary) {\n\tlet length = 0;\n\n\tfor (const [name, value] of form) {\n\t\tlength += Buffer.byteLength(getHeader(boundary, name, value));\n\n\t\tlength += isBlob(value) ? value.size : Buffer.byteLength(String(value));\n\n\t\tlength += carriageLength;\n\t}\n\n\tlength += Buffer.byteLength(getFooter(boundary));\n\n\treturn length;\n}\n","\n/**\n * Body.js\n *\n * Body interface provides common methods for Request and Response\n */\n\nimport Stream, {PassThrough} from 'stream';\nimport {types} from 'util';\n\nimport Blob from 'fetch-blob';\n\nimport {FetchError} from './errors/fetch-error.js';\nimport {FetchBaseError} from './errors/base.js';\nimport {formDataIterator, getBoundary, getFormDataLength} from './utils/form-data.js';\nimport {isBlob, isURLSearchParameters, isFormData} from './utils/is.js';\n\nconst INTERNALS = Symbol('Body internals');\n\n/**\n * Body mixin\n *\n * Ref: https://fetch.spec.whatwg.org/#body\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nexport default class Body {\n\tconstructor(body, {\n\t\tsize = 0\n\t} = {}) {\n\t\tlet boundary = null;\n\n\t\tif (body === null) {\n\t\t\t// Body is undefined or null\n\t\t\tbody = null;\n\t\t} else if (isURLSearchParameters(body)) {\n\t\t// Body is a URLSearchParams\n\t\t\tbody = Buffer.from(body.toString());\n\t\t} else if (isBlob(body)) {\n\t\t\t// Body is blob\n\t\t} else if (Buffer.isBuffer(body)) {\n\t\t\t// Body is Buffer\n\t\t} else if (types.isAnyArrayBuffer(body)) {\n\t\t\t// Body is ArrayBuffer\n\t\t\tbody = Buffer.from(body);\n\t\t} else if (ArrayBuffer.isView(body)) {\n\t\t\t// Body is ArrayBufferView\n\t\t\tbody = Buffer.from(body.buffer, body.byteOffset, body.byteLength);\n\t\t} else if (body instanceof Stream) {\n\t\t\t// Body is stream\n\t\t} else if (isFormData(body)) {\n\t\t\t// Body is an instance of formdata-node\n\t\t\tboundary = `NodeFetchFormDataBoundary${getBoundary()}`;\n\t\t\tbody = Stream.Readable.from(formDataIterator(body, boundary));\n\t\t} else {\n\t\t\t// None of the above\n\t\t\t// coerce to string then buffer\n\t\t\tbody = Buffer.from(String(body));\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\tbody,\n\t\t\tboundary,\n\t\t\tdisturbed: false,\n\t\t\terror: null\n\t\t};\n\t\tthis.size = size;\n\n\t\tif (body instanceof Stream) {\n\t\t\tbody.on('error', error_ => {\n\t\t\t\tconst error = error_ instanceof FetchBaseError ?\n\t\t\t\t\terror_ :\n\t\t\t\t\tnew FetchError(`Invalid response body while trying to fetch ${this.url}: ${error_.message}`, 'system', error_);\n\t\t\t\tthis[INTERNALS].error = error;\n\t\t\t});\n\t\t}\n\t}\n\n\tget body() {\n\t\treturn this[INTERNALS].body;\n\t}\n\n\tget bodyUsed() {\n\t\treturn this[INTERNALS].disturbed;\n\t}\n\n\t/**\n\t * Decode response as ArrayBuffer\n\t *\n\t * @return  Promise\n\t */\n\tasync arrayBuffer() {\n\t\tconst {buffer, byteOffset, byteLength} = await consumeBody(this);\n\t\treturn buffer.slice(byteOffset, byteOffset + byteLength);\n\t}\n\n\t/**\n\t * Return raw response as Blob\n\t *\n\t * @return Promise\n\t */\n\tasync blob() {\n\t\tconst ct = (this.headers && this.headers.get('content-type')) || (this[INTERNALS].body && this[INTERNALS].body.type) || '';\n\t\tconst buf = await this.buffer();\n\n\t\treturn new Blob([buf], {\n\t\t\ttype: ct\n\t\t});\n\t}\n\n\t/**\n\t * Decode response as json\n\t *\n\t * @return  Promise\n\t */\n\tasync json() {\n\t\tconst buffer = await consumeBody(this);\n\t\treturn JSON.parse(buffer.toString());\n\t}\n\n\t/**\n\t * Decode response as text\n\t *\n\t * @return  Promise\n\t */\n\tasync text() {\n\t\tconst buffer = await consumeBody(this);\n\t\treturn buffer.toString();\n\t}\n\n\t/**\n\t * Decode response as buffer (non-spec api)\n\t *\n\t * @return  Promise\n\t */\n\tbuffer() {\n\t\treturn consumeBody(this);\n\t}\n}\n\n// In browsers, all properties are enumerable.\nObject.defineProperties(Body.prototype, {\n\tbody: {enumerable: true},\n\tbodyUsed: {enumerable: true},\n\tarrayBuffer: {enumerable: true},\n\tblob: {enumerable: true},\n\tjson: {enumerable: true},\n\ttext: {enumerable: true}\n});\n\n/**\n * Consume and convert an entire Body to a Buffer.\n *\n * Ref: https://fetch.spec.whatwg.org/#concept-body-consume-body\n *\n * @return Promise\n */\nasync function consumeBody(data) {\n\tif (data[INTERNALS].disturbed) {\n\t\tthrow new TypeError(`body used already for: ${data.url}`);\n\t}\n\n\tdata[INTERNALS].disturbed = true;\n\n\tif (data[INTERNALS].error) {\n\t\tthrow data[INTERNALS].error;\n\t}\n\n\tlet {body} = data;\n\n\t// Body is null\n\tif (body === null) {\n\t\treturn Buffer.alloc(0);\n\t}\n\n\t// Body is blob\n\tif (isBlob(body)) {\n\t\tbody = Stream.Readable.from(body.stream());\n\t}\n\n\t// Body is buffer\n\tif (Buffer.isBuffer(body)) {\n\t\treturn body;\n\t}\n\n\t/* c8 ignore next 3 */\n\tif (!(body instanceof Stream)) {\n\t\treturn Buffer.alloc(0);\n\t}\n\n\t// Body is stream\n\t// get ready to actually consume the body\n\tconst accum = [];\n\tlet accumBytes = 0;\n\n\ttry {\n\t\tfor await (const chunk of body) {\n\t\t\tif (data.size > 0 && accumBytes + chunk.length > data.size) {\n\t\t\t\tconst error = new FetchError(`content size at ${data.url} over limit: ${data.size}`, 'max-size');\n\t\t\t\tbody.destroy(error);\n\t\t\t\tthrow error;\n\t\t\t}\n\n\t\t\taccumBytes += chunk.length;\n\t\t\taccum.push(chunk);\n\t\t}\n\t} catch (error) {\n\t\tconst error_ = error instanceof FetchBaseError ? error : new FetchError(`Invalid response body while trying to fetch ${data.url}: ${error.message}`, 'system', error);\n\t\tthrow error_;\n\t}\n\n\tif (body.readableEnded === true || body._readableState.ended === true) {\n\t\ttry {\n\t\t\tif (accum.every(c => typeof c === 'string')) {\n\t\t\t\treturn Buffer.from(accum.join(''));\n\t\t\t}\n\n\t\t\treturn Buffer.concat(accum, accumBytes);\n\t\t} catch (error) {\n\t\t\tthrow new FetchError(`Could not create Buffer from response body for ${data.url}: ${error.message}`, 'system', error);\n\t\t}\n\t} else {\n\t\tthrow new FetchError(`Premature close of server response while trying to fetch ${data.url}`);\n\t}\n}\n\n/**\n * Clone body given Res/Req instance\n *\n * @param   Mixed   instance       Response or Request instance\n * @param   String  highWaterMark  highWaterMark for both PassThrough body streams\n * @return  Mixed\n */\nexport const clone = (instance, highWaterMark) => {\n\tlet p1;\n\tlet p2;\n\tlet {body} = instance;\n\n\t// Don't allow cloning a used body\n\tif (instance.bodyUsed) {\n\t\tthrow new Error('cannot clone body after it is used');\n\t}\n\n\t// Check that body is a stream and not form-data object\n\t// note: we can't clone the form-data object without having it as a dependency\n\tif ((body instanceof Stream) && (typeof body.getBoundary !== 'function')) {\n\t\t// Tee instance body\n\t\tp1 = new PassThrough({highWaterMark});\n\t\tp2 = new PassThrough({highWaterMark});\n\t\tbody.pipe(p1);\n\t\tbody.pipe(p2);\n\t\t// Set instance body to teed body and return the other teed body\n\t\tinstance[INTERNALS].body = p1;\n\t\tbody = p2;\n\t}\n\n\treturn body;\n};\n\n/**\n * Performs the operation \"extract a `Content-Type` value from |object|\" as\n * specified in the specification:\n * https://fetch.spec.whatwg.org/#concept-bodyinit-extract\n *\n * This function assumes that instance.body is present.\n *\n * @param {any} body Any options.body input\n * @returns {string | null}\n */\nexport const extractContentType = (body, request) => {\n\t// Body is null or undefined\n\tif (body === null) {\n\t\treturn null;\n\t}\n\n\t// Body is string\n\tif (typeof body === 'string') {\n\t\treturn 'text/plain;charset=UTF-8';\n\t}\n\n\t// Body is a URLSearchParams\n\tif (isURLSearchParameters(body)) {\n\t\treturn 'application/x-www-form-urlencoded;charset=UTF-8';\n\t}\n\n\t// Body is blob\n\tif (isBlob(body)) {\n\t\treturn body.type || null;\n\t}\n\n\t// Body is a Buffer (Buffer, ArrayBuffer or ArrayBufferView)\n\tif (Buffer.isBuffer(body) || types.isAnyArrayBuffer(body) || ArrayBuffer.isView(body)) {\n\t\treturn null;\n\t}\n\n\t// Detect form data input from form-data module\n\tif (body && typeof body.getBoundary === 'function') {\n\t\treturn `multipart/form-data;boundary=${body.getBoundary()}`;\n\t}\n\n\tif (isFormData(body)) {\n\t\treturn `multipart/form-data; boundary=${request[INTERNALS].boundary}`;\n\t}\n\n\t// Body is stream - can't really do much about this\n\tif (body instanceof Stream) {\n\t\treturn null;\n\t}\n\n\t// Body constructor defaults other things to string\n\treturn 'text/plain;charset=UTF-8';\n};\n\n/**\n * The Fetch Standard treats this as if \"total bytes\" is a property on the body.\n * For us, we have to explicitly get it with a function.\n *\n * ref: https://fetch.spec.whatwg.org/#concept-body-total-bytes\n *\n * @param {any} obj.body Body object from the Body instance.\n * @returns {number | null}\n */\nexport const getTotalBytes = request => {\n\tconst {body} = request;\n\n\t// Body is null or undefined\n\tif (body === null) {\n\t\treturn 0;\n\t}\n\n\t// Body is Blob\n\tif (isBlob(body)) {\n\t\treturn body.size;\n\t}\n\n\t// Body is Buffer\n\tif (Buffer.isBuffer(body)) {\n\t\treturn body.length;\n\t}\n\n\t// Detect form data input from form-data module\n\tif (body && typeof body.getLengthSync === 'function') {\n\t\treturn body.hasKnownLength && body.hasKnownLength() ? body.getLengthSync() : null;\n\t}\n\n\t// Body is a spec-compliant form-data\n\tif (isFormData(body)) {\n\t\treturn getFormDataLength(request[INTERNALS].boundary);\n\t}\n\n\t// Body is stream\n\treturn null;\n};\n\n/**\n * Write a Body to a Node.js WritableStream (e.g. http.Request) object.\n *\n * @param {Stream.Writable} dest The stream to write to.\n * @param obj.body Body object from the Body instance.\n * @returns {void}\n */\nexport const writeToStream = (dest, {body}) => {\n\tif (body === null) {\n\t\t// Body is null\n\t\tdest.end();\n\t} else if (isBlob(body)) {\n\t\t// Body is Blob\n\t\tStream.Readable.from(body.stream()).pipe(dest);\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// Body is buffer\n\t\tdest.write(body);\n\t\tdest.end();\n\t} else {\n\t\t// Body is stream\n\t\tbody.pipe(dest);\n\t}\n};\n","/**\n * Headers.js\n *\n * Headers class offers convenient helpers\n */\n\nimport {types} from 'util';\nimport http from 'http';\n\nconst validateHeaderName = typeof http.validateHeaderName === 'function' ?\n\thttp.validateHeaderName :\n\tname => {\n\t\tif (!/^[\\^`\\-\\w!#$%&'*+.|~]+$/.test(name)) {\n\t\t\tconst error = new TypeError(`Header name must be a valid HTTP token [${name}]`);\n\t\t\tObject.defineProperty(error, 'code', {value: 'ERR_INVALID_HTTP_TOKEN'});\n\t\t\tthrow error;\n\t\t}\n\t};\n\nconst validateHeaderValue = typeof http.validateHeaderValue === 'function' ?\n\thttp.validateHeaderValue :\n\t(name, value) => {\n\t\tif (/[^\\t\\u0020-\\u007E\\u0080-\\u00FF]/.test(value)) {\n\t\t\tconst error = new TypeError(`Invalid character in header content [\"${name}\"]`);\n\t\t\tObject.defineProperty(error, 'code', {value: 'ERR_INVALID_CHAR'});\n\t\t\tthrow error;\n\t\t}\n\t};\n\n/**\n * @typedef {Headers | Record<string, string> | Iterable<readonly [string, string]> | Iterable<Iterable<string>>} HeadersInit\n */\n\n/**\n * This Fetch API interface allows you to perform various actions on HTTP request and response headers.\n * These actions include retrieving, setting, adding to, and removing.\n * A Headers object has an associated header list, which is initially empty and consists of zero or more name and value pairs.\n * You can add to this using methods like append() (see Examples.)\n * In all methods of this interface, header names are matched by case-insensitive byte sequence.\n *\n */\nexport default class Headers extends URLSearchParams {\n\t/**\n\t * Headers class\n\t *\n\t * @constructor\n\t * @param {HeadersInit} [init] - Response headers\n\t */\n\tconstructor(init) {\n\t\t// Validate and normalize init object in [name, value(s)][]\n\t\t/** @type {string[][]} */\n\t\tlet result = [];\n\t\tif (init instanceof Headers) {\n\t\t\tconst raw = init.raw();\n\t\t\tfor (const [name, values] of Object.entries(raw)) {\n\t\t\t\tresult.push(...values.map(value => [name, value]));\n\t\t\t}\n\t\t} else if (init == null) { // eslint-disable-line no-eq-null, eqeqeq\n\t\t\t// No op\n\t\t} else if (typeof init === 'object' && !types.isBoxedPrimitive(init)) {\n\t\t\tconst method = init[Symbol.iterator];\n\t\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\t\tif (method == null) {\n\t\t\t\t// Record<ByteString, ByteString>\n\t\t\t\tresult.push(...Object.entries(init));\n\t\t\t} else {\n\t\t\t\tif (typeof method !== 'function') {\n\t\t\t\t\tthrow new TypeError('Header pairs must be iterable');\n\t\t\t\t}\n\n\t\t\t\t// Sequence<sequence<ByteString>>\n\t\t\t\t// Note: per spec we have to first exhaust the lists then process them\n\t\t\t\tresult = [...init]\n\t\t\t\t\t.map(pair => {\n\t\t\t\t\t\tif (\n\t\t\t\t\t\t\ttypeof pair !== 'object' || types.isBoxedPrimitive(pair)\n\t\t\t\t\t\t) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be an iterable object');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t}).map(pair => {\n\t\t\t\t\t\tif (pair.length !== 2) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be a name/value tuple');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t});\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new TypeError('Failed to construct \\'Headers\\': The provided value is not of type \\'(sequence<sequence<ByteString>> or record<ByteString, ByteString>)');\n\t\t}\n\n\t\t// Validate and lowercase\n\t\tresult =\n\t\t\tresult.length > 0 ?\n\t\t\t\tresult.map(([name, value]) => {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn [String(name).toLowerCase(), String(value)];\n\t\t\t\t}) :\n\t\t\t\tundefined;\n\n\t\tsuper(result);\n\n\t\t// Returning a Proxy that will lowercase key names, validate parameters and sort keys\n\t\t// eslint-disable-next-line no-constructor-return\n\t\treturn new Proxy(this, {\n\t\t\tget(target, p, receiver) {\n\t\t\t\tswitch (p) {\n\t\t\t\t\tcase 'append':\n\t\t\t\t\tcase 'set':\n\t\t\t\t\t\treturn (name, value) => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\ttarget,\n\t\t\t\t\t\t\t\tString(name).toLowerCase(),\n\t\t\t\t\t\t\t\tString(value)\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'delete':\n\t\t\t\t\tcase 'has':\n\t\t\t\t\tcase 'getAll':\n\t\t\t\t\t\treturn name => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\ttarget,\n\t\t\t\t\t\t\t\tString(name).toLowerCase()\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'keys':\n\t\t\t\t\t\treturn () => {\n\t\t\t\t\t\t\ttarget.sort();\n\t\t\t\t\t\t\treturn new Set(URLSearchParams.prototype.keys.call(target)).keys();\n\t\t\t\t\t\t};\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn Reflect.get(target, p, receiver);\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* c8 ignore next */\n\t\t});\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n\n\ttoString() {\n\t\treturn Object.prototype.toString.call(this);\n\t}\n\n\tget(name) {\n\t\tconst values = this.getAll(name);\n\t\tif (values.length === 0) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlet value = values.join(', ');\n\t\tif (/^content-encoding$/i.test(name)) {\n\t\t\tvalue = value.toLowerCase();\n\t\t}\n\n\t\treturn value;\n\t}\n\n\tforEach(callback, thisArg = undefined) {\n\t\tfor (const name of this.keys()) {\n\t\t\tReflect.apply(callback, thisArg, [this.get(name), name, this]);\n\t\t}\n\t}\n\n\t* values() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield this.get(name);\n\t\t}\n\t}\n\n\t/**\n\t * @type {() => IterableIterator<[string, string]>}\n\t */\n\t* entries() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield [name, this.get(name)];\n\t\t}\n\t}\n\n\t[Symbol.iterator]() {\n\t\treturn this.entries();\n\t}\n\n\t/**\n\t * Node-fetch non-spec method\n\t * returning all headers and their values as array\n\t * @returns {Record<string, string[]>}\n\t */\n\traw() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tresult[key] = this.getAll(key);\n\t\t\treturn result;\n\t\t}, {});\n\t}\n\n\t/**\n\t * For better console.log(headers) and also to convert Headers into Node.js Request compatible format\n\t */\n\t[Symbol.for('nodejs.util.inspect.custom')]() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tconst values = this.getAll(key);\n\t\t\t// Http.request() only supports string as Host header.\n\t\t\t// This hack makes specifying custom Host header possible.\n\t\t\tif (key === 'host') {\n\t\t\t\tresult[key] = values[0];\n\t\t\t} else {\n\t\t\t\tresult[key] = values.length > 1 ? values : values[0];\n\t\t\t}\n\n\t\t\treturn result;\n\t\t}, {});\n\t}\n}\n\n/**\n * Re-shaping object for Web IDL tests\n * Only need to do it for overridden methods\n */\nObject.defineProperties(\n\tHeaders.prototype,\n\t['get', 'entries', 'forEach', 'values'].reduce((result, property) => {\n\t\tresult[property] = {enumerable: true};\n\t\treturn result;\n\t}, {})\n);\n\n/**\n * Create a Headers object from an http.IncomingMessage.rawHeaders, ignoring those that do\n * not conform to HTTP grammar productions.\n * @param {import('http').IncomingMessage['rawHeaders']} headers\n */\nexport function fromRawHeaders(headers = []) {\n\treturn new Headers(\n\t\theaders\n\t\t\t// Split into pairs\n\t\t\t.reduce((result, value, index, array) => {\n\t\t\t\tif (index % 2 === 0) {\n\t\t\t\t\tresult.push(array.slice(index, index + 2));\n\t\t\t\t}\n\n\t\t\t\treturn result;\n\t\t\t}, [])\n\t\t\t.filter(([name, value]) => {\n\t\t\t\ttry {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn true;\n\t\t\t\t} catch {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t})\n\n\t);\n}\n","const redirectStatus = new Set([301, 302, 303, 307, 308]);\n\n/**\n * Redirect code matching\n *\n * @param {number} code - Status code\n * @return {boolean}\n */\nexport const isRedirect = code => {\n\treturn redirectStatus.has(code);\n};\n","/**\n * Response.js\n *\n * Response class provides content decoding\n */\n\nimport Headers from './headers.js';\nimport Body, {clone, extractContentType} from './body.js';\nimport {isRedirect} from './utils/is-redirect.js';\n\nconst INTERNALS = Symbol('Response internals');\n\n/**\n * Response class\n *\n * Ref: https://fetch.spec.whatwg.org/#response-class\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nexport default class Response extends Body {\n\tconstructor(body = null, options = {}) {\n\t\tsuper(body, options);\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq, no-negated-condition\n\t\tconst status = options.status != null ? options.status : 200;\n\n\t\tconst headers = new Headers(options.headers);\n\n\t\tif (body !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(body);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\ttype: 'default',\n\t\t\turl: options.url,\n\t\t\tstatus,\n\t\t\tstatusText: options.statusText || '',\n\t\t\theaders,\n\t\t\tcounter: options.counter,\n\t\t\thighWaterMark: options.highWaterMark\n\t\t};\n\t}\n\n\tget type() {\n\t\treturn this[INTERNALS].type;\n\t}\n\n\tget url() {\n\t\treturn this[INTERNALS].url || '';\n\t}\n\n\tget status() {\n\t\treturn this[INTERNALS].status;\n\t}\n\n\t/**\n\t * Convenience property representing if the request ended normally\n\t */\n\tget ok() {\n\t\treturn this[INTERNALS].status >= 200 && this[INTERNALS].status < 300;\n\t}\n\n\tget redirected() {\n\t\treturn this[INTERNALS].counter > 0;\n\t}\n\n\tget statusText() {\n\t\treturn this[INTERNALS].statusText;\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget highWaterMark() {\n\t\treturn this[INTERNALS].highWaterMark;\n\t}\n\n\t/**\n\t * Clone this response\n\t *\n\t * @return  Response\n\t */\n\tclone() {\n\t\treturn new Response(clone(this, this.highWaterMark), {\n\t\t\ttype: this.type,\n\t\t\turl: this.url,\n\t\t\tstatus: this.status,\n\t\t\tstatusText: this.statusText,\n\t\t\theaders: this.headers,\n\t\t\tok: this.ok,\n\t\t\tredirected: this.redirected,\n\t\t\tsize: this.size\n\t\t});\n\t}\n\n\t/**\n\t * @param {string} url    The URL that the new response is to originate from.\n\t * @param {number} status An optional status code for the response (e.g., 302.)\n\t * @returns {Response}    A Response object.\n\t */\n\tstatic redirect(url, status = 302) {\n\t\tif (!isRedirect(status)) {\n\t\t\tthrow new RangeError('Failed to execute \"redirect\" on \"response\": Invalid status code');\n\t\t}\n\n\t\treturn new Response(null, {\n\t\t\theaders: {\n\t\t\t\tlocation: new URL(url).toString()\n\t\t\t},\n\t\t\tstatus\n\t\t});\n\t}\n\n\tstatic error() {\n\t\tconst response = new Response(null, {status: 0, statusText: ''});\n\t\tresponse[INTERNALS].type = 'error';\n\t\treturn response;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Response';\n\t}\n}\n\nObject.defineProperties(Response.prototype, {\n\ttype: {enumerable: true},\n\turl: {enumerable: true},\n\tstatus: {enumerable: true},\n\tok: {enumerable: true},\n\tredirected: {enumerable: true},\n\tstatusText: {enumerable: true},\n\theaders: {enumerable: true},\n\tclone: {enumerable: true}\n});\n","export const getSearch = parsedURL => {\n\tif (parsedURL.search) {\n\t\treturn parsedURL.search;\n\t}\n\n\tconst lastOffset = parsedURL.href.length - 1;\n\tconst hash = parsedURL.hash || (parsedURL.href[lastOffset] === '#' ? '#' : '');\n\treturn parsedURL.href[lastOffset - hash.length] === '?' ? '?' : '';\n};\n","\n/**\n * Request.js\n *\n * Request class contains server only options\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nimport {format as formatUrl} from 'url';\nimport Headers from './headers.js';\nimport Body, {clone, extractContentType, getTotalBytes} from './body.js';\nimport {isAbortSignal} from './utils/is.js';\nimport {getSearch} from './utils/get-search.js';\n\nconst INTERNALS = Symbol('Request internals');\n\n/**\n * Check if `obj` is an instance of Request.\n *\n * @param  {*} obj\n * @return {boolean}\n */\nconst isRequest = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object[INTERNALS] === 'object'\n\t);\n};\n\n/**\n * Request class\n *\n * Ref: https://fetch.spec.whatwg.org/#request-class\n *\n * @param   Mixed   input  Url or Request instance\n * @param   Object  init   Custom options\n * @return  Void\n */\nexport default class Request extends Body {\n\tconstructor(input, init = {}) {\n\t\tlet parsedURL;\n\n\t\t// Normalize input and force URL to be encoded as UTF-8 (https://github.com/node-fetch/node-fetch/issues/245)\n\t\tif (isRequest(input)) {\n\t\t\tparsedURL = new URL(input.url);\n\t\t} else {\n\t\t\tparsedURL = new URL(input);\n\t\t\tinput = {};\n\t\t}\n\n\t\tlet method = init.method || input.method || 'GET';\n\t\tmethod = method.toUpperCase();\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif (((init.body != null || isRequest(input)) && input.body !== null) &&\n\t\t\t(method === 'GET' || method === 'HEAD')) {\n\t\t\tthrow new TypeError('Request with GET/HEAD method cannot have body');\n\t\t}\n\n\t\tconst inputBody = init.body ?\n\t\t\tinit.body :\n\t\t\t(isRequest(input) && input.body !== null ?\n\t\t\t\tclone(input) :\n\t\t\t\tnull);\n\n\t\tsuper(inputBody, {\n\t\t\tsize: init.size || input.size || 0\n\t\t});\n\n\t\tconst headers = new Headers(init.headers || input.headers || {});\n\n\t\tif (inputBody !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(inputBody, this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tlet signal = isRequest(input) ?\n\t\t\tinput.signal :\n\t\t\tnull;\n\t\tif ('signal' in init) {\n\t\t\tsignal = init.signal;\n\t\t}\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif (signal != null && !isAbortSignal(signal)) {\n\t\t\tthrow new TypeError('Expected signal to be an instanceof AbortSignal or EventTarget');\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\tmethod,\n\t\t\tredirect: init.redirect || input.redirect || 'follow',\n\t\t\theaders,\n\t\t\tparsedURL,\n\t\t\tsignal\n\t\t};\n\n\t\t// Node-fetch-only options\n\t\tthis.follow = init.follow === undefined ? (input.follow === undefined ? 20 : input.follow) : init.follow;\n\t\tthis.compress = init.compress === undefined ? (input.compress === undefined ? true : input.compress) : init.compress;\n\t\tthis.counter = init.counter || input.counter || 0;\n\t\tthis.agent = init.agent || input.agent;\n\t\tthis.highWaterMark = init.highWaterMark || input.highWaterMark || 16384;\n\t\tthis.insecureHTTPParser = init.insecureHTTPParser || input.insecureHTTPParser || false;\n\t}\n\n\tget method() {\n\t\treturn this[INTERNALS].method;\n\t}\n\n\tget url() {\n\t\treturn formatUrl(this[INTERNALS].parsedURL);\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget redirect() {\n\t\treturn this[INTERNALS].redirect;\n\t}\n\n\tget signal() {\n\t\treturn this[INTERNALS].signal;\n\t}\n\n\t/**\n\t * Clone this request\n\t *\n\t * @return  Request\n\t */\n\tclone() {\n\t\treturn new Request(this);\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Request';\n\t}\n}\n\nObject.defineProperties(Request.prototype, {\n\tmethod: {enumerable: true},\n\turl: {enumerable: true},\n\theaders: {enumerable: true},\n\tredirect: {enumerable: true},\n\tclone: {enumerable: true},\n\tsignal: {enumerable: true}\n});\n\n/**\n * Convert a Request to Node.js http request options.\n *\n * @param   Request  A Request instance\n * @return  Object   The options object to be passed to http.request\n */\nexport const getNodeRequestOptions = request => {\n\tconst {parsedURL} = request[INTERNALS];\n\tconst headers = new Headers(request[INTERNALS].headers);\n\n\t// Fetch step 1.3\n\tif (!headers.has('Accept')) {\n\t\theaders.set('Accept', '*/*');\n\t}\n\n\t// HTTP-network-or-cache fetch steps 2.4-2.7\n\tlet contentLengthValue = null;\n\tif (request.body === null && /^(post|put)$/i.test(request.method)) {\n\t\tcontentLengthValue = '0';\n\t}\n\n\tif (request.body !== null) {\n\t\tconst totalBytes = getTotalBytes(request);\n\t\t// Set Content-Length if totalBytes is a number (that is not NaN)\n\t\tif (typeof totalBytes === 'number' && !Number.isNaN(totalBytes)) {\n\t\t\tcontentLengthValue = String(totalBytes);\n\t\t}\n\t}\n\n\tif (contentLengthValue) {\n\t\theaders.set('Content-Length', contentLengthValue);\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.11\n\tif (!headers.has('User-Agent')) {\n\t\theaders.set('User-Agent', 'node-fetch');\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.15\n\tif (request.compress && !headers.has('Accept-Encoding')) {\n\t\theaders.set('Accept-Encoding', 'gzip,deflate,br');\n\t}\n\n\tlet {agent} = request;\n\tif (typeof agent === 'function') {\n\t\tagent = agent(parsedURL);\n\t}\n\n\tif (!headers.has('Connection') && !agent) {\n\t\theaders.set('Connection', 'close');\n\t}\n\n\t// HTTP-network fetch step 4.2\n\t// chunked encoding is handled by Node.js\n\n\tconst search = getSearch(parsedURL);\n\n\t// Manually spread the URL object instead of spread syntax\n\tconst requestOptions = {\n\t\tpath: parsedURL.pathname + search,\n\t\tpathname: parsedURL.pathname,\n\t\thostname: parsedURL.hostname,\n\t\tprotocol: parsedURL.protocol,\n\t\tport: parsedURL.port,\n\t\thash: parsedURL.hash,\n\t\tsearch: parsedURL.search,\n\t\tquery: parsedURL.query,\n\t\thref: parsedURL.href,\n\t\tmethod: request.method,\n\t\theaders: headers[Symbol.for('nodejs.util.inspect.custom')](),\n\t\tinsecureHTTPParser: request.insecureHTTPParser,\n\t\tagent\n\t};\n\n\treturn requestOptions;\n};\n","import {FetchBaseError} from './base.js';\n\n/**\n * AbortError interface for cancelled requests\n */\nexport class AbortError extends FetchBaseError {\n\tconstructor(message, type = 'aborted') {\n\t\tsuper(message, type);\n\t}\n}\n","/**\n * Index.js\n *\n * a request API compatible with window.fetch\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nimport http from 'http';\nimport https from 'https';\nimport zlib from 'zlib';\nimport Stream, {PassThrough, pipeline as pump} from 'stream';\nimport dataUriToBuffer from 'data-uri-to-buffer';\n\nimport {writeToStream} from './body.js';\nimport Response from './response.js';\nimport Headers, {fromRawHeaders} from './headers.js';\nimport Request, {getNodeRequestOptions} from './request.js';\nimport {FetchError} from './errors/fetch-error.js';\nimport {AbortError} from './errors/abort-error.js';\nimport {isRedirect} from './utils/is-redirect.js';\n\nexport {Headers, Request, Response, FetchError, AbortError, isRedirect};\n\nconst supportedSchemas = new Set(['data:', 'http:', 'https:']);\n\n/**\n * Fetch function\n *\n * @param   {string | URL | import('./request').default} url - Absolute url or Request instance\n * @param   {*} [options_] - Fetch options\n * @return  {Promise<import('./response').default>}\n */\nexport default async function fetch(url, options_) {\n\treturn new Promise((resolve, reject) => {\n\t\t// Build request object\n\t\tconst request = new Request(url, options_);\n\t\tconst options = getNodeRequestOptions(request);\n\t\tif (!supportedSchemas.has(options.protocol)) {\n\t\t\tthrow new TypeError(`node-fetch cannot load ${url}. URL scheme \"${options.protocol.replace(/:$/, '')}\" is not supported.`);\n\t\t}\n\n\t\tif (options.protocol === 'data:') {\n\t\t\tconst data = dataUriToBuffer(request.url);\n\t\t\tconst response = new Response(data, {headers: {'Content-Type': data.typeFull}});\n\t\t\tresolve(response);\n\t\t\treturn;\n\t\t}\n\n\t\t// Wrap http.request into fetch\n\t\tconst send = (options.protocol === 'https:' ? https : http).request;\n\t\tconst {signal} = request;\n\t\tlet response = null;\n\n\t\tconst abort = () => {\n\t\t\tconst error = new AbortError('The operation was aborted.');\n\t\t\treject(error);\n\t\t\tif (request.body && request.body instanceof Stream.Readable) {\n\t\t\t\trequest.body.destroy(error);\n\t\t\t}\n\n\t\t\tif (!response || !response.body) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tresponse.body.emit('error', error);\n\t\t};\n\n\t\tif (signal && signal.aborted) {\n\t\t\tabort();\n\t\t\treturn;\n\t\t}\n\n\t\tconst abortAndFinalize = () => {\n\t\t\tabort();\n\t\t\tfinalize();\n\t\t};\n\n\t\t// Send request\n\t\tconst request_ = send(options);\n\n\t\tif (signal) {\n\t\t\tsignal.addEventListener('abort', abortAndFinalize);\n\t\t}\n\n\t\tconst finalize = () => {\n\t\t\trequest_.abort();\n\t\t\tif (signal) {\n\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t}\n\t\t};\n\n\t\trequest_.on('error', error => {\n\t\t\treject(new FetchError(`request to ${request.url} failed, reason: ${error.message}`, 'system', error));\n\t\t\tfinalize();\n\t\t});\n\n\t\tfixResponseChunkedTransferBadEnding(request_, error => {\n\t\t\tresponse.body.destroy(error);\n\t\t});\n\n\t\t/* c8 ignore next 18 */\n\t\tif (process.version < 'v14') {\n\t\t\t// Before Node.js 14, pipeline() does not fully support async iterators and does not always\n\t\t\t// properly handle when the socket close/end events are out of order.\n\t\t\trequest_.on('socket', s => {\n\t\t\t\tlet endedWithEventsCount;\n\t\t\t\ts.prependListener('end', () => {\n\t\t\t\t\tendedWithEventsCount = s._eventsCount;\n\t\t\t\t});\n\t\t\t\ts.prependListener('close', hadError => {\n\t\t\t\t\t// if end happened before close but the socket didn't emit an error, do it now\n\t\t\t\t\tif (response && endedWithEventsCount < s._eventsCount && !hadError) {\n\t\t\t\t\t\tconst error = new Error('Premature close');\n\t\t\t\t\t\terror.code = 'ERR_STREAM_PREMATURE_CLOSE';\n\t\t\t\t\t\tresponse.body.emit('error', error);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t});\n\t\t}\n\n\t\trequest_.on('response', response_ => {\n\t\t\trequest_.setTimeout(0);\n\t\t\tconst headers = fromRawHeaders(response_.rawHeaders);\n\n\t\t\t// HTTP fetch step 5\n\t\t\tif (isRedirect(response_.statusCode)) {\n\t\t\t\t// HTTP fetch step 5.2\n\t\t\t\tconst location = headers.get('Location');\n\n\t\t\t\t// HTTP fetch step 5.3\n\t\t\t\tconst locationURL = location === null ? null : new URL(location, request.url);\n\n\t\t\t\t// HTTP fetch step 5.5\n\t\t\t\tswitch (request.redirect) {\n\t\t\t\t\tcase 'error':\n\t\t\t\t\t\treject(new FetchError(`uri requested responds with a redirect, redirect mode is set to error: ${request.url}`, 'no-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\tcase 'manual':\n\t\t\t\t\t\t// Node-fetch-specific step: make manual redirect a bit easier to use by setting the Location header value to the resolved URL.\n\t\t\t\t\t\tif (locationURL !== null) {\n\t\t\t\t\t\t\theaders.set('Location', locationURL);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'follow': {\n\t\t\t\t\t\t// HTTP-redirect fetch step 2\n\t\t\t\t\t\tif (locationURL === null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 5\n\t\t\t\t\t\tif (request.counter >= request.follow) {\n\t\t\t\t\t\t\treject(new FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 6 (counter increment)\n\t\t\t\t\t\t// Create a new Request object.\n\t\t\t\t\t\tconst requestOptions = {\n\t\t\t\t\t\t\theaders: new Headers(request.headers),\n\t\t\t\t\t\t\tfollow: request.follow,\n\t\t\t\t\t\t\tcounter: request.counter + 1,\n\t\t\t\t\t\t\tagent: request.agent,\n\t\t\t\t\t\t\tcompress: request.compress,\n\t\t\t\t\t\t\tmethod: request.method,\n\t\t\t\t\t\t\tbody: request.body,\n\t\t\t\t\t\t\tsignal: request.signal,\n\t\t\t\t\t\t\tsize: request.size\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 9\n\t\t\t\t\t\tif (response_.statusCode !== 303 && request.body && options_.body instanceof Stream.Readable) {\n\t\t\t\t\t\t\treject(new FetchError('Cannot follow redirect with body being a readable stream', 'unsupported-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 11\n\t\t\t\t\t\tif (response_.statusCode === 303 || ((response_.statusCode === 301 || response_.statusCode === 302) && request.method === 'POST')) {\n\t\t\t\t\t\t\trequestOptions.method = 'GET';\n\t\t\t\t\t\t\trequestOptions.body = undefined;\n\t\t\t\t\t\t\trequestOptions.headers.delete('content-length');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 15\n\t\t\t\t\t\tresolve(fetch(new Request(locationURL, requestOptions)));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn reject(new TypeError(`Redirect option '${request.redirect}' is not a valid value of RequestRedirect`));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Prepare response\n\t\t\tif (signal) {\n\t\t\t\tresponse_.once('end', () => {\n\t\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tlet body = pump(response_, new PassThrough(), reject);\n\t\t\t// see https://github.com/nodejs/node/pull/29376\n\t\t\tif (process.version < 'v12.10') {\n\t\t\t\tresponse_.on('aborted', abortAndFinalize);\n\t\t\t}\n\n\t\t\tconst responseOptions = {\n\t\t\t\turl: request.url,\n\t\t\t\tstatus: response_.statusCode,\n\t\t\t\tstatusText: response_.statusMessage,\n\t\t\t\theaders,\n\t\t\t\tsize: request.size,\n\t\t\t\tcounter: request.counter,\n\t\t\t\thighWaterMark: request.highWaterMark\n\t\t\t};\n\n\t\t\t// HTTP-network fetch step 12.1.1.3\n\t\t\tconst codings = headers.get('Content-Encoding');\n\n\t\t\t// HTTP-network fetch step 12.1.1.4: handle content codings\n\n\t\t\t// in following scenarios we ignore compression support\n\t\t\t// 1. compression support is disabled\n\t\t\t// 2. HEAD request\n\t\t\t// 3. no Content-Encoding header\n\t\t\t// 4. no content response (204)\n\t\t\t// 5. content not modified response (304)\n\t\t\tif (!request.compress || request.method === 'HEAD' || codings === null || response_.statusCode === 204 || response_.statusCode === 304) {\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For Node v6+\n\t\t\t// Be less strict when decoding compressed responses, since sometimes\n\t\t\t// servers send slightly invalid responses that are still accepted\n\t\t\t// by common browsers.\n\t\t\t// Always using Z_SYNC_FLUSH is what cURL does.\n\t\t\tconst zlibOptions = {\n\t\t\t\tflush: zlib.Z_SYNC_FLUSH,\n\t\t\t\tfinishFlush: zlib.Z_SYNC_FLUSH\n\t\t\t};\n\n\t\t\t// For gzip\n\t\t\tif (codings === 'gzip' || codings === 'x-gzip') {\n\t\t\t\tbody = pump(body, zlib.createGunzip(zlibOptions), reject);\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For deflate\n\t\t\tif (codings === 'deflate' || codings === 'x-deflate') {\n\t\t\t\t// Handle the infamous raw deflate response from old servers\n\t\t\t\t// a hack for old IIS and Apache servers\n\t\t\t\tconst raw = pump(response_, new PassThrough(), reject);\n\t\t\t\traw.once('data', chunk => {\n\t\t\t\t\t// See http://stackoverflow.com/questions/37519828\n\t\t\t\t\tbody = (chunk[0] & 0x0F) === 0x08 ? pump(body, zlib.createInflate(), reject) : pump(body, zlib.createInflateRaw(), reject);\n\n\t\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\t\tresolve(response);\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For br\n\t\t\tif (codings === 'br') {\n\t\t\t\tbody = pump(body, zlib.createBrotliDecompress(), reject);\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Otherwise, use response as-is\n\t\t\tresponse = new Response(body, responseOptions);\n\t\t\tresolve(response);\n\t\t});\n\n\t\twriteToStream(request_, request);\n\t});\n}\n\nfunction fixResponseChunkedTransferBadEnding(request, errorCallback) {\n\tconst LAST_CHUNK = Buffer.from('0\\r\\n\\r\\n');\n\n\tlet isChunkedTransfer = false;\n\tlet properLastChunkReceived = false;\n\tlet previousChunk;\n\n\trequest.on('response', response => {\n\t\tconst {headers} = response;\n\t\tisChunkedTransfer = headers['transfer-encoding'] === 'chunked' && !headers['content-length'];\n\t});\n\n\trequest.on('socket', socket => {\n\t\tconst onSocketClose = () => {\n\t\t\tif (isChunkedTransfer && !properLastChunkReceived) {\n\t\t\t\tconst error = new Error('Premature close');\n\t\t\t\terror.code = 'ERR_STREAM_PREMATURE_CLOSE';\n\t\t\t\terrorCallback(error);\n\t\t\t}\n\t\t};\n\n\t\tsocket.prependListener('close', onSocketClose);\n\n\t\trequest.on('abort', () => {\n\t\t\tsocket.removeListener('close', onSocketClose);\n\t\t});\n\n\t\tsocket.on('data', buf => {\n\t\t\tproperLastChunkReceived = Buffer.compare(buf.slice(-5), LAST_CHUNK) === 0;\n\n\t\t\t// Sometimes final 0-length chunk and end of message code are in separate packets\n\t\t\tif (!properLastChunkReceived && previousChunk) {\n\t\t\t\tproperLastChunkReceived = (\n\t\t\t\t\tBuffer.compare(previousChunk.slice(-3), LAST_CHUNK.slice(0, 3)) === 0 &&\n\t\t\t\t\tBuffer.compare(buf.slice(-2), LAST_CHUNK.slice(3)) === 0\n\t\t\t\t);\n\t\t\t}\n\n\t\t\tpreviousChunk = buf;\n\t\t});\n\t});\n}\n","var wrappy = require('wrappy')\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n","'use strict';\n\nfunction posix(path) {\n\treturn path.charAt(0) === '/';\n}\n\nfunction win32(path) {\n\t// https://github.com/nodejs/node/blob/b3fcc245fb25539909ef1d5eaa01dbf92e168633/lib/path.js#L56\n\tvar splitDeviceRe = /^([a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/]+)?([\\\\\\/])?([\\s\\S]*?)$/;\n\tvar result = splitDeviceRe.exec(path);\n\tvar device = result[1] || '';\n\tvar isUnc = Boolean(device && device.charAt(1) !== ':');\n\n\t// UNC paths are always absolute\n\treturn Boolean(result[2] || isUnc);\n}\n\nmodule.exports = process.platform === 'win32' ? win32 : posix;\nmodule.exports.posix = posix;\nmodule.exports.win32 = win32;\n","const {promisify} = require(\"util\");\r\nconst tmp = require(\"tmp\");\r\n\r\n// file\r\nmodule.exports.fileSync = tmp.fileSync;\r\nconst fileWithOptions = promisify((options, cb) =>\r\n  tmp.file(options, (err, path, fd, cleanup) =>\r\n    err ? cb(err) : cb(undefined, { path, fd, cleanup: promisify(cleanup) })\r\n  )\r\n);\r\nmodule.exports.file = async (options) => fileWithOptions(options);\r\n\r\nmodule.exports.withFile = async function withFile(fn, options) {\r\n  const { path, fd, cleanup } = await module.exports.file(options);\r\n  try {\r\n    return await fn({ path, fd });\r\n  } finally {\r\n    await cleanup();\r\n  }\r\n};\r\n\r\n\r\n// directory\r\nmodule.exports.dirSync = tmp.dirSync;\r\nconst dirWithOptions = promisify((options, cb) =>\r\n  tmp.dir(options, (err, path, cleanup) =>\r\n    err ? cb(err) : cb(undefined, { path, cleanup: promisify(cleanup) })\r\n  )\r\n);\r\nmodule.exports.dir = async (options) => dirWithOptions(options);\r\n\r\nmodule.exports.withDir = async function withDir(fn, options) {\r\n  const { path, cleanup } = await module.exports.dir(options);\r\n  try {\r\n    return await fn({ path });\r\n  } finally {\r\n    await cleanup();\r\n  }\r\n};\r\n\r\n\r\n// name generation\r\nmodule.exports.tmpNameSync = tmp.tmpNameSync;\r\nmodule.exports.tmpName = promisify(tmp.tmpName);\r\n\r\nmodule.exports.tmpdir = tmp.tmpdir;\r\n\r\nmodule.exports.setGracefulCleanup = tmp.setGracefulCleanup;\r\n","/*!\n * Tmp\n *\n * Copyright (c) 2011-2017 KARASZI Istvan <github@spam.raszi.hu>\n *\n * MIT Licensed\n */\n\n/*\n * Module dependencies.\n */\nconst fs = require('fs');\nconst os = require('os');\nconst path = require('path');\nconst crypto = require('crypto');\nconst _c = fs.constants && os.constants ?\n  { fs: fs.constants, os: os.constants } :\n  process.binding('constants');\nconst rimraf = require('rimraf');\n\n/*\n * The working inner variables.\n */\nconst\n  // the random characters to choose from\n  RANDOM_CHARS = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz',\n\n  TEMPLATE_PATTERN = /XXXXXX/,\n\n  DEFAULT_TRIES = 3,\n\n  CREATE_FLAGS = (_c.O_CREAT || _c.fs.O_CREAT) | (_c.O_EXCL || _c.fs.O_EXCL) | (_c.O_RDWR || _c.fs.O_RDWR),\n\n  EBADF = _c.EBADF || _c.os.errno.EBADF,\n  ENOENT = _c.ENOENT || _c.os.errno.ENOENT,\n\n  DIR_MODE = 448 /* 0o700 */,\n  FILE_MODE = 384 /* 0o600 */,\n\n  EXIT = 'exit',\n\n  SIGINT = 'SIGINT',\n\n  // this will hold the objects need to be removed on exit\n  _removeObjects = [];\n\nvar\n  _gracefulCleanup = false;\n\n/**\n * Random name generator based on crypto.\n * Adapted from http://blog.tompawlak.org/how-to-generate-random-values-nodejs-javascript\n *\n * @param {number} howMany\n * @returns {string} the generated random name\n * @private\n */\nfunction _randomChars(howMany) {\n  var\n    value = [],\n    rnd = null;\n\n  // make sure that we do not fail because we ran out of entropy\n  try {\n    rnd = crypto.randomBytes(howMany);\n  } catch (e) {\n    rnd = crypto.pseudoRandomBytes(howMany);\n  }\n\n  for (var i = 0; i < howMany; i++) {\n    value.push(RANDOM_CHARS[rnd[i] % RANDOM_CHARS.length]);\n  }\n\n  return value.join('');\n}\n\n/**\n * Checks whether the `obj` parameter is defined or not.\n *\n * @param {Object} obj\n * @returns {boolean} true if the object is undefined\n * @private\n */\nfunction _isUndefined(obj) {\n  return typeof obj === 'undefined';\n}\n\n/**\n * Parses the function arguments.\n *\n * This function helps to have optional arguments.\n *\n * @param {(Options|Function)} options\n * @param {Function} callback\n * @returns {Array} parsed arguments\n * @private\n */\nfunction _parseArguments(options, callback) {\n  /* istanbul ignore else */\n  if (typeof options === 'function') {\n    return [{}, options];\n  }\n\n  /* istanbul ignore else */\n  if (_isUndefined(options)) {\n    return [{}, callback];\n  }\n\n  return [options, callback];\n}\n\n/**\n * Generates a new temporary name.\n *\n * @param {Object} opts\n * @returns {string} the new random name according to opts\n * @private\n */\nfunction _generateTmpName(opts) {\n\n  const tmpDir = _getTmpDir();\n\n  // fail early on missing tmp dir\n  if (isBlank(opts.dir) && isBlank(tmpDir)) {\n    throw new Error('No tmp dir specified');\n  }\n\n  /* istanbul ignore else */\n  if (!isBlank(opts.name)) {\n    return path.join(opts.dir || tmpDir, opts.name);\n  }\n\n  // mkstemps like template\n  // opts.template has already been guarded in tmpName() below\n  /* istanbul ignore else */\n  if (opts.template) {\n    var template = opts.template;\n    // make sure that we prepend the tmp path if none was given\n    /* istanbul ignore else */\n    if (path.basename(template) === template)\n      template = path.join(opts.dir || tmpDir, template);\n    return template.replace(TEMPLATE_PATTERN, _randomChars(6));\n  }\n\n  // prefix and postfix\n  const name = [\n    (isBlank(opts.prefix) ? 'tmp-' : opts.prefix),\n    process.pid,\n    _randomChars(12),\n    (opts.postfix ? opts.postfix : '')\n  ].join('');\n\n  return path.join(opts.dir || tmpDir, name);\n}\n\n/**\n * Gets a temporary file name.\n *\n * @param {(Options|tmpNameCallback)} options options or callback\n * @param {?tmpNameCallback} callback the callback function\n */\nfunction tmpName(options, callback) {\n  var\n    args = _parseArguments(options, callback),\n    opts = args[0],\n    cb = args[1],\n    tries = !isBlank(opts.name) ? 1 : opts.tries || DEFAULT_TRIES;\n\n  /* istanbul ignore else */\n  if (isNaN(tries) || tries < 0)\n    return cb(new Error('Invalid tries'));\n\n  /* istanbul ignore else */\n  if (opts.template && !opts.template.match(TEMPLATE_PATTERN))\n    return cb(new Error('Invalid template provided'));\n\n  (function _getUniqueName() {\n    try {\n      const name = _generateTmpName(opts);\n\n      // check whether the path exists then retry if needed\n      fs.stat(name, function (err) {\n        /* istanbul ignore else */\n        if (!err) {\n          /* istanbul ignore else */\n          if (tries-- > 0) return _getUniqueName();\n\n          return cb(new Error('Could not get a unique tmp filename, max tries reached ' + name));\n        }\n\n        cb(null, name);\n      });\n    } catch (err) {\n      cb(err);\n    }\n  }());\n}\n\n/**\n * Synchronous version of tmpName.\n *\n * @param {Object} options\n * @returns {string} the generated random name\n * @throws {Error} if the options are invalid or could not generate a filename\n */\nfunction tmpNameSync(options) {\n  var\n    args = _parseArguments(options),\n    opts = args[0],\n    tries = !isBlank(opts.name) ? 1 : opts.tries || DEFAULT_TRIES;\n\n  /* istanbul ignore else */\n  if (isNaN(tries) || tries < 0)\n    throw new Error('Invalid tries');\n\n  /* istanbul ignore else */\n  if (opts.template && !opts.template.match(TEMPLATE_PATTERN))\n    throw new Error('Invalid template provided');\n\n  do {\n    const name = _generateTmpName(opts);\n    try {\n      fs.statSync(name);\n    } catch (e) {\n      return name;\n    }\n  } while (tries-- > 0);\n\n  throw new Error('Could not get a unique tmp filename, max tries reached');\n}\n\n/**\n * Creates and opens a temporary file.\n *\n * @param {(Options|fileCallback)} options the config options or the callback function\n * @param {?fileCallback} callback\n */\nfunction file(options, callback) {\n  var\n    args = _parseArguments(options, callback),\n    opts = args[0],\n    cb = args[1];\n\n  // gets a temporary filename\n  tmpName(opts, function _tmpNameCreated(err, name) {\n    /* istanbul ignore else */\n    if (err) return cb(err);\n\n    // create and open the file\n    fs.open(name, CREATE_FLAGS, opts.mode || FILE_MODE, function _fileCreated(err, fd) {\n      /* istanbul ignore else */\n      if (err) return cb(err);\n\n      if (opts.discardDescriptor) {\n        return fs.close(fd, function _discardCallback(err) {\n          /* istanbul ignore else */\n          if (err) {\n            // Low probability, and the file exists, so this could be\n            // ignored.  If it isn't we certainly need to unlink the\n            // file, and if that fails too its error is more\n            // important.\n            try {\n              fs.unlinkSync(name);\n            } catch (e) {\n              if (!isENOENT(e)) {\n                err = e;\n              }\n            }\n            return cb(err);\n          }\n          cb(null, name, undefined, _prepareTmpFileRemoveCallback(name, -1, opts));\n        });\n      }\n      /* istanbul ignore else */\n      if (opts.detachDescriptor) {\n        return cb(null, name, fd, _prepareTmpFileRemoveCallback(name, -1, opts));\n      }\n      cb(null, name, fd, _prepareTmpFileRemoveCallback(name, fd, opts));\n    });\n  });\n}\n\n/**\n * Synchronous version of file.\n *\n * @param {Options} options\n * @returns {FileSyncObject} object consists of name, fd and removeCallback\n * @throws {Error} if cannot create a file\n */\nfunction fileSync(options) {\n  var\n    args = _parseArguments(options),\n    opts = args[0];\n\n  const discardOrDetachDescriptor = opts.discardDescriptor || opts.detachDescriptor;\n  const name = tmpNameSync(opts);\n  var fd = fs.openSync(name, CREATE_FLAGS, opts.mode || FILE_MODE);\n  /* istanbul ignore else */\n  if (opts.discardDescriptor) {\n    fs.closeSync(fd);\n    fd = undefined;\n  }\n\n  return {\n    name: name,\n    fd: fd,\n    removeCallback: _prepareTmpFileRemoveCallback(name, discardOrDetachDescriptor ? -1 : fd, opts)\n  };\n}\n\n/**\n * Creates a temporary directory.\n *\n * @param {(Options|dirCallback)} options the options or the callback function\n * @param {?dirCallback} callback\n */\nfunction dir(options, callback) {\n  var\n    args = _parseArguments(options, callback),\n    opts = args[0],\n    cb = args[1];\n\n  // gets a temporary filename\n  tmpName(opts, function _tmpNameCreated(err, name) {\n    /* istanbul ignore else */\n    if (err) return cb(err);\n\n    // create the directory\n    fs.mkdir(name, opts.mode || DIR_MODE, function _dirCreated(err) {\n      /* istanbul ignore else */\n      if (err) return cb(err);\n\n      cb(null, name, _prepareTmpDirRemoveCallback(name, opts));\n    });\n  });\n}\n\n/**\n * Synchronous version of dir.\n *\n * @param {Options} options\n * @returns {DirSyncObject} object consists of name and removeCallback\n * @throws {Error} if it cannot create a directory\n */\nfunction dirSync(options) {\n  var\n    args = _parseArguments(options),\n    opts = args[0];\n\n  const name = tmpNameSync(opts);\n  fs.mkdirSync(name, opts.mode || DIR_MODE);\n\n  return {\n    name: name,\n    removeCallback: _prepareTmpDirRemoveCallback(name, opts)\n  };\n}\n\n/**\n * Removes files asynchronously.\n *\n * @param {Object} fdPath\n * @param {Function} next\n * @private\n */\nfunction _removeFileAsync(fdPath, next) {\n  const _handler = function (err) {\n    if (err && !isENOENT(err)) {\n      // reraise any unanticipated error\n      return next(err);\n    }\n    next();\n  }\n\n  if (0 <= fdPath[0])\n    fs.close(fdPath[0], function (err) {\n      fs.unlink(fdPath[1], _handler);\n    });\n  else fs.unlink(fdPath[1], _handler);\n}\n\n/**\n * Removes files synchronously.\n *\n * @param {Object} fdPath\n * @private\n */\nfunction _removeFileSync(fdPath) {\n  try {\n    if (0 <= fdPath[0]) fs.closeSync(fdPath[0]);\n  } catch (e) {\n    // reraise any unanticipated error\n    if (!isEBADF(e) && !isENOENT(e)) throw e;\n  } finally {\n    try {\n      fs.unlinkSync(fdPath[1]);\n    }\n    catch (e) {\n      // reraise any unanticipated error\n      if (!isENOENT(e)) throw e;\n    }\n  }\n}\n\n/**\n * Prepares the callback for removal of the temporary file.\n *\n * @param {string} name the path of the file\n * @param {number} fd file descriptor\n * @param {Object} opts\n * @returns {fileCallback}\n * @private\n */\nfunction _prepareTmpFileRemoveCallback(name, fd, opts) {\n  const removeCallbackSync = _prepareRemoveCallback(_removeFileSync, [fd, name]);\n  const removeCallback = _prepareRemoveCallback(_removeFileAsync, [fd, name], removeCallbackSync);\n\n  if (!opts.keep) _removeObjects.unshift(removeCallbackSync);\n\n  return removeCallback;\n}\n\n/**\n * Simple wrapper for rimraf.\n *\n * @param {string} dirPath\n * @param {Function} next\n * @private\n */\nfunction _rimrafRemoveDirWrapper(dirPath, next) {\n  rimraf(dirPath, next);\n}\n\n/**\n * Simple wrapper for rimraf.sync.\n *\n * @param {string} dirPath\n * @private\n */\nfunction _rimrafRemoveDirSyncWrapper(dirPath, next) {\n  try {\n    return next(null, rimraf.sync(dirPath));\n  } catch (err) {\n    return next(err);\n  }\n}\n\n/**\n * Prepares the callback for removal of the temporary directory.\n *\n * @param {string} name\n * @param {Object} opts\n * @returns {Function} the callback\n * @private\n */\nfunction _prepareTmpDirRemoveCallback(name, opts) {\n  const removeFunction = opts.unsafeCleanup ? _rimrafRemoveDirWrapper : fs.rmdir.bind(fs);\n  const removeFunctionSync = opts.unsafeCleanup ? _rimrafRemoveDirSyncWrapper : fs.rmdirSync.bind(fs);\n  const removeCallbackSync = _prepareRemoveCallback(removeFunctionSync, name);\n  const removeCallback = _prepareRemoveCallback(removeFunction, name, removeCallbackSync);\n  if (!opts.keep) _removeObjects.unshift(removeCallbackSync);\n\n  return removeCallback;\n}\n\n/**\n * Creates a guarded function wrapping the removeFunction call.\n *\n * @param {Function} removeFunction\n * @param {Object} arg\n * @returns {Function}\n * @private\n */\nfunction _prepareRemoveCallback(removeFunction, arg, cleanupCallbackSync) {\n  var called = false;\n\n  return function _cleanupCallback(next) {\n    next = next || function () {};\n    if (!called) {\n      const toRemove = cleanupCallbackSync || _cleanupCallback;\n      const index = _removeObjects.indexOf(toRemove);\n      /* istanbul ignore else */\n      if (index >= 0) _removeObjects.splice(index, 1);\n\n      called = true;\n      // sync?\n      if (removeFunction.length === 1) {\n        try {\n          removeFunction(arg);\n          return next(null);\n        }\n        catch (err) {\n          // if no next is provided and since we are\n          // in silent cleanup mode on process exit,\n          // we will ignore the error\n          return next(err);\n        }\n      } else return removeFunction(arg, next);\n    } else return next(new Error('cleanup callback has already been called'));\n  };\n}\n\n/**\n * The garbage collector.\n *\n * @private\n */\nfunction _garbageCollector() {\n  /* istanbul ignore else */\n  if (!_gracefulCleanup) return;\n\n  // the function being called removes itself from _removeObjects,\n  // loop until _removeObjects is empty\n  while (_removeObjects.length) {\n    try {\n      _removeObjects[0]();\n    } catch (e) {\n      // already removed?\n    }\n  }\n}\n\n/**\n * Helper for testing against EBADF to compensate changes made to Node 7.x under Windows.\n */\nfunction isEBADF(error) {\n  return isExpectedError(error, -EBADF, 'EBADF');\n}\n\n/**\n * Helper for testing against ENOENT to compensate changes made to Node 7.x under Windows.\n */\nfunction isENOENT(error) {\n  return isExpectedError(error, -ENOENT, 'ENOENT');\n}\n\n/**\n * Helper to determine whether the expected error code matches the actual code and errno,\n * which will differ between the supported node versions.\n *\n * - Node >= 7.0:\n *   error.code {string}\n *   error.errno {string|number} any numerical value will be negated\n *\n * - Node >= 6.0 < 7.0:\n *   error.code {string}\n *   error.errno {number} negated\n *\n * - Node >= 4.0 < 6.0: introduces SystemError\n *   error.code {string}\n *   error.errno {number} negated\n *\n * - Node >= 0.10 < 4.0:\n *   error.code {number} negated\n *   error.errno n/a\n */\nfunction isExpectedError(error, code, errno) {\n  return error.code === code || error.code === errno;\n}\n\n/**\n * Helper which determines whether a string s is blank, that is undefined, or empty or null.\n *\n * @private\n * @param {string} s\n * @returns {Boolean} true whether the string s is blank, false otherwise\n */\nfunction isBlank(s) {\n  return s === null || s === undefined || !s.trim();\n}\n\n/**\n * Sets the graceful cleanup.\n */\nfunction setGracefulCleanup() {\n  _gracefulCleanup = true;\n}\n\n/**\n * Returns the currently configured tmp dir from os.tmpdir().\n *\n * @private\n * @returns {string} the currently configured tmp dir\n */\nfunction _getTmpDir() {\n  return os.tmpdir();\n}\n\n/**\n * If there are multiple different versions of tmp in place, make sure that\n * we recognize the old listeners.\n *\n * @param {Function} listener\n * @private\n * @returns {Boolean} true whether listener is a legacy listener\n */\nfunction _is_legacy_listener(listener) {\n  return (listener.name === '_exit' || listener.name === '_uncaughtExceptionThrown')\n    && listener.toString().indexOf('_garbageCollector();') > -1;\n}\n\n/**\n * Safely install SIGINT listener.\n *\n * NOTE: this will only work on OSX and Linux.\n *\n * @private\n */\nfunction _safely_install_sigint_listener() {\n\n  const listeners = process.listeners(SIGINT);\n  const existingListeners = [];\n  for (let i = 0, length = listeners.length; i < length; i++) {\n    const lstnr = listeners[i];\n    /* istanbul ignore else */\n    if (lstnr.name === '_tmp$sigint_listener') {\n      existingListeners.push(lstnr);\n      process.removeListener(SIGINT, lstnr);\n    }\n  }\n  process.on(SIGINT, function _tmp$sigint_listener(doExit) {\n    for (let i = 0, length = existingListeners.length; i < length; i++) {\n      // let the existing listener do the garbage collection (e.g. jest sandbox)\n      try {\n        existingListeners[i](false);\n      } catch (err) {\n        // ignore\n      }\n    }\n    try {\n      // force the garbage collector even it is called again in the exit listener\n      _garbageCollector();\n    } finally {\n      if (!!doExit) {\n        process.exit(0);\n      }\n    }\n  });\n}\n\n/**\n * Safely install process exit listener.\n *\n * @private\n */\nfunction _safely_install_exit_listener() {\n  const listeners = process.listeners(EXIT);\n\n  // collect any existing listeners\n  const existingListeners = [];\n  for (let i = 0, length = listeners.length; i < length; i++) {\n    const lstnr = listeners[i];\n    /* istanbul ignore else */\n    // TODO: remove support for legacy listeners once release 1.0.0 is out\n    if (lstnr.name === '_tmp$safe_listener' || _is_legacy_listener(lstnr)) {\n      // we must forget about the uncaughtException listener, hopefully it is ours\n      if (lstnr.name !== '_uncaughtExceptionThrown') {\n        existingListeners.push(lstnr);\n      }\n      process.removeListener(EXIT, lstnr);\n    }\n  }\n  // TODO: what was the data parameter good for?\n  process.addListener(EXIT, function _tmp$safe_listener(data) {\n    for (let i = 0, length = existingListeners.length; i < length; i++) {\n      // let the existing listener do the garbage collection (e.g. jest sandbox)\n      try {\n        existingListeners[i](data);\n      } catch (err) {\n        // ignore\n      }\n    }\n    _garbageCollector();\n  });\n}\n\n_safely_install_exit_listener();\n_safely_install_sigint_listener();\n\n/**\n * Configuration options.\n *\n * @typedef {Object} Options\n * @property {?number} tries the number of tries before give up the name generation\n * @property {?string} template the \"mkstemp\" like filename template\n * @property {?string} name fix name\n * @property {?string} dir the tmp directory to use\n * @property {?string} prefix prefix for the generated name\n * @property {?string} postfix postfix for the generated name\n * @property {?boolean} unsafeCleanup recursively removes the created temporary directory, even when it's not empty\n */\n\n/**\n * @typedef {Object} FileSyncObject\n * @property {string} name the name of the file\n * @property {string} fd the file descriptor\n * @property {fileCallback} removeCallback the callback function to remove the file\n */\n\n/**\n * @typedef {Object} DirSyncObject\n * @property {string} name the name of the directory\n * @property {fileCallback} removeCallback the callback function to remove the directory\n */\n\n/**\n * @callback tmpNameCallback\n * @param {?Error} err the error object if anything goes wrong\n * @param {string} name the temporary file name\n */\n\n/**\n * @callback fileCallback\n * @param {?Error} err the error object if anything goes wrong\n * @param {string} name the temporary file name\n * @param {number} fd the file descriptor\n * @param {cleanupCallback} fn the cleanup callback function\n */\n\n/**\n * @callback dirCallback\n * @param {?Error} err the error object if anything goes wrong\n * @param {string} name the temporary file name\n * @param {cleanupCallback} fn the cleanup callback function\n */\n\n/**\n * Removes the temporary created file or directory.\n *\n * @callback cleanupCallback\n * @param {simpleCallback} [next] function to call after entry was removed\n */\n\n/**\n * Callback function for function composition.\n * @see {@link https://github.com/raszi/node-tmp/issues/57|raszi/node-tmp#57}\n *\n * @callback simpleCallback\n */\n\n// exporting all the needed methods\n\n// evaluate os.tmpdir() lazily, mainly for simplifying testing but it also will\n// allow users to reconfigure the temporary directory\nObject.defineProperty(module.exports, 'tmpdir', {\n  enumerable: true,\n  configurable: false,\n  get: function () {\n    return _getTmpDir();\n  }\n});\n\nmodule.exports.dir = dir;\nmodule.exports.dirSync = dirSync;\n\nmodule.exports.file = file;\nmodule.exports.fileSync = fileSync;\n\nmodule.exports.tmpName = tmpName;\nmodule.exports.tmpNameSync = tmpNameSync;\n\nmodule.exports.setGracefulCleanup = setGracefulCleanup;\n","module.exports = rimraf\nrimraf.sync = rimrafSync\n\nvar assert = require(\"assert\")\nvar path = require(\"path\")\nvar fs = require(\"fs\")\nvar glob = undefined\ntry {\n  glob = require(\"glob\")\n} catch (_err) {\n  // treat glob as optional.\n}\nvar _0666 = parseInt('666', 8)\n\nvar defaultGlobOpts = {\n  nosort: true,\n  silent: true\n}\n\n// for EMFILE handling\nvar timeout = 0\n\nvar isWindows = (process.platform === \"win32\")\n\nfunction defaults (options) {\n  var methods = [\n    'unlink',\n    'chmod',\n    'stat',\n    'lstat',\n    'rmdir',\n    'readdir'\n  ]\n  methods.forEach(function(m) {\n    options[m] = options[m] || fs[m]\n    m = m + 'Sync'\n    options[m] = options[m] || fs[m]\n  })\n\n  options.maxBusyTries = options.maxBusyTries || 3\n  options.emfileWait = options.emfileWait || 1000\n  if (options.glob === false) {\n    options.disableGlob = true\n  }\n  if (options.disableGlob !== true && glob === undefined) {\n    throw Error('glob dependency not found, set `options.disableGlob = true` if intentional')\n  }\n  options.disableGlob = options.disableGlob || false\n  options.glob = options.glob || defaultGlobOpts\n}\n\nfunction rimraf (p, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = {}\n  }\n\n  assert(p, 'rimraf: missing path')\n  assert.equal(typeof p, 'string', 'rimraf: path should be a string')\n  assert.equal(typeof cb, 'function', 'rimraf: callback function required')\n  assert(options, 'rimraf: invalid options argument provided')\n  assert.equal(typeof options, 'object', 'rimraf: options should be object')\n\n  defaults(options)\n\n  var busyTries = 0\n  var errState = null\n  var n = 0\n\n  if (options.disableGlob || !glob.hasMagic(p))\n    return afterGlob(null, [p])\n\n  options.lstat(p, function (er, stat) {\n    if (!er)\n      return afterGlob(null, [p])\n\n    glob(p, options.glob, afterGlob)\n  })\n\n  function next (er) {\n    errState = errState || er\n    if (--n === 0)\n      cb(errState)\n  }\n\n  function afterGlob (er, results) {\n    if (er)\n      return cb(er)\n\n    n = results.length\n    if (n === 0)\n      return cb()\n\n    results.forEach(function (p) {\n      rimraf_(p, options, function CB (er) {\n        if (er) {\n          if ((er.code === \"EBUSY\" || er.code === \"ENOTEMPTY\" || er.code === \"EPERM\") &&\n              busyTries < options.maxBusyTries) {\n            busyTries ++\n            var time = busyTries * 100\n            // try again, with the same exact callback as this one.\n            return setTimeout(function () {\n              rimraf_(p, options, CB)\n            }, time)\n          }\n\n          // this one won't happen if graceful-fs is used.\n          if (er.code === \"EMFILE\" && timeout < options.emfileWait) {\n            return setTimeout(function () {\n              rimraf_(p, options, CB)\n            }, timeout ++)\n          }\n\n          // already gone\n          if (er.code === \"ENOENT\") er = null\n        }\n\n        timeout = 0\n        next(er)\n      })\n    })\n  }\n}\n\n// Two possible strategies.\n// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR\n// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR\n//\n// Both result in an extra syscall when you guess wrong.  However, there\n// are likely far more normal files in the world than directories.  This\n// is based on the assumption that a the average number of files per\n// directory is >= 1.\n//\n// If anyone ever complains about this, then I guess the strategy could\n// be made configurable somehow.  But until then, YAGNI.\nfunction rimraf_ (p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // sunos lets the root user unlink directories, which is... weird.\n  // so we have to lstat here and make sure it's not a dir.\n  options.lstat(p, function (er, st) {\n    if (er && er.code === \"ENOENT\")\n      return cb(null)\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er && er.code === \"EPERM\" && isWindows)\n      fixWinEPERM(p, options, er, cb)\n\n    if (st && st.isDirectory())\n      return rmdir(p, options, er, cb)\n\n    options.unlink(p, function (er) {\n      if (er) {\n        if (er.code === \"ENOENT\")\n          return cb(null)\n        if (er.code === \"EPERM\")\n          return (isWindows)\n            ? fixWinEPERM(p, options, er, cb)\n            : rmdir(p, options, er, cb)\n        if (er.code === \"EISDIR\")\n          return rmdir(p, options, er, cb)\n      }\n      return cb(er)\n    })\n  })\n}\n\nfunction fixWinEPERM (p, options, er, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n  if (er)\n    assert(er instanceof Error)\n\n  options.chmod(p, _0666, function (er2) {\n    if (er2)\n      cb(er2.code === \"ENOENT\" ? null : er)\n    else\n      options.stat(p, function(er3, stats) {\n        if (er3)\n          cb(er3.code === \"ENOENT\" ? null : er)\n        else if (stats.isDirectory())\n          rmdir(p, options, er, cb)\n        else\n          options.unlink(p, cb)\n      })\n  })\n}\n\nfunction fixWinEPERMSync (p, options, er) {\n  assert(p)\n  assert(options)\n  if (er)\n    assert(er instanceof Error)\n\n  try {\n    options.chmodSync(p, _0666)\n  } catch (er2) {\n    if (er2.code === \"ENOENT\")\n      return\n    else\n      throw er\n  }\n\n  try {\n    var stats = options.statSync(p)\n  } catch (er3) {\n    if (er3.code === \"ENOENT\")\n      return\n    else\n      throw er\n  }\n\n  if (stats.isDirectory())\n    rmdirSync(p, options, er)\n  else\n    options.unlinkSync(p)\n}\n\nfunction rmdir (p, options, originalEr, cb) {\n  assert(p)\n  assert(options)\n  if (originalEr)\n    assert(originalEr instanceof Error)\n  assert(typeof cb === 'function')\n\n  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)\n  // if we guessed wrong, and it's not a directory, then\n  // raise the original error.\n  options.rmdir(p, function (er) {\n    if (er && (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\" || er.code === \"EPERM\"))\n      rmkids(p, options, cb)\n    else if (er && er.code === \"ENOTDIR\")\n      cb(originalEr)\n    else\n      cb(er)\n  })\n}\n\nfunction rmkids(p, options, cb) {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.readdir(p, function (er, files) {\n    if (er)\n      return cb(er)\n    var n = files.length\n    if (n === 0)\n      return options.rmdir(p, cb)\n    var errState\n    files.forEach(function (f) {\n      rimraf(path.join(p, f), options, function (er) {\n        if (errState)\n          return\n        if (er)\n          return cb(errState = er)\n        if (--n === 0)\n          options.rmdir(p, cb)\n      })\n    })\n  })\n}\n\n// this looks simpler, and is strictly *faster*, but will\n// tie up the JavaScript thread and fail on excessively\n// deep directory trees.\nfunction rimrafSync (p, options) {\n  options = options || {}\n  defaults(options)\n\n  assert(p, 'rimraf: missing path')\n  assert.equal(typeof p, 'string', 'rimraf: path should be a string')\n  assert(options, 'rimraf: missing options')\n  assert.equal(typeof options, 'object', 'rimraf: options should be object')\n\n  var results\n\n  if (options.disableGlob || !glob.hasMagic(p)) {\n    results = [p]\n  } else {\n    try {\n      options.lstatSync(p)\n      results = [p]\n    } catch (er) {\n      results = glob.sync(p, options.glob)\n    }\n  }\n\n  if (!results.length)\n    return\n\n  for (var i = 0; i < results.length; i++) {\n    var p = results[i]\n\n    try {\n      var st = options.lstatSync(p)\n    } catch (er) {\n      if (er.code === \"ENOENT\")\n        return\n\n      // Windows can EPERM on stat.  Life is suffering.\n      if (er.code === \"EPERM\" && isWindows)\n        fixWinEPERMSync(p, options, er)\n    }\n\n    try {\n      // sunos lets the root user unlink directories, which is... weird.\n      if (st && st.isDirectory())\n        rmdirSync(p, options, null)\n      else\n        options.unlinkSync(p)\n    } catch (er) {\n      if (er.code === \"ENOENT\")\n        return\n      if (er.code === \"EPERM\")\n        return isWindows ? fixWinEPERMSync(p, options, er) : rmdirSync(p, options, er)\n      if (er.code !== \"EISDIR\")\n        throw er\n\n      rmdirSync(p, options, er)\n    }\n  }\n}\n\nfunction rmdirSync (p, options, originalEr) {\n  assert(p)\n  assert(options)\n  if (originalEr)\n    assert(originalEr instanceof Error)\n\n  try {\n    options.rmdirSync(p)\n  } catch (er) {\n    if (er.code === \"ENOENT\")\n      return\n    if (er.code === \"ENOTDIR\")\n      throw originalEr\n    if (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\" || er.code === \"EPERM\")\n      rmkidsSync(p, options)\n  }\n}\n\nfunction rmkidsSync (p, options) {\n  assert(p)\n  assert(options)\n  options.readdirSync(p).forEach(function (f) {\n    rimrafSync(path.join(p, f), options)\n  })\n\n  // We only end up here once we got ENOTEMPTY at least once, and\n  // at this point, we are guaranteed to have removed all the kids.\n  // So, we know that it won't be ENOENT or ENOTDIR or anything else.\n  // try really hard to delete stuff on windows, because it has a\n  // PROFOUNDLY annoying habit of not closing handles promptly when\n  // files are deleted, resulting in spurious ENOTEMPTY errors.\n  var retries = isWindows ? 100 : 1\n  var i = 0\n  do {\n    var threw = true\n    try {\n      var ret = options.rmdirSync(p, options)\n      threw = false\n      return ret\n    } finally {\n      if (++i < retries && threw)\n        continue\n    }\n  } while (true)\n}\n","module.exports = require('./lib/tunnel');\n","'use strict';\n\nvar net = require('net');\nvar tls = require('tls');\nvar http = require('http');\nvar https = require('https');\nvar events = require('events');\nvar assert = require('assert');\nvar util = require('util');\n\n\nexports.httpOverHttp = httpOverHttp;\nexports.httpsOverHttp = httpsOverHttp;\nexports.httpOverHttps = httpOverHttps;\nexports.httpsOverHttps = httpsOverHttps;\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  return agent;\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  return agent;\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this;\n  self.options = options || {};\n  self.proxyOptions = self.options.proxy || {};\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets;\n  self.requests = [];\n  self.sockets = [];\n\n  self.on('free', function onFree(socket, host, port, localAddress) {\n    var options = toOptions(host, port, localAddress);\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i];\n      if (pending.host === options.host && pending.port === options.port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1);\n        pending.request.onSocket(socket);\n        return;\n      }\n    }\n    socket.destroy();\n    self.removeSocket(socket);\n  });\n}\nutil.inherits(TunnelingAgent, events.EventEmitter);\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, host, port, localAddress) {\n  var self = this;\n  var options = mergeOptions({request: req}, self.options, toOptions(host, port, localAddress));\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push(options);\n    return;\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createSocket(options, function(socket) {\n    socket.on('free', onFree);\n    socket.on('close', onCloseOrRemove);\n    socket.on('agentRemove', onCloseOrRemove);\n    req.onSocket(socket);\n\n    function onFree() {\n      self.emit('free', socket, options);\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket(socket);\n      socket.removeListener('free', onFree);\n      socket.removeListener('close', onCloseOrRemove);\n      socket.removeListener('agentRemove', onCloseOrRemove);\n    }\n  });\n};\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this;\n  var placeholder = {};\n  self.sockets.push(placeholder);\n\n  var connectOptions = mergeOptions({}, self.proxyOptions, {\n    method: 'CONNECT',\n    path: options.host + ':' + options.port,\n    agent: false,\n    headers: {\n      host: options.host + ':' + options.port\n    }\n  });\n  if (options.localAddress) {\n    connectOptions.localAddress = options.localAddress;\n  }\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {};\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        new Buffer(connectOptions.proxyAuth).toString('base64');\n  }\n\n  debug('making CONNECT request');\n  var connectReq = self.request(connectOptions);\n  connectReq.useChunkedEncodingByDefault = false; // for v0.6\n  connectReq.once('response', onResponse); // for v0.6\n  connectReq.once('upgrade', onUpgrade);   // for v0.6\n  connectReq.once('connect', onConnect);   // for v0.7 or later\n  connectReq.once('error', onError);\n  connectReq.end();\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true;\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head);\n    });\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners();\n    socket.removeAllListeners();\n\n    if (res.statusCode !== 200) {\n      debug('tunneling socket could not be established, statusCode=%d',\n        res.statusCode);\n      socket.destroy();\n      var error = new Error('tunneling socket could not be established, ' +\n        'statusCode=' + res.statusCode);\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    if (head.length > 0) {\n      debug('got illegal response body from proxy');\n      socket.destroy();\n      var error = new Error('got illegal response body from proxy');\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    debug('tunneling connection has established');\n    self.sockets[self.sockets.indexOf(placeholder)] = socket;\n    return cb(socket);\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners();\n\n    debug('tunneling socket could not be established, cause=%s\\n',\n          cause.message, cause.stack);\n    var error = new Error('tunneling socket could not be established, ' +\n                          'cause=' + cause.message);\n    error.code = 'ECONNRESET';\n    options.request.emit('error', error);\n    self.removeSocket(placeholder);\n  }\n};\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) {\n    return;\n  }\n  this.sockets.splice(pos, 1);\n\n  var pending = this.requests.shift();\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(pending, function(socket) {\n      pending.request.onSocket(socket);\n    });\n  }\n};\n\nfunction createSecureSocket(options, cb) {\n  var self = this;\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    var hostHeader = options.request.getHeader('host');\n    var tlsOptions = mergeOptions({}, self.options, {\n      socket: socket,\n      servername: hostHeader ? hostHeader.replace(/:.*$/, '') : options.host\n    });\n\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, tlsOptions);\n    self.sockets[self.sockets.indexOf(socket)] = secureSocket;\n    cb(secureSocket);\n  });\n}\n\n\nfunction toOptions(host, port, localAddress) {\n  if (typeof host === 'string') { // since v0.10\n    return {\n      host: host,\n      port: port,\n      localAddress: localAddress\n    };\n  }\n  return host; // for v0.11 or later\n}\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i];\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides);\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j];\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k];\n        }\n      }\n    }\n  }\n  return target;\n}\n\n\nvar debug;\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments);\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0];\n    } else {\n      args.unshift('TUNNEL:');\n    }\n    console.error.apply(console, args);\n  }\n} else {\n  debug = function() {};\n}\nexports.debug = debug; // for test\n","/**\n * web-streams-polyfill v3.1.1\n */\n(function (global, factory) {\n    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n    typeof define === 'function' && define.amd ? define(['exports'], factory) :\n    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.WebStreamsPolyfill = {}));\n}(this, (function (exports) { 'use strict';\n\n    /// <reference lib=\"es2015.symbol\" />\n    const SymbolPolyfill = typeof Symbol === 'function' && typeof Symbol.iterator === 'symbol' ?\n        Symbol :\n        description => `Symbol(${description})`;\n\n    /// <reference lib=\"dom\" />\n    function noop() {\n        return undefined;\n    }\n    function getGlobals() {\n        if (typeof self !== 'undefined') {\n            return self;\n        }\n        else if (typeof window !== 'undefined') {\n            return window;\n        }\n        else if (typeof global !== 'undefined') {\n            return global;\n        }\n        return undefined;\n    }\n    const globals = getGlobals();\n\n    function typeIsObject(x) {\n        return (typeof x === 'object' && x !== null) || typeof x === 'function';\n    }\n    const rethrowAssertionErrorRejection = noop;\n\n    const originalPromise = Promise;\n    const originalPromiseThen = Promise.prototype.then;\n    const originalPromiseResolve = Promise.resolve.bind(originalPromise);\n    const originalPromiseReject = Promise.reject.bind(originalPromise);\n    function newPromise(executor) {\n        return new originalPromise(executor);\n    }\n    function promiseResolvedWith(value) {\n        return originalPromiseResolve(value);\n    }\n    function promiseRejectedWith(reason) {\n        return originalPromiseReject(reason);\n    }\n    function PerformPromiseThen(promise, onFulfilled, onRejected) {\n        // There doesn't appear to be any way to correctly emulate the behaviour from JavaScript, so this is just an\n        // approximation.\n        return originalPromiseThen.call(promise, onFulfilled, onRejected);\n    }\n    function uponPromise(promise, onFulfilled, onRejected) {\n        PerformPromiseThen(PerformPromiseThen(promise, onFulfilled, onRejected), undefined, rethrowAssertionErrorRejection);\n    }\n    function uponFulfillment(promise, onFulfilled) {\n        uponPromise(promise, onFulfilled);\n    }\n    function uponRejection(promise, onRejected) {\n        uponPromise(promise, undefined, onRejected);\n    }\n    function transformPromiseWith(promise, fulfillmentHandler, rejectionHandler) {\n        return PerformPromiseThen(promise, fulfillmentHandler, rejectionHandler);\n    }\n    function setPromiseIsHandledToTrue(promise) {\n        PerformPromiseThen(promise, undefined, rethrowAssertionErrorRejection);\n    }\n    const queueMicrotask = (() => {\n        const globalQueueMicrotask = globals && globals.queueMicrotask;\n        if (typeof globalQueueMicrotask === 'function') {\n            return globalQueueMicrotask;\n        }\n        const resolvedPromise = promiseResolvedWith(undefined);\n        return (fn) => PerformPromiseThen(resolvedPromise, fn);\n    })();\n    function reflectCall(F, V, args) {\n        if (typeof F !== 'function') {\n            throw new TypeError('Argument is not a function');\n        }\n        return Function.prototype.apply.call(F, V, args);\n    }\n    function promiseCall(F, V, args) {\n        try {\n            return promiseResolvedWith(reflectCall(F, V, args));\n        }\n        catch (value) {\n            return promiseRejectedWith(value);\n        }\n    }\n\n    // Original from Chromium\n    // https://chromium.googlesource.com/chromium/src/+/0aee4434a4dba42a42abaea9bfbc0cd196a63bc1/third_party/blink/renderer/core/streams/SimpleQueue.js\n    const QUEUE_MAX_ARRAY_SIZE = 16384;\n    /**\n     * Simple queue structure.\n     *\n     * Avoids scalability issues with using a packed array directly by using\n     * multiple arrays in a linked list and keeping the array size bounded.\n     */\n    class SimpleQueue {\n        constructor() {\n            this._cursor = 0;\n            this._size = 0;\n            // _front and _back are always defined.\n            this._front = {\n                _elements: [],\n                _next: undefined\n            };\n            this._back = this._front;\n            // The cursor is used to avoid calling Array.shift().\n            // It contains the index of the front element of the array inside the\n            // front-most node. It is always in the range [0, QUEUE_MAX_ARRAY_SIZE).\n            this._cursor = 0;\n            // When there is only one node, size === elements.length - cursor.\n            this._size = 0;\n        }\n        get length() {\n            return this._size;\n        }\n        // For exception safety, this method is structured in order:\n        // 1. Read state\n        // 2. Calculate required state mutations\n        // 3. Perform state mutations\n        push(element) {\n            const oldBack = this._back;\n            let newBack = oldBack;\n            if (oldBack._elements.length === QUEUE_MAX_ARRAY_SIZE - 1) {\n                newBack = {\n                    _elements: [],\n                    _next: undefined\n                };\n            }\n            // push() is the mutation most likely to throw an exception, so it\n            // goes first.\n            oldBack._elements.push(element);\n            if (newBack !== oldBack) {\n                this._back = newBack;\n                oldBack._next = newBack;\n            }\n            ++this._size;\n        }\n        // Like push(), shift() follows the read -> calculate -> mutate pattern for\n        // exception safety.\n        shift() { // must not be called on an empty queue\n            const oldFront = this._front;\n            let newFront = oldFront;\n            const oldCursor = this._cursor;\n            let newCursor = oldCursor + 1;\n            const elements = oldFront._elements;\n            const element = elements[oldCursor];\n            if (newCursor === QUEUE_MAX_ARRAY_SIZE) {\n                newFront = oldFront._next;\n                newCursor = 0;\n            }\n            // No mutations before this point.\n            --this._size;\n            this._cursor = newCursor;\n            if (oldFront !== newFront) {\n                this._front = newFront;\n            }\n            // Permit shifted element to be garbage collected.\n            elements[oldCursor] = undefined;\n            return element;\n        }\n        // The tricky thing about forEach() is that it can be called\n        // re-entrantly. The queue may be mutated inside the callback. It is easy to\n        // see that push() within the callback has no negative effects since the end\n        // of the queue is checked for on every iteration. If shift() is called\n        // repeatedly within the callback then the next iteration may return an\n        // element that has been removed. In this case the callback will be called\n        // with undefined values until we either \"catch up\" with elements that still\n        // exist or reach the back of the queue.\n        forEach(callback) {\n            let i = this._cursor;\n            let node = this._front;\n            let elements = node._elements;\n            while (i !== elements.length || node._next !== undefined) {\n                if (i === elements.length) {\n                    node = node._next;\n                    elements = node._elements;\n                    i = 0;\n                    if (elements.length === 0) {\n                        break;\n                    }\n                }\n                callback(elements[i]);\n                ++i;\n            }\n        }\n        // Return the element that would be returned if shift() was called now,\n        // without modifying the queue.\n        peek() { // must not be called on an empty queue\n            const front = this._front;\n            const cursor = this._cursor;\n            return front._elements[cursor];\n        }\n    }\n\n    function ReadableStreamReaderGenericInitialize(reader, stream) {\n        reader._ownerReadableStream = stream;\n        stream._reader = reader;\n        if (stream._state === 'readable') {\n            defaultReaderClosedPromiseInitialize(reader);\n        }\n        else if (stream._state === 'closed') {\n            defaultReaderClosedPromiseInitializeAsResolved(reader);\n        }\n        else {\n            defaultReaderClosedPromiseInitializeAsRejected(reader, stream._storedError);\n        }\n    }\n    // A client of ReadableStreamDefaultReader and ReadableStreamBYOBReader may use these functions directly to bypass state\n    // check.\n    function ReadableStreamReaderGenericCancel(reader, reason) {\n        const stream = reader._ownerReadableStream;\n        return ReadableStreamCancel(stream, reason);\n    }\n    function ReadableStreamReaderGenericRelease(reader) {\n        if (reader._ownerReadableStream._state === 'readable') {\n            defaultReaderClosedPromiseReject(reader, new TypeError(`Reader was released and can no longer be used to monitor the stream's closedness`));\n        }\n        else {\n            defaultReaderClosedPromiseResetToRejected(reader, new TypeError(`Reader was released and can no longer be used to monitor the stream's closedness`));\n        }\n        reader._ownerReadableStream._reader = undefined;\n        reader._ownerReadableStream = undefined;\n    }\n    // Helper functions for the readers.\n    function readerLockException(name) {\n        return new TypeError('Cannot ' + name + ' a stream using a released reader');\n    }\n    // Helper functions for the ReadableStreamDefaultReader.\n    function defaultReaderClosedPromiseInitialize(reader) {\n        reader._closedPromise = newPromise((resolve, reject) => {\n            reader._closedPromise_resolve = resolve;\n            reader._closedPromise_reject = reject;\n        });\n    }\n    function defaultReaderClosedPromiseInitializeAsRejected(reader, reason) {\n        defaultReaderClosedPromiseInitialize(reader);\n        defaultReaderClosedPromiseReject(reader, reason);\n    }\n    function defaultReaderClosedPromiseInitializeAsResolved(reader) {\n        defaultReaderClosedPromiseInitialize(reader);\n        defaultReaderClosedPromiseResolve(reader);\n    }\n    function defaultReaderClosedPromiseReject(reader, reason) {\n        if (reader._closedPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(reader._closedPromise);\n        reader._closedPromise_reject(reason);\n        reader._closedPromise_resolve = undefined;\n        reader._closedPromise_reject = undefined;\n    }\n    function defaultReaderClosedPromiseResetToRejected(reader, reason) {\n        defaultReaderClosedPromiseInitializeAsRejected(reader, reason);\n    }\n    function defaultReaderClosedPromiseResolve(reader) {\n        if (reader._closedPromise_resolve === undefined) {\n            return;\n        }\n        reader._closedPromise_resolve(undefined);\n        reader._closedPromise_resolve = undefined;\n        reader._closedPromise_reject = undefined;\n    }\n\n    const AbortSteps = SymbolPolyfill('[[AbortSteps]]');\n    const ErrorSteps = SymbolPolyfill('[[ErrorSteps]]');\n    const CancelSteps = SymbolPolyfill('[[CancelSteps]]');\n    const PullSteps = SymbolPolyfill('[[PullSteps]]');\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isFinite#Polyfill\n    const NumberIsFinite = Number.isFinite || function (x) {\n        return typeof x === 'number' && isFinite(x);\n    };\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/trunc#Polyfill\n    const MathTrunc = Math.trunc || function (v) {\n        return v < 0 ? Math.ceil(v) : Math.floor(v);\n    };\n\n    // https://heycam.github.io/webidl/#idl-dictionaries\n    function isDictionary(x) {\n        return typeof x === 'object' || typeof x === 'function';\n    }\n    function assertDictionary(obj, context) {\n        if (obj !== undefined && !isDictionary(obj)) {\n            throw new TypeError(`${context} is not an object.`);\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-callback-functions\n    function assertFunction(x, context) {\n        if (typeof x !== 'function') {\n            throw new TypeError(`${context} is not a function.`);\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-object\n    function isObject(x) {\n        return (typeof x === 'object' && x !== null) || typeof x === 'function';\n    }\n    function assertObject(x, context) {\n        if (!isObject(x)) {\n            throw new TypeError(`${context} is not an object.`);\n        }\n    }\n    function assertRequiredArgument(x, position, context) {\n        if (x === undefined) {\n            throw new TypeError(`Parameter ${position} is required in '${context}'.`);\n        }\n    }\n    function assertRequiredField(x, field, context) {\n        if (x === undefined) {\n            throw new TypeError(`${field} is required in '${context}'.`);\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-unrestricted-double\n    function convertUnrestrictedDouble(value) {\n        return Number(value);\n    }\n    function censorNegativeZero(x) {\n        return x === 0 ? 0 : x;\n    }\n    function integerPart(x) {\n        return censorNegativeZero(MathTrunc(x));\n    }\n    // https://heycam.github.io/webidl/#idl-unsigned-long-long\n    function convertUnsignedLongLongWithEnforceRange(value, context) {\n        const lowerBound = 0;\n        const upperBound = Number.MAX_SAFE_INTEGER;\n        let x = Number(value);\n        x = censorNegativeZero(x);\n        if (!NumberIsFinite(x)) {\n            throw new TypeError(`${context} is not a finite number`);\n        }\n        x = integerPart(x);\n        if (x < lowerBound || x > upperBound) {\n            throw new TypeError(`${context} is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`);\n        }\n        if (!NumberIsFinite(x) || x === 0) {\n            return 0;\n        }\n        // TODO Use BigInt if supported?\n        // let xBigInt = BigInt(integerPart(x));\n        // xBigInt = BigInt.asUintN(64, xBigInt);\n        // return Number(xBigInt);\n        return x;\n    }\n\n    function assertReadableStream(x, context) {\n        if (!IsReadableStream(x)) {\n            throw new TypeError(`${context} is not a ReadableStream.`);\n        }\n    }\n\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamDefaultReader(stream) {\n        return new ReadableStreamDefaultReader(stream);\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamAddReadRequest(stream, readRequest) {\n        stream._reader._readRequests.push(readRequest);\n    }\n    function ReadableStreamFulfillReadRequest(stream, chunk, done) {\n        const reader = stream._reader;\n        const readRequest = reader._readRequests.shift();\n        if (done) {\n            readRequest._closeSteps();\n        }\n        else {\n            readRequest._chunkSteps(chunk);\n        }\n    }\n    function ReadableStreamGetNumReadRequests(stream) {\n        return stream._reader._readRequests.length;\n    }\n    function ReadableStreamHasDefaultReader(stream) {\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return false;\n        }\n        if (!IsReadableStreamDefaultReader(reader)) {\n            return false;\n        }\n        return true;\n    }\n    /**\n     * A default reader vended by a {@link ReadableStream}.\n     *\n     * @public\n     */\n    class ReadableStreamDefaultReader {\n        constructor(stream) {\n            assertRequiredArgument(stream, 1, 'ReadableStreamDefaultReader');\n            assertReadableStream(stream, 'First parameter');\n            if (IsReadableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n            }\n            ReadableStreamReaderGenericInitialize(this, stream);\n            this._readRequests = new SimpleQueue();\n        }\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed,\n         * or rejected if the stream ever errors or the reader's lock is released before the stream finishes closing.\n         */\n        get closed() {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        }\n        /**\n         * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n         */\n        cancel(reason = undefined) {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('cancel'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('cancel'));\n            }\n            return ReadableStreamReaderGenericCancel(this, reason);\n        }\n        /**\n         * Returns a promise that allows access to the next chunk from the stream's internal queue, if available.\n         *\n         * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n         */\n        read() {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('read'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('read from'));\n            }\n            let resolvePromise;\n            let rejectPromise;\n            const promise = newPromise((resolve, reject) => {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            const readRequest = {\n                _chunkSteps: chunk => resolvePromise({ value: chunk, done: false }),\n                _closeSteps: () => resolvePromise({ value: undefined, done: true }),\n                _errorSteps: e => rejectPromise(e)\n            };\n            ReadableStreamDefaultReaderRead(this, readRequest);\n            return promise;\n        }\n        /**\n         * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n         * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n         * from now on; otherwise, the reader will appear closed.\n         *\n         * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n         * the reader's {@link ReadableStreamDefaultReader.read | read()} method has not yet been settled. Attempting to\n         * do so will throw a `TypeError` and leave the reader locked to the stream.\n         */\n        releaseLock() {\n            if (!IsReadableStreamDefaultReader(this)) {\n                throw defaultReaderBrandCheckException('releaseLock');\n            }\n            if (this._ownerReadableStream === undefined) {\n                return;\n            }\n            if (this._readRequests.length > 0) {\n                throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n            }\n            ReadableStreamReaderGenericRelease(this);\n        }\n    }\n    Object.defineProperties(ReadableStreamDefaultReader.prototype, {\n        cancel: { enumerable: true },\n        read: { enumerable: true },\n        releaseLock: { enumerable: true },\n        closed: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamDefaultReader.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamDefaultReader',\n            configurable: true\n        });\n    }\n    // Abstract operations for the readers.\n    function IsReadableStreamDefaultReader(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readRequests')) {\n            return false;\n        }\n        return x instanceof ReadableStreamDefaultReader;\n    }\n    function ReadableStreamDefaultReaderRead(reader, readRequest) {\n        const stream = reader._ownerReadableStream;\n        stream._disturbed = true;\n        if (stream._state === 'closed') {\n            readRequest._closeSteps();\n        }\n        else if (stream._state === 'errored') {\n            readRequest._errorSteps(stream._storedError);\n        }\n        else {\n            stream._readableStreamController[PullSteps](readRequest);\n        }\n    }\n    // Helper functions for the ReadableStreamDefaultReader.\n    function defaultReaderBrandCheckException(name) {\n        return new TypeError(`ReadableStreamDefaultReader.prototype.${name} can only be used on a ReadableStreamDefaultReader`);\n    }\n\n    /// <reference lib=\"es2018.asynciterable\" />\n    /* eslint-disable @typescript-eslint/no-empty-function */\n    const AsyncIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf(async function* () { }).prototype);\n\n    /// <reference lib=\"es2018.asynciterable\" />\n    class ReadableStreamAsyncIteratorImpl {\n        constructor(reader, preventCancel) {\n            this._ongoingPromise = undefined;\n            this._isFinished = false;\n            this._reader = reader;\n            this._preventCancel = preventCancel;\n        }\n        next() {\n            const nextSteps = () => this._nextSteps();\n            this._ongoingPromise = this._ongoingPromise ?\n                transformPromiseWith(this._ongoingPromise, nextSteps, nextSteps) :\n                nextSteps();\n            return this._ongoingPromise;\n        }\n        return(value) {\n            const returnSteps = () => this._returnSteps(value);\n            return this._ongoingPromise ?\n                transformPromiseWith(this._ongoingPromise, returnSteps, returnSteps) :\n                returnSteps();\n        }\n        _nextSteps() {\n            if (this._isFinished) {\n                return Promise.resolve({ value: undefined, done: true });\n            }\n            const reader = this._reader;\n            if (reader._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('iterate'));\n            }\n            let resolvePromise;\n            let rejectPromise;\n            const promise = newPromise((resolve, reject) => {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            const readRequest = {\n                _chunkSteps: chunk => {\n                    this._ongoingPromise = undefined;\n                    // This needs to be delayed by one microtask, otherwise we stop pulling too early which breaks a test.\n                    // FIXME Is this a bug in the specification, or in the test?\n                    queueMicrotask(() => resolvePromise({ value: chunk, done: false }));\n                },\n                _closeSteps: () => {\n                    this._ongoingPromise = undefined;\n                    this._isFinished = true;\n                    ReadableStreamReaderGenericRelease(reader);\n                    resolvePromise({ value: undefined, done: true });\n                },\n                _errorSteps: reason => {\n                    this._ongoingPromise = undefined;\n                    this._isFinished = true;\n                    ReadableStreamReaderGenericRelease(reader);\n                    rejectPromise(reason);\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n            return promise;\n        }\n        _returnSteps(value) {\n            if (this._isFinished) {\n                return Promise.resolve({ value, done: true });\n            }\n            this._isFinished = true;\n            const reader = this._reader;\n            if (reader._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('finish iterating'));\n            }\n            if (!this._preventCancel) {\n                const result = ReadableStreamReaderGenericCancel(reader, value);\n                ReadableStreamReaderGenericRelease(reader);\n                return transformPromiseWith(result, () => ({ value, done: true }));\n            }\n            ReadableStreamReaderGenericRelease(reader);\n            return promiseResolvedWith({ value, done: true });\n        }\n    }\n    const ReadableStreamAsyncIteratorPrototype = {\n        next() {\n            if (!IsReadableStreamAsyncIterator(this)) {\n                return promiseRejectedWith(streamAsyncIteratorBrandCheckException('next'));\n            }\n            return this._asyncIteratorImpl.next();\n        },\n        return(value) {\n            if (!IsReadableStreamAsyncIterator(this)) {\n                return promiseRejectedWith(streamAsyncIteratorBrandCheckException('return'));\n            }\n            return this._asyncIteratorImpl.return(value);\n        }\n    };\n    if (AsyncIteratorPrototype !== undefined) {\n        Object.setPrototypeOf(ReadableStreamAsyncIteratorPrototype, AsyncIteratorPrototype);\n    }\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamAsyncIterator(stream, preventCancel) {\n        const reader = AcquireReadableStreamDefaultReader(stream);\n        const impl = new ReadableStreamAsyncIteratorImpl(reader, preventCancel);\n        const iterator = Object.create(ReadableStreamAsyncIteratorPrototype);\n        iterator._asyncIteratorImpl = impl;\n        return iterator;\n    }\n    function IsReadableStreamAsyncIterator(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_asyncIteratorImpl')) {\n            return false;\n        }\n        try {\n            // noinspection SuspiciousTypeOfGuard\n            return x._asyncIteratorImpl instanceof\n                ReadableStreamAsyncIteratorImpl;\n        }\n        catch (_a) {\n            return false;\n        }\n    }\n    // Helper functions for the ReadableStream.\n    function streamAsyncIteratorBrandCheckException(name) {\n        return new TypeError(`ReadableStreamAsyncIterator.${name} can only be used on a ReadableSteamAsyncIterator`);\n    }\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isNaN#Polyfill\n    const NumberIsNaN = Number.isNaN || function (x) {\n        // eslint-disable-next-line no-self-compare\n        return x !== x;\n    };\n\n    function CreateArrayFromList(elements) {\n        // We use arrays to represent lists, so this is basically a no-op.\n        // Do a slice though just in case we happen to depend on the unique-ness.\n        return elements.slice();\n    }\n    function CopyDataBlockBytes(dest, destOffset, src, srcOffset, n) {\n        new Uint8Array(dest).set(new Uint8Array(src, srcOffset, n), destOffset);\n    }\n    // Not implemented correctly\n    function TransferArrayBuffer(O) {\n        return O;\n    }\n    // Not implemented correctly\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    function IsDetachedBuffer(O) {\n        return false;\n    }\n    function ArrayBufferSlice(buffer, begin, end) {\n        // ArrayBuffer.prototype.slice is not available on IE10\n        // https://www.caniuse.com/mdn-javascript_builtins_arraybuffer_slice\n        if (buffer.slice) {\n            return buffer.slice(begin, end);\n        }\n        const length = end - begin;\n        const slice = new ArrayBuffer(length);\n        CopyDataBlockBytes(slice, 0, buffer, begin, length);\n        return slice;\n    }\n\n    function IsNonNegativeNumber(v) {\n        if (typeof v !== 'number') {\n            return false;\n        }\n        if (NumberIsNaN(v)) {\n            return false;\n        }\n        if (v < 0) {\n            return false;\n        }\n        return true;\n    }\n    function CloneAsUint8Array(O) {\n        const buffer = ArrayBufferSlice(O.buffer, O.byteOffset, O.byteOffset + O.byteLength);\n        return new Uint8Array(buffer);\n    }\n\n    function DequeueValue(container) {\n        const pair = container._queue.shift();\n        container._queueTotalSize -= pair.size;\n        if (container._queueTotalSize < 0) {\n            container._queueTotalSize = 0;\n        }\n        return pair.value;\n    }\n    function EnqueueValueWithSize(container, value, size) {\n        if (!IsNonNegativeNumber(size) || size === Infinity) {\n            throw new RangeError('Size must be a finite, non-NaN, non-negative number.');\n        }\n        container._queue.push({ value, size });\n        container._queueTotalSize += size;\n    }\n    function PeekQueueValue(container) {\n        const pair = container._queue.peek();\n        return pair.value;\n    }\n    function ResetQueue(container) {\n        container._queue = new SimpleQueue();\n        container._queueTotalSize = 0;\n    }\n\n    /**\n     * A pull-into request in a {@link ReadableByteStreamController}.\n     *\n     * @public\n     */\n    class ReadableStreamBYOBRequest {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the view for writing in to, or `null` if the BYOB request has already been responded to.\n         */\n        get view() {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('view');\n            }\n            return this._view;\n        }\n        respond(bytesWritten) {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('respond');\n            }\n            assertRequiredArgument(bytesWritten, 1, 'respond');\n            bytesWritten = convertUnsignedLongLongWithEnforceRange(bytesWritten, 'First parameter');\n            if (this._associatedReadableByteStreamController === undefined) {\n                throw new TypeError('This BYOB request has been invalidated');\n            }\n            if (IsDetachedBuffer(this._view.buffer)) ;\n            ReadableByteStreamControllerRespond(this._associatedReadableByteStreamController, bytesWritten);\n        }\n        respondWithNewView(view) {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('respondWithNewView');\n            }\n            assertRequiredArgument(view, 1, 'respondWithNewView');\n            if (!ArrayBuffer.isView(view)) {\n                throw new TypeError('You can only respond with array buffer views');\n            }\n            if (this._associatedReadableByteStreamController === undefined) {\n                throw new TypeError('This BYOB request has been invalidated');\n            }\n            if (IsDetachedBuffer(view.buffer)) ;\n            ReadableByteStreamControllerRespondWithNewView(this._associatedReadableByteStreamController, view);\n        }\n    }\n    Object.defineProperties(ReadableStreamBYOBRequest.prototype, {\n        respond: { enumerable: true },\n        respondWithNewView: { enumerable: true },\n        view: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamBYOBRequest.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamBYOBRequest',\n            configurable: true\n        });\n    }\n    /**\n     * Allows control of a {@link ReadableStream | readable byte stream}'s state and internal queue.\n     *\n     * @public\n     */\n    class ReadableByteStreamController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the current BYOB pull request, or `null` if there isn't one.\n         */\n        get byobRequest() {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('byobRequest');\n            }\n            return ReadableByteStreamControllerGetBYOBRequest(this);\n        }\n        /**\n         * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n         * over-full. An underlying byte source ought to use this information to determine when and how to apply backpressure.\n         */\n        get desiredSize() {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('desiredSize');\n            }\n            return ReadableByteStreamControllerGetDesiredSize(this);\n        }\n        /**\n         * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n         * the stream, but once those are read, the stream will become closed.\n         */\n        close() {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('close');\n            }\n            if (this._closeRequested) {\n                throw new TypeError('The stream has already been closed; do not close it again!');\n            }\n            const state = this._controlledReadableByteStream._state;\n            if (state !== 'readable') {\n                throw new TypeError(`The stream (in ${state} state) is not in the readable state and cannot be closed`);\n            }\n            ReadableByteStreamControllerClose(this);\n        }\n        enqueue(chunk) {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('enqueue');\n            }\n            assertRequiredArgument(chunk, 1, 'enqueue');\n            if (!ArrayBuffer.isView(chunk)) {\n                throw new TypeError('chunk must be an array buffer view');\n            }\n            if (chunk.byteLength === 0) {\n                throw new TypeError('chunk must have non-zero byteLength');\n            }\n            if (chunk.buffer.byteLength === 0) {\n                throw new TypeError(`chunk's buffer must have non-zero byteLength`);\n            }\n            if (this._closeRequested) {\n                throw new TypeError('stream is closed or draining');\n            }\n            const state = this._controlledReadableByteStream._state;\n            if (state !== 'readable') {\n                throw new TypeError(`The stream (in ${state} state) is not in the readable state and cannot be enqueued to`);\n            }\n            ReadableByteStreamControllerEnqueue(this, chunk);\n        }\n        /**\n         * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n         */\n        error(e = undefined) {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('error');\n            }\n            ReadableByteStreamControllerError(this, e);\n        }\n        /** @internal */\n        [CancelSteps](reason) {\n            ReadableByteStreamControllerClearPendingPullIntos(this);\n            ResetQueue(this);\n            const result = this._cancelAlgorithm(reason);\n            ReadableByteStreamControllerClearAlgorithms(this);\n            return result;\n        }\n        /** @internal */\n        [PullSteps](readRequest) {\n            const stream = this._controlledReadableByteStream;\n            if (this._queueTotalSize > 0) {\n                const entry = this._queue.shift();\n                this._queueTotalSize -= entry.byteLength;\n                ReadableByteStreamControllerHandleQueueDrain(this);\n                const view = new Uint8Array(entry.buffer, entry.byteOffset, entry.byteLength);\n                readRequest._chunkSteps(view);\n                return;\n            }\n            const autoAllocateChunkSize = this._autoAllocateChunkSize;\n            if (autoAllocateChunkSize !== undefined) {\n                let buffer;\n                try {\n                    buffer = new ArrayBuffer(autoAllocateChunkSize);\n                }\n                catch (bufferE) {\n                    readRequest._errorSteps(bufferE);\n                    return;\n                }\n                const pullIntoDescriptor = {\n                    buffer,\n                    bufferByteLength: autoAllocateChunkSize,\n                    byteOffset: 0,\n                    byteLength: autoAllocateChunkSize,\n                    bytesFilled: 0,\n                    elementSize: 1,\n                    viewConstructor: Uint8Array,\n                    readerType: 'default'\n                };\n                this._pendingPullIntos.push(pullIntoDescriptor);\n            }\n            ReadableStreamAddReadRequest(stream, readRequest);\n            ReadableByteStreamControllerCallPullIfNeeded(this);\n        }\n    }\n    Object.defineProperties(ReadableByteStreamController.prototype, {\n        close: { enumerable: true },\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        byobRequest: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableByteStreamController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableByteStreamController',\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableByteStreamController.\n    function IsReadableByteStreamController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableByteStream')) {\n            return false;\n        }\n        return x instanceof ReadableByteStreamController;\n    }\n    function IsReadableStreamBYOBRequest(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_associatedReadableByteStreamController')) {\n            return false;\n        }\n        return x instanceof ReadableStreamBYOBRequest;\n    }\n    function ReadableByteStreamControllerCallPullIfNeeded(controller) {\n        const shouldPull = ReadableByteStreamControllerShouldCallPull(controller);\n        if (!shouldPull) {\n            return;\n        }\n        if (controller._pulling) {\n            controller._pullAgain = true;\n            return;\n        }\n        controller._pulling = true;\n        // TODO: Test controller argument\n        const pullPromise = controller._pullAlgorithm();\n        uponPromise(pullPromise, () => {\n            controller._pulling = false;\n            if (controller._pullAgain) {\n                controller._pullAgain = false;\n                ReadableByteStreamControllerCallPullIfNeeded(controller);\n            }\n        }, e => {\n            ReadableByteStreamControllerError(controller, e);\n        });\n    }\n    function ReadableByteStreamControllerClearPendingPullIntos(controller) {\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        controller._pendingPullIntos = new SimpleQueue();\n    }\n    function ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor) {\n        let done = false;\n        if (stream._state === 'closed') {\n            done = true;\n        }\n        const filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n        if (pullIntoDescriptor.readerType === 'default') {\n            ReadableStreamFulfillReadRequest(stream, filledView, done);\n        }\n        else {\n            ReadableStreamFulfillReadIntoRequest(stream, filledView, done);\n        }\n    }\n    function ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor) {\n        const bytesFilled = pullIntoDescriptor.bytesFilled;\n        const elementSize = pullIntoDescriptor.elementSize;\n        return new pullIntoDescriptor.viewConstructor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, bytesFilled / elementSize);\n    }\n    function ReadableByteStreamControllerEnqueueChunkToQueue(controller, buffer, byteOffset, byteLength) {\n        controller._queue.push({ buffer, byteOffset, byteLength });\n        controller._queueTotalSize += byteLength;\n    }\n    function ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor) {\n        const elementSize = pullIntoDescriptor.elementSize;\n        const currentAlignedBytes = pullIntoDescriptor.bytesFilled - pullIntoDescriptor.bytesFilled % elementSize;\n        const maxBytesToCopy = Math.min(controller._queueTotalSize, pullIntoDescriptor.byteLength - pullIntoDescriptor.bytesFilled);\n        const maxBytesFilled = pullIntoDescriptor.bytesFilled + maxBytesToCopy;\n        const maxAlignedBytes = maxBytesFilled - maxBytesFilled % elementSize;\n        let totalBytesToCopyRemaining = maxBytesToCopy;\n        let ready = false;\n        if (maxAlignedBytes > currentAlignedBytes) {\n            totalBytesToCopyRemaining = maxAlignedBytes - pullIntoDescriptor.bytesFilled;\n            ready = true;\n        }\n        const queue = controller._queue;\n        while (totalBytesToCopyRemaining > 0) {\n            const headOfQueue = queue.peek();\n            const bytesToCopy = Math.min(totalBytesToCopyRemaining, headOfQueue.byteLength);\n            const destStart = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n            CopyDataBlockBytes(pullIntoDescriptor.buffer, destStart, headOfQueue.buffer, headOfQueue.byteOffset, bytesToCopy);\n            if (headOfQueue.byteLength === bytesToCopy) {\n                queue.shift();\n            }\n            else {\n                headOfQueue.byteOffset += bytesToCopy;\n                headOfQueue.byteLength -= bytesToCopy;\n            }\n            controller._queueTotalSize -= bytesToCopy;\n            ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesToCopy, pullIntoDescriptor);\n            totalBytesToCopyRemaining -= bytesToCopy;\n        }\n        return ready;\n    }\n    function ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, size, pullIntoDescriptor) {\n        pullIntoDescriptor.bytesFilled += size;\n    }\n    function ReadableByteStreamControllerHandleQueueDrain(controller) {\n        if (controller._queueTotalSize === 0 && controller._closeRequested) {\n            ReadableByteStreamControllerClearAlgorithms(controller);\n            ReadableStreamClose(controller._controlledReadableByteStream);\n        }\n        else {\n            ReadableByteStreamControllerCallPullIfNeeded(controller);\n        }\n    }\n    function ReadableByteStreamControllerInvalidateBYOBRequest(controller) {\n        if (controller._byobRequest === null) {\n            return;\n        }\n        controller._byobRequest._associatedReadableByteStreamController = undefined;\n        controller._byobRequest._view = null;\n        controller._byobRequest = null;\n    }\n    function ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller) {\n        while (controller._pendingPullIntos.length > 0) {\n            if (controller._queueTotalSize === 0) {\n                return;\n            }\n            const pullIntoDescriptor = controller._pendingPullIntos.peek();\n            if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n                ReadableByteStreamControllerShiftPendingPullInto(controller);\n                ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n            }\n        }\n    }\n    function ReadableByteStreamControllerPullInto(controller, view, readIntoRequest) {\n        const stream = controller._controlledReadableByteStream;\n        let elementSize = 1;\n        if (view.constructor !== DataView) {\n            elementSize = view.constructor.BYTES_PER_ELEMENT;\n        }\n        const ctor = view.constructor;\n        // try {\n        const buffer = TransferArrayBuffer(view.buffer);\n        // } catch (e) {\n        //   readIntoRequest._errorSteps(e);\n        //   return;\n        // }\n        const pullIntoDescriptor = {\n            buffer,\n            bufferByteLength: buffer.byteLength,\n            byteOffset: view.byteOffset,\n            byteLength: view.byteLength,\n            bytesFilled: 0,\n            elementSize,\n            viewConstructor: ctor,\n            readerType: 'byob'\n        };\n        if (controller._pendingPullIntos.length > 0) {\n            controller._pendingPullIntos.push(pullIntoDescriptor);\n            // No ReadableByteStreamControllerCallPullIfNeeded() call since:\n            // - No change happens on desiredSize\n            // - The source has already been notified of that there's at least 1 pending read(view)\n            ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n            return;\n        }\n        if (stream._state === 'closed') {\n            const emptyView = new ctor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, 0);\n            readIntoRequest._closeSteps(emptyView);\n            return;\n        }\n        if (controller._queueTotalSize > 0) {\n            if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n                const filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n                ReadableByteStreamControllerHandleQueueDrain(controller);\n                readIntoRequest._chunkSteps(filledView);\n                return;\n            }\n            if (controller._closeRequested) {\n                const e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n                ReadableByteStreamControllerError(controller, e);\n                readIntoRequest._errorSteps(e);\n                return;\n            }\n        }\n        controller._pendingPullIntos.push(pullIntoDescriptor);\n        ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerRespondInClosedState(controller, firstDescriptor) {\n        const stream = controller._controlledReadableByteStream;\n        if (ReadableStreamHasBYOBReader(stream)) {\n            while (ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n                const pullIntoDescriptor = ReadableByteStreamControllerShiftPendingPullInto(controller);\n                ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor);\n            }\n        }\n    }\n    function ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, pullIntoDescriptor) {\n        ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesWritten, pullIntoDescriptor);\n        if (pullIntoDescriptor.bytesFilled < pullIntoDescriptor.elementSize) {\n            return;\n        }\n        ReadableByteStreamControllerShiftPendingPullInto(controller);\n        const remainderSize = pullIntoDescriptor.bytesFilled % pullIntoDescriptor.elementSize;\n        if (remainderSize > 0) {\n            const end = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n            const remainder = ArrayBufferSlice(pullIntoDescriptor.buffer, end - remainderSize, end);\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, remainder, 0, remainder.byteLength);\n        }\n        pullIntoDescriptor.bytesFilled -= remainderSize;\n        ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n        ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n    }\n    function ReadableByteStreamControllerRespondInternal(controller, bytesWritten) {\n        const firstDescriptor = controller._pendingPullIntos.peek();\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            ReadableByteStreamControllerRespondInClosedState(controller);\n        }\n        else {\n            ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, firstDescriptor);\n        }\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerShiftPendingPullInto(controller) {\n        const descriptor = controller._pendingPullIntos.shift();\n        return descriptor;\n    }\n    function ReadableByteStreamControllerShouldCallPull(controller) {\n        const stream = controller._controlledReadableByteStream;\n        if (stream._state !== 'readable') {\n            return false;\n        }\n        if (controller._closeRequested) {\n            return false;\n        }\n        if (!controller._started) {\n            return false;\n        }\n        if (ReadableStreamHasDefaultReader(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            return true;\n        }\n        if (ReadableStreamHasBYOBReader(stream) && ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n            return true;\n        }\n        const desiredSize = ReadableByteStreamControllerGetDesiredSize(controller);\n        if (desiredSize > 0) {\n            return true;\n        }\n        return false;\n    }\n    function ReadableByteStreamControllerClearAlgorithms(controller) {\n        controller._pullAlgorithm = undefined;\n        controller._cancelAlgorithm = undefined;\n    }\n    // A client of ReadableByteStreamController may use these functions directly to bypass state check.\n    function ReadableByteStreamControllerClose(controller) {\n        const stream = controller._controlledReadableByteStream;\n        if (controller._closeRequested || stream._state !== 'readable') {\n            return;\n        }\n        if (controller._queueTotalSize > 0) {\n            controller._closeRequested = true;\n            return;\n        }\n        if (controller._pendingPullIntos.length > 0) {\n            const firstPendingPullInto = controller._pendingPullIntos.peek();\n            if (firstPendingPullInto.bytesFilled > 0) {\n                const e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n                ReadableByteStreamControllerError(controller, e);\n                throw e;\n            }\n        }\n        ReadableByteStreamControllerClearAlgorithms(controller);\n        ReadableStreamClose(stream);\n    }\n    function ReadableByteStreamControllerEnqueue(controller, chunk) {\n        const stream = controller._controlledReadableByteStream;\n        if (controller._closeRequested || stream._state !== 'readable') {\n            return;\n        }\n        const buffer = chunk.buffer;\n        const byteOffset = chunk.byteOffset;\n        const byteLength = chunk.byteLength;\n        const transferredBuffer = TransferArrayBuffer(buffer);\n        if (controller._pendingPullIntos.length > 0) {\n            const firstPendingPullInto = controller._pendingPullIntos.peek();\n            if (IsDetachedBuffer(firstPendingPullInto.buffer)) ;\n            firstPendingPullInto.buffer = TransferArrayBuffer(firstPendingPullInto.buffer);\n        }\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        if (ReadableStreamHasDefaultReader(stream)) {\n            if (ReadableStreamGetNumReadRequests(stream) === 0) {\n                ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n            }\n            else {\n                const transferredView = new Uint8Array(transferredBuffer, byteOffset, byteLength);\n                ReadableStreamFulfillReadRequest(stream, transferredView, false);\n            }\n        }\n        else if (ReadableStreamHasBYOBReader(stream)) {\n            // TODO: Ideally in this branch detaching should happen only if the buffer is not consumed fully.\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n            ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n        }\n        else {\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n        }\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerError(controller, e) {\n        const stream = controller._controlledReadableByteStream;\n        if (stream._state !== 'readable') {\n            return;\n        }\n        ReadableByteStreamControllerClearPendingPullIntos(controller);\n        ResetQueue(controller);\n        ReadableByteStreamControllerClearAlgorithms(controller);\n        ReadableStreamError(stream, e);\n    }\n    function ReadableByteStreamControllerGetBYOBRequest(controller) {\n        if (controller._byobRequest === null && controller._pendingPullIntos.length > 0) {\n            const firstDescriptor = controller._pendingPullIntos.peek();\n            const view = new Uint8Array(firstDescriptor.buffer, firstDescriptor.byteOffset + firstDescriptor.bytesFilled, firstDescriptor.byteLength - firstDescriptor.bytesFilled);\n            const byobRequest = Object.create(ReadableStreamBYOBRequest.prototype);\n            SetUpReadableStreamBYOBRequest(byobRequest, controller, view);\n            controller._byobRequest = byobRequest;\n        }\n        return controller._byobRequest;\n    }\n    function ReadableByteStreamControllerGetDesiredSize(controller) {\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'errored') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    function ReadableByteStreamControllerRespond(controller, bytesWritten) {\n        const firstDescriptor = controller._pendingPullIntos.peek();\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            if (bytesWritten !== 0) {\n                throw new TypeError('bytesWritten must be 0 when calling respond() on a closed stream');\n            }\n        }\n        else {\n            if (bytesWritten === 0) {\n                throw new TypeError('bytesWritten must be greater than 0 when calling respond() on a readable stream');\n            }\n            if (firstDescriptor.bytesFilled + bytesWritten > firstDescriptor.byteLength) {\n                throw new RangeError('bytesWritten out of range');\n            }\n        }\n        firstDescriptor.buffer = TransferArrayBuffer(firstDescriptor.buffer);\n        ReadableByteStreamControllerRespondInternal(controller, bytesWritten);\n    }\n    function ReadableByteStreamControllerRespondWithNewView(controller, view) {\n        const firstDescriptor = controller._pendingPullIntos.peek();\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            if (view.byteLength !== 0) {\n                throw new TypeError('The view\\'s length must be 0 when calling respondWithNewView() on a closed stream');\n            }\n        }\n        else {\n            if (view.byteLength === 0) {\n                throw new TypeError('The view\\'s length must be greater than 0 when calling respondWithNewView() on a readable stream');\n            }\n        }\n        if (firstDescriptor.byteOffset + firstDescriptor.bytesFilled !== view.byteOffset) {\n            throw new RangeError('The region specified by view does not match byobRequest');\n        }\n        if (firstDescriptor.bufferByteLength !== view.buffer.byteLength) {\n            throw new RangeError('The buffer of view has different capacity than byobRequest');\n        }\n        if (firstDescriptor.bytesFilled + view.byteLength > firstDescriptor.byteLength) {\n            throw new RangeError('The region specified by view is larger than byobRequest');\n        }\n        firstDescriptor.buffer = TransferArrayBuffer(view.buffer);\n        ReadableByteStreamControllerRespondInternal(controller, view.byteLength);\n    }\n    function SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize) {\n        controller._controlledReadableByteStream = stream;\n        controller._pullAgain = false;\n        controller._pulling = false;\n        controller._byobRequest = null;\n        // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n        controller._queue = controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._closeRequested = false;\n        controller._started = false;\n        controller._strategyHWM = highWaterMark;\n        controller._pullAlgorithm = pullAlgorithm;\n        controller._cancelAlgorithm = cancelAlgorithm;\n        controller._autoAllocateChunkSize = autoAllocateChunkSize;\n        controller._pendingPullIntos = new SimpleQueue();\n        stream._readableStreamController = controller;\n        const startResult = startAlgorithm();\n        uponPromise(promiseResolvedWith(startResult), () => {\n            controller._started = true;\n            ReadableByteStreamControllerCallPullIfNeeded(controller);\n        }, r => {\n            ReadableByteStreamControllerError(controller, r);\n        });\n    }\n    function SetUpReadableByteStreamControllerFromUnderlyingSource(stream, underlyingByteSource, highWaterMark) {\n        const controller = Object.create(ReadableByteStreamController.prototype);\n        let startAlgorithm = () => undefined;\n        let pullAlgorithm = () => promiseResolvedWith(undefined);\n        let cancelAlgorithm = () => promiseResolvedWith(undefined);\n        if (underlyingByteSource.start !== undefined) {\n            startAlgorithm = () => underlyingByteSource.start(controller);\n        }\n        if (underlyingByteSource.pull !== undefined) {\n            pullAlgorithm = () => underlyingByteSource.pull(controller);\n        }\n        if (underlyingByteSource.cancel !== undefined) {\n            cancelAlgorithm = reason => underlyingByteSource.cancel(reason);\n        }\n        const autoAllocateChunkSize = underlyingByteSource.autoAllocateChunkSize;\n        if (autoAllocateChunkSize === 0) {\n            throw new TypeError('autoAllocateChunkSize must be greater than 0');\n        }\n        SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize);\n    }\n    function SetUpReadableStreamBYOBRequest(request, controller, view) {\n        request._associatedReadableByteStreamController = controller;\n        request._view = view;\n    }\n    // Helper functions for the ReadableStreamBYOBRequest.\n    function byobRequestBrandCheckException(name) {\n        return new TypeError(`ReadableStreamBYOBRequest.prototype.${name} can only be used on a ReadableStreamBYOBRequest`);\n    }\n    // Helper functions for the ReadableByteStreamController.\n    function byteStreamControllerBrandCheckException(name) {\n        return new TypeError(`ReadableByteStreamController.prototype.${name} can only be used on a ReadableByteStreamController`);\n    }\n\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamBYOBReader(stream) {\n        return new ReadableStreamBYOBReader(stream);\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamAddReadIntoRequest(stream, readIntoRequest) {\n        stream._reader._readIntoRequests.push(readIntoRequest);\n    }\n    function ReadableStreamFulfillReadIntoRequest(stream, chunk, done) {\n        const reader = stream._reader;\n        const readIntoRequest = reader._readIntoRequests.shift();\n        if (done) {\n            readIntoRequest._closeSteps(chunk);\n        }\n        else {\n            readIntoRequest._chunkSteps(chunk);\n        }\n    }\n    function ReadableStreamGetNumReadIntoRequests(stream) {\n        return stream._reader._readIntoRequests.length;\n    }\n    function ReadableStreamHasBYOBReader(stream) {\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return false;\n        }\n        if (!IsReadableStreamBYOBReader(reader)) {\n            return false;\n        }\n        return true;\n    }\n    /**\n     * A BYOB reader vended by a {@link ReadableStream}.\n     *\n     * @public\n     */\n    class ReadableStreamBYOBReader {\n        constructor(stream) {\n            assertRequiredArgument(stream, 1, 'ReadableStreamBYOBReader');\n            assertReadableStream(stream, 'First parameter');\n            if (IsReadableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n            }\n            if (!IsReadableByteStreamController(stream._readableStreamController)) {\n                throw new TypeError('Cannot construct a ReadableStreamBYOBReader for a stream not constructed with a byte ' +\n                    'source');\n            }\n            ReadableStreamReaderGenericInitialize(this, stream);\n            this._readIntoRequests = new SimpleQueue();\n        }\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n         * the reader's lock is released before the stream finishes closing.\n         */\n        get closed() {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        }\n        /**\n         * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n         */\n        cancel(reason = undefined) {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('cancel'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('cancel'));\n            }\n            return ReadableStreamReaderGenericCancel(this, reason);\n        }\n        /**\n         * Attempts to reads bytes into view, and returns a promise resolved with the result.\n         *\n         * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n         */\n        read(view) {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('read'));\n            }\n            if (!ArrayBuffer.isView(view)) {\n                return promiseRejectedWith(new TypeError('view must be an array buffer view'));\n            }\n            if (view.byteLength === 0) {\n                return promiseRejectedWith(new TypeError('view must have non-zero byteLength'));\n            }\n            if (view.buffer.byteLength === 0) {\n                return promiseRejectedWith(new TypeError(`view's buffer must have non-zero byteLength`));\n            }\n            if (IsDetachedBuffer(view.buffer)) ;\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('read from'));\n            }\n            let resolvePromise;\n            let rejectPromise;\n            const promise = newPromise((resolve, reject) => {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            const readIntoRequest = {\n                _chunkSteps: chunk => resolvePromise({ value: chunk, done: false }),\n                _closeSteps: chunk => resolvePromise({ value: chunk, done: true }),\n                _errorSteps: e => rejectPromise(e)\n            };\n            ReadableStreamBYOBReaderRead(this, view, readIntoRequest);\n            return promise;\n        }\n        /**\n         * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n         * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n         * from now on; otherwise, the reader will appear closed.\n         *\n         * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n         * the reader's {@link ReadableStreamBYOBReader.read | read()} method has not yet been settled. Attempting to\n         * do so will throw a `TypeError` and leave the reader locked to the stream.\n         */\n        releaseLock() {\n            if (!IsReadableStreamBYOBReader(this)) {\n                throw byobReaderBrandCheckException('releaseLock');\n            }\n            if (this._ownerReadableStream === undefined) {\n                return;\n            }\n            if (this._readIntoRequests.length > 0) {\n                throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n            }\n            ReadableStreamReaderGenericRelease(this);\n        }\n    }\n    Object.defineProperties(ReadableStreamBYOBReader.prototype, {\n        cancel: { enumerable: true },\n        read: { enumerable: true },\n        releaseLock: { enumerable: true },\n        closed: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamBYOBReader.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamBYOBReader',\n            configurable: true\n        });\n    }\n    // Abstract operations for the readers.\n    function IsReadableStreamBYOBReader(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readIntoRequests')) {\n            return false;\n        }\n        return x instanceof ReadableStreamBYOBReader;\n    }\n    function ReadableStreamBYOBReaderRead(reader, view, readIntoRequest) {\n        const stream = reader._ownerReadableStream;\n        stream._disturbed = true;\n        if (stream._state === 'errored') {\n            readIntoRequest._errorSteps(stream._storedError);\n        }\n        else {\n            ReadableByteStreamControllerPullInto(stream._readableStreamController, view, readIntoRequest);\n        }\n    }\n    // Helper functions for the ReadableStreamBYOBReader.\n    function byobReaderBrandCheckException(name) {\n        return new TypeError(`ReadableStreamBYOBReader.prototype.${name} can only be used on a ReadableStreamBYOBReader`);\n    }\n\n    function ExtractHighWaterMark(strategy, defaultHWM) {\n        const { highWaterMark } = strategy;\n        if (highWaterMark === undefined) {\n            return defaultHWM;\n        }\n        if (NumberIsNaN(highWaterMark) || highWaterMark < 0) {\n            throw new RangeError('Invalid highWaterMark');\n        }\n        return highWaterMark;\n    }\n    function ExtractSizeAlgorithm(strategy) {\n        const { size } = strategy;\n        if (!size) {\n            return () => 1;\n        }\n        return size;\n    }\n\n    function convertQueuingStrategy(init, context) {\n        assertDictionary(init, context);\n        const highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n        const size = init === null || init === void 0 ? void 0 : init.size;\n        return {\n            highWaterMark: highWaterMark === undefined ? undefined : convertUnrestrictedDouble(highWaterMark),\n            size: size === undefined ? undefined : convertQueuingStrategySize(size, `${context} has member 'size' that`)\n        };\n    }\n    function convertQueuingStrategySize(fn, context) {\n        assertFunction(fn, context);\n        return chunk => convertUnrestrictedDouble(fn(chunk));\n    }\n\n    function convertUnderlyingSink(original, context) {\n        assertDictionary(original, context);\n        const abort = original === null || original === void 0 ? void 0 : original.abort;\n        const close = original === null || original === void 0 ? void 0 : original.close;\n        const start = original === null || original === void 0 ? void 0 : original.start;\n        const type = original === null || original === void 0 ? void 0 : original.type;\n        const write = original === null || original === void 0 ? void 0 : original.write;\n        return {\n            abort: abort === undefined ?\n                undefined :\n                convertUnderlyingSinkAbortCallback(abort, original, `${context} has member 'abort' that`),\n            close: close === undefined ?\n                undefined :\n                convertUnderlyingSinkCloseCallback(close, original, `${context} has member 'close' that`),\n            start: start === undefined ?\n                undefined :\n                convertUnderlyingSinkStartCallback(start, original, `${context} has member 'start' that`),\n            write: write === undefined ?\n                undefined :\n                convertUnderlyingSinkWriteCallback(write, original, `${context} has member 'write' that`),\n            type\n        };\n    }\n    function convertUnderlyingSinkAbortCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (reason) => promiseCall(fn, original, [reason]);\n    }\n    function convertUnderlyingSinkCloseCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return () => promiseCall(fn, original, []);\n    }\n    function convertUnderlyingSinkStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => reflectCall(fn, original, [controller]);\n    }\n    function convertUnderlyingSinkWriteCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (chunk, controller) => promiseCall(fn, original, [chunk, controller]);\n    }\n\n    function assertWritableStream(x, context) {\n        if (!IsWritableStream(x)) {\n            throw new TypeError(`${context} is not a WritableStream.`);\n        }\n    }\n\n    function isAbortSignal(value) {\n        if (typeof value !== 'object' || value === null) {\n            return false;\n        }\n        try {\n            return typeof value.aborted === 'boolean';\n        }\n        catch (_a) {\n            // AbortSignal.prototype.aborted throws if its brand check fails\n            return false;\n        }\n    }\n    const supportsAbortController = typeof AbortController === 'function';\n    /**\n     * Construct a new AbortController, if supported by the platform.\n     *\n     * @internal\n     */\n    function createAbortController() {\n        if (supportsAbortController) {\n            return new AbortController();\n        }\n        return undefined;\n    }\n\n    /**\n     * A writable stream represents a destination for data, into which you can write.\n     *\n     * @public\n     */\n    class WritableStream {\n        constructor(rawUnderlyingSink = {}, rawStrategy = {}) {\n            if (rawUnderlyingSink === undefined) {\n                rawUnderlyingSink = null;\n            }\n            else {\n                assertObject(rawUnderlyingSink, 'First parameter');\n            }\n            const strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n            const underlyingSink = convertUnderlyingSink(rawUnderlyingSink, 'First parameter');\n            InitializeWritableStream(this);\n            const type = underlyingSink.type;\n            if (type !== undefined) {\n                throw new RangeError('Invalid type is specified');\n            }\n            const sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n            const highWaterMark = ExtractHighWaterMark(strategy, 1);\n            SetUpWritableStreamDefaultControllerFromUnderlyingSink(this, underlyingSink, highWaterMark, sizeAlgorithm);\n        }\n        /**\n         * Returns whether or not the writable stream is locked to a writer.\n         */\n        get locked() {\n            if (!IsWritableStream(this)) {\n                throw streamBrandCheckException$2('locked');\n            }\n            return IsWritableStreamLocked(this);\n        }\n        /**\n         * Aborts the stream, signaling that the producer can no longer successfully write to the stream and it is to be\n         * immediately moved to an errored state, with any queued-up writes discarded. This will also execute any abort\n         * mechanism of the underlying sink.\n         *\n         * The returned promise will fulfill if the stream shuts down successfully, or reject if the underlying sink signaled\n         * that there was an error doing so. Additionally, it will reject with a `TypeError` (without attempting to cancel\n         * the stream) if the stream is currently locked.\n         */\n        abort(reason = undefined) {\n            if (!IsWritableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$2('abort'));\n            }\n            if (IsWritableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot abort a stream that already has a writer'));\n            }\n            return WritableStreamAbort(this, reason);\n        }\n        /**\n         * Closes the stream. The underlying sink will finish processing any previously-written chunks, before invoking its\n         * close behavior. During this time any further attempts to write will fail (without erroring the stream).\n         *\n         * The method returns a promise that will fulfill if all remaining chunks are successfully written and the stream\n         * successfully closes, or rejects if an error is encountered during this process. Additionally, it will reject with\n         * a `TypeError` (without attempting to cancel the stream) if the stream is currently locked.\n         */\n        close() {\n            if (!IsWritableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$2('close'));\n            }\n            if (IsWritableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot close a stream that already has a writer'));\n            }\n            if (WritableStreamCloseQueuedOrInFlight(this)) {\n                return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n            }\n            return WritableStreamClose(this);\n        }\n        /**\n         * Creates a {@link WritableStreamDefaultWriter | writer} and locks the stream to the new writer. While the stream\n         * is locked, no other writer can be acquired until this one is released.\n         *\n         * This functionality is especially useful for creating abstractions that desire the ability to write to a stream\n         * without interruption or interleaving. By getting a writer for the stream, you can ensure nobody else can write at\n         * the same time, which would cause the resulting written data to be unpredictable and probably useless.\n         */\n        getWriter() {\n            if (!IsWritableStream(this)) {\n                throw streamBrandCheckException$2('getWriter');\n            }\n            return AcquireWritableStreamDefaultWriter(this);\n        }\n    }\n    Object.defineProperties(WritableStream.prototype, {\n        abort: { enumerable: true },\n        close: { enumerable: true },\n        getWriter: { enumerable: true },\n        locked: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStream',\n            configurable: true\n        });\n    }\n    // Abstract operations for the WritableStream.\n    function AcquireWritableStreamDefaultWriter(stream) {\n        return new WritableStreamDefaultWriter(stream);\n    }\n    // Throws if and only if startAlgorithm throws.\n    function CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark = 1, sizeAlgorithm = () => 1) {\n        const stream = Object.create(WritableStream.prototype);\n        InitializeWritableStream(stream);\n        const controller = Object.create(WritableStreamDefaultController.prototype);\n        SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n        return stream;\n    }\n    function InitializeWritableStream(stream) {\n        stream._state = 'writable';\n        // The error that will be reported by new method calls once the state becomes errored. Only set when [[state]] is\n        // 'erroring' or 'errored'. May be set to an undefined value.\n        stream._storedError = undefined;\n        stream._writer = undefined;\n        // Initialize to undefined first because the constructor of the controller checks this\n        // variable to validate the caller.\n        stream._writableStreamController = undefined;\n        // This queue is placed here instead of the writer class in order to allow for passing a writer to the next data\n        // producer without waiting for the queued writes to finish.\n        stream._writeRequests = new SimpleQueue();\n        // Write requests are removed from _writeRequests when write() is called on the underlying sink. This prevents\n        // them from being erroneously rejected on error. If a write() call is in-flight, the request is stored here.\n        stream._inFlightWriteRequest = undefined;\n        // The promise that was returned from writer.close(). Stored here because it may be fulfilled after the writer\n        // has been detached.\n        stream._closeRequest = undefined;\n        // Close request is removed from _closeRequest when close() is called on the underlying sink. This prevents it\n        // from being erroneously rejected on error. If a close() call is in-flight, the request is stored here.\n        stream._inFlightCloseRequest = undefined;\n        // The promise that was returned from writer.abort(). This may also be fulfilled after the writer has detached.\n        stream._pendingAbortRequest = undefined;\n        // The backpressure signal set by the controller.\n        stream._backpressure = false;\n    }\n    function IsWritableStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_writableStreamController')) {\n            return false;\n        }\n        return x instanceof WritableStream;\n    }\n    function IsWritableStreamLocked(stream) {\n        if (stream._writer === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamAbort(stream, reason) {\n        var _a;\n        if (stream._state === 'closed' || stream._state === 'errored') {\n            return promiseResolvedWith(undefined);\n        }\n        stream._writableStreamController._abortReason = reason;\n        (_a = stream._writableStreamController._abortController) === null || _a === void 0 ? void 0 : _a.abort();\n        // TypeScript narrows the type of `stream._state` down to 'writable' | 'erroring',\n        // but it doesn't know that signaling abort runs author code that might have changed the state.\n        // Widen the type again by casting to WritableStreamState.\n        const state = stream._state;\n        if (state === 'closed' || state === 'errored') {\n            return promiseResolvedWith(undefined);\n        }\n        if (stream._pendingAbortRequest !== undefined) {\n            return stream._pendingAbortRequest._promise;\n        }\n        let wasAlreadyErroring = false;\n        if (state === 'erroring') {\n            wasAlreadyErroring = true;\n            // reason will not be used, so don't keep a reference to it.\n            reason = undefined;\n        }\n        const promise = newPromise((resolve, reject) => {\n            stream._pendingAbortRequest = {\n                _promise: undefined,\n                _resolve: resolve,\n                _reject: reject,\n                _reason: reason,\n                _wasAlreadyErroring: wasAlreadyErroring\n            };\n        });\n        stream._pendingAbortRequest._promise = promise;\n        if (!wasAlreadyErroring) {\n            WritableStreamStartErroring(stream, reason);\n        }\n        return promise;\n    }\n    function WritableStreamClose(stream) {\n        const state = stream._state;\n        if (state === 'closed' || state === 'errored') {\n            return promiseRejectedWith(new TypeError(`The stream (in ${state} state) is not in the writable state and cannot be closed`));\n        }\n        const promise = newPromise((resolve, reject) => {\n            const closeRequest = {\n                _resolve: resolve,\n                _reject: reject\n            };\n            stream._closeRequest = closeRequest;\n        });\n        const writer = stream._writer;\n        if (writer !== undefined && stream._backpressure && state === 'writable') {\n            defaultWriterReadyPromiseResolve(writer);\n        }\n        WritableStreamDefaultControllerClose(stream._writableStreamController);\n        return promise;\n    }\n    // WritableStream API exposed for controllers.\n    function WritableStreamAddWriteRequest(stream) {\n        const promise = newPromise((resolve, reject) => {\n            const writeRequest = {\n                _resolve: resolve,\n                _reject: reject\n            };\n            stream._writeRequests.push(writeRequest);\n        });\n        return promise;\n    }\n    function WritableStreamDealWithRejection(stream, error) {\n        const state = stream._state;\n        if (state === 'writable') {\n            WritableStreamStartErroring(stream, error);\n            return;\n        }\n        WritableStreamFinishErroring(stream);\n    }\n    function WritableStreamStartErroring(stream, reason) {\n        const controller = stream._writableStreamController;\n        stream._state = 'erroring';\n        stream._storedError = reason;\n        const writer = stream._writer;\n        if (writer !== undefined) {\n            WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, reason);\n        }\n        if (!WritableStreamHasOperationMarkedInFlight(stream) && controller._started) {\n            WritableStreamFinishErroring(stream);\n        }\n    }\n    function WritableStreamFinishErroring(stream) {\n        stream._state = 'errored';\n        stream._writableStreamController[ErrorSteps]();\n        const storedError = stream._storedError;\n        stream._writeRequests.forEach(writeRequest => {\n            writeRequest._reject(storedError);\n        });\n        stream._writeRequests = new SimpleQueue();\n        if (stream._pendingAbortRequest === undefined) {\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n            return;\n        }\n        const abortRequest = stream._pendingAbortRequest;\n        stream._pendingAbortRequest = undefined;\n        if (abortRequest._wasAlreadyErroring) {\n            abortRequest._reject(storedError);\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n            return;\n        }\n        const promise = stream._writableStreamController[AbortSteps](abortRequest._reason);\n        uponPromise(promise, () => {\n            abortRequest._resolve();\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        }, (reason) => {\n            abortRequest._reject(reason);\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        });\n    }\n    function WritableStreamFinishInFlightWrite(stream) {\n        stream._inFlightWriteRequest._resolve(undefined);\n        stream._inFlightWriteRequest = undefined;\n    }\n    function WritableStreamFinishInFlightWriteWithError(stream, error) {\n        stream._inFlightWriteRequest._reject(error);\n        stream._inFlightWriteRequest = undefined;\n        WritableStreamDealWithRejection(stream, error);\n    }\n    function WritableStreamFinishInFlightClose(stream) {\n        stream._inFlightCloseRequest._resolve(undefined);\n        stream._inFlightCloseRequest = undefined;\n        const state = stream._state;\n        if (state === 'erroring') {\n            // The error was too late to do anything, so it is ignored.\n            stream._storedError = undefined;\n            if (stream._pendingAbortRequest !== undefined) {\n                stream._pendingAbortRequest._resolve();\n                stream._pendingAbortRequest = undefined;\n            }\n        }\n        stream._state = 'closed';\n        const writer = stream._writer;\n        if (writer !== undefined) {\n            defaultWriterClosedPromiseResolve(writer);\n        }\n    }\n    function WritableStreamFinishInFlightCloseWithError(stream, error) {\n        stream._inFlightCloseRequest._reject(error);\n        stream._inFlightCloseRequest = undefined;\n        // Never execute sink abort() after sink close().\n        if (stream._pendingAbortRequest !== undefined) {\n            stream._pendingAbortRequest._reject(error);\n            stream._pendingAbortRequest = undefined;\n        }\n        WritableStreamDealWithRejection(stream, error);\n    }\n    // TODO(ricea): Fix alphabetical order.\n    function WritableStreamCloseQueuedOrInFlight(stream) {\n        if (stream._closeRequest === undefined && stream._inFlightCloseRequest === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamHasOperationMarkedInFlight(stream) {\n        if (stream._inFlightWriteRequest === undefined && stream._inFlightCloseRequest === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamMarkCloseRequestInFlight(stream) {\n        stream._inFlightCloseRequest = stream._closeRequest;\n        stream._closeRequest = undefined;\n    }\n    function WritableStreamMarkFirstWriteRequestInFlight(stream) {\n        stream._inFlightWriteRequest = stream._writeRequests.shift();\n    }\n    function WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream) {\n        if (stream._closeRequest !== undefined) {\n            stream._closeRequest._reject(stream._storedError);\n            stream._closeRequest = undefined;\n        }\n        const writer = stream._writer;\n        if (writer !== undefined) {\n            defaultWriterClosedPromiseReject(writer, stream._storedError);\n        }\n    }\n    function WritableStreamUpdateBackpressure(stream, backpressure) {\n        const writer = stream._writer;\n        if (writer !== undefined && backpressure !== stream._backpressure) {\n            if (backpressure) {\n                defaultWriterReadyPromiseReset(writer);\n            }\n            else {\n                defaultWriterReadyPromiseResolve(writer);\n            }\n        }\n        stream._backpressure = backpressure;\n    }\n    /**\n     * A default writer vended by a {@link WritableStream}.\n     *\n     * @public\n     */\n    class WritableStreamDefaultWriter {\n        constructor(stream) {\n            assertRequiredArgument(stream, 1, 'WritableStreamDefaultWriter');\n            assertWritableStream(stream, 'First parameter');\n            if (IsWritableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive writing by another writer');\n            }\n            this._ownerWritableStream = stream;\n            stream._writer = this;\n            const state = stream._state;\n            if (state === 'writable') {\n                if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._backpressure) {\n                    defaultWriterReadyPromiseInitialize(this);\n                }\n                else {\n                    defaultWriterReadyPromiseInitializeAsResolved(this);\n                }\n                defaultWriterClosedPromiseInitialize(this);\n            }\n            else if (state === 'erroring') {\n                defaultWriterReadyPromiseInitializeAsRejected(this, stream._storedError);\n                defaultWriterClosedPromiseInitialize(this);\n            }\n            else if (state === 'closed') {\n                defaultWriterReadyPromiseInitializeAsResolved(this);\n                defaultWriterClosedPromiseInitializeAsResolved(this);\n            }\n            else {\n                const storedError = stream._storedError;\n                defaultWriterReadyPromiseInitializeAsRejected(this, storedError);\n                defaultWriterClosedPromiseInitializeAsRejected(this, storedError);\n            }\n        }\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n         * the writer’s lock is released before the stream finishes closing.\n         */\n        get closed() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        }\n        /**\n         * Returns the desired size to fill the stream’s internal queue. It can be negative, if the queue is over-full.\n         * A producer can use this information to determine the right amount of data to write.\n         *\n         * It will be `null` if the stream cannot be successfully written to (due to either being errored, or having an abort\n         * queued up). It will return zero if the stream is closed. And the getter will throw an exception if invoked when\n         * the writer’s lock is released.\n         */\n        get desiredSize() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                throw defaultWriterBrandCheckException('desiredSize');\n            }\n            if (this._ownerWritableStream === undefined) {\n                throw defaultWriterLockException('desiredSize');\n            }\n            return WritableStreamDefaultWriterGetDesiredSize(this);\n        }\n        /**\n         * Returns a promise that will be fulfilled when the desired size to fill the stream’s internal queue transitions\n         * from non-positive to positive, signaling that it is no longer applying backpressure. Once the desired size dips\n         * back to zero or below, the getter will return a new promise that stays pending until the next transition.\n         *\n         * If the stream becomes errored or aborted, or the writer’s lock is released, the returned promise will become\n         * rejected.\n         */\n        get ready() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('ready'));\n            }\n            return this._readyPromise;\n        }\n        /**\n         * If the reader is active, behaves the same as {@link WritableStream.abort | stream.abort(reason)}.\n         */\n        abort(reason = undefined) {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('abort'));\n            }\n            if (this._ownerWritableStream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('abort'));\n            }\n            return WritableStreamDefaultWriterAbort(this, reason);\n        }\n        /**\n         * If the reader is active, behaves the same as {@link WritableStream.close | stream.close()}.\n         */\n        close() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('close'));\n            }\n            const stream = this._ownerWritableStream;\n            if (stream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('close'));\n            }\n            if (WritableStreamCloseQueuedOrInFlight(stream)) {\n                return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n            }\n            return WritableStreamDefaultWriterClose(this);\n        }\n        /**\n         * Releases the writer’s lock on the corresponding stream. After the lock is released, the writer is no longer active.\n         * If the associated stream is errored when the lock is released, the writer will appear errored in the same way from\n         * now on; otherwise, the writer will appear closed.\n         *\n         * Note that the lock can still be released even if some ongoing writes have not yet finished (i.e. even if the\n         * promises returned from previous calls to {@link WritableStreamDefaultWriter.write | write()} have not yet settled).\n         * It’s not necessary to hold the lock on the writer for the duration of the write; the lock instead simply prevents\n         * other producers from writing in an interleaved manner.\n         */\n        releaseLock() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                throw defaultWriterBrandCheckException('releaseLock');\n            }\n            const stream = this._ownerWritableStream;\n            if (stream === undefined) {\n                return;\n            }\n            WritableStreamDefaultWriterRelease(this);\n        }\n        write(chunk = undefined) {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('write'));\n            }\n            if (this._ownerWritableStream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('write to'));\n            }\n            return WritableStreamDefaultWriterWrite(this, chunk);\n        }\n    }\n    Object.defineProperties(WritableStreamDefaultWriter.prototype, {\n        abort: { enumerable: true },\n        close: { enumerable: true },\n        releaseLock: { enumerable: true },\n        write: { enumerable: true },\n        closed: { enumerable: true },\n        desiredSize: { enumerable: true },\n        ready: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStreamDefaultWriter.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStreamDefaultWriter',\n            configurable: true\n        });\n    }\n    // Abstract operations for the WritableStreamDefaultWriter.\n    function IsWritableStreamDefaultWriter(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_ownerWritableStream')) {\n            return false;\n        }\n        return x instanceof WritableStreamDefaultWriter;\n    }\n    // A client of WritableStreamDefaultWriter may use these functions directly to bypass state check.\n    function WritableStreamDefaultWriterAbort(writer, reason) {\n        const stream = writer._ownerWritableStream;\n        return WritableStreamAbort(stream, reason);\n    }\n    function WritableStreamDefaultWriterClose(writer) {\n        const stream = writer._ownerWritableStream;\n        return WritableStreamClose(stream);\n    }\n    function WritableStreamDefaultWriterCloseWithErrorPropagation(writer) {\n        const stream = writer._ownerWritableStream;\n        const state = stream._state;\n        if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n            return promiseResolvedWith(undefined);\n        }\n        if (state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        return WritableStreamDefaultWriterClose(writer);\n    }\n    function WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, error) {\n        if (writer._closedPromiseState === 'pending') {\n            defaultWriterClosedPromiseReject(writer, error);\n        }\n        else {\n            defaultWriterClosedPromiseResetToRejected(writer, error);\n        }\n    }\n    function WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, error) {\n        if (writer._readyPromiseState === 'pending') {\n            defaultWriterReadyPromiseReject(writer, error);\n        }\n        else {\n            defaultWriterReadyPromiseResetToRejected(writer, error);\n        }\n    }\n    function WritableStreamDefaultWriterGetDesiredSize(writer) {\n        const stream = writer._ownerWritableStream;\n        const state = stream._state;\n        if (state === 'errored' || state === 'erroring') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return WritableStreamDefaultControllerGetDesiredSize(stream._writableStreamController);\n    }\n    function WritableStreamDefaultWriterRelease(writer) {\n        const stream = writer._ownerWritableStream;\n        const releasedError = new TypeError(`Writer was released and can no longer be used to monitor the stream's closedness`);\n        WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, releasedError);\n        // The state transitions to \"errored\" before the sink abort() method runs, but the writer.closed promise is not\n        // rejected until afterwards. This means that simply testing state will not work.\n        WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, releasedError);\n        stream._writer = undefined;\n        writer._ownerWritableStream = undefined;\n    }\n    function WritableStreamDefaultWriterWrite(writer, chunk) {\n        const stream = writer._ownerWritableStream;\n        const controller = stream._writableStreamController;\n        const chunkSize = WritableStreamDefaultControllerGetChunkSize(controller, chunk);\n        if (stream !== writer._ownerWritableStream) {\n            return promiseRejectedWith(defaultWriterLockException('write to'));\n        }\n        const state = stream._state;\n        if (state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n            return promiseRejectedWith(new TypeError('The stream is closing or closed and cannot be written to'));\n        }\n        if (state === 'erroring') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        const promise = WritableStreamAddWriteRequest(stream);\n        WritableStreamDefaultControllerWrite(controller, chunk, chunkSize);\n        return promise;\n    }\n    const closeSentinel = {};\n    /**\n     * Allows control of a {@link WritableStream | writable stream}'s state and internal queue.\n     *\n     * @public\n     */\n    class WritableStreamDefaultController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * The reason which was passed to `WritableStream.abort(reason)` when the stream was aborted.\n         */\n        get abortReason() {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('abortReason');\n            }\n            return this._abortReason;\n        }\n        /**\n         * An `AbortSignal` that can be used to abort the pending write or close operation when the stream is aborted.\n         */\n        get signal() {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('signal');\n            }\n            if (this._abortController === undefined) {\n                // Older browsers or older Node versions may not support `AbortController` or `AbortSignal`.\n                // We don't want to bundle and ship an `AbortController` polyfill together with our polyfill,\n                // so instead we only implement support for `signal` if we find a global `AbortController` constructor.\n                throw new TypeError('WritableStreamDefaultController.prototype.signal is not supported');\n            }\n            return this._abortController.signal;\n        }\n        /**\n         * Closes the controlled writable stream, making all future interactions with it fail with the given error `e`.\n         *\n         * This method is rarely used, since usually it suffices to return a rejected promise from one of the underlying\n         * sink's methods. However, it can be useful for suddenly shutting down a stream in response to an event outside the\n         * normal lifecycle of interactions with the underlying sink.\n         */\n        error(e = undefined) {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('error');\n            }\n            const state = this._controlledWritableStream._state;\n            if (state !== 'writable') {\n                // The stream is closed, errored or will be soon. The sink can't do anything useful if it gets an error here, so\n                // just treat it as a no-op.\n                return;\n            }\n            WritableStreamDefaultControllerError(this, e);\n        }\n        /** @internal */\n        [AbortSteps](reason) {\n            const result = this._abortAlgorithm(reason);\n            WritableStreamDefaultControllerClearAlgorithms(this);\n            return result;\n        }\n        /** @internal */\n        [ErrorSteps]() {\n            ResetQueue(this);\n        }\n    }\n    Object.defineProperties(WritableStreamDefaultController.prototype, {\n        error: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Abstract operations implementing interface required by the WritableStream.\n    function IsWritableStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledWritableStream')) {\n            return false;\n        }\n        return x instanceof WritableStreamDefaultController;\n    }\n    function SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm) {\n        controller._controlledWritableStream = stream;\n        stream._writableStreamController = controller;\n        // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n        controller._queue = undefined;\n        controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._abortReason = undefined;\n        controller._abortController = createAbortController();\n        controller._started = false;\n        controller._strategySizeAlgorithm = sizeAlgorithm;\n        controller._strategyHWM = highWaterMark;\n        controller._writeAlgorithm = writeAlgorithm;\n        controller._closeAlgorithm = closeAlgorithm;\n        controller._abortAlgorithm = abortAlgorithm;\n        const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n        WritableStreamUpdateBackpressure(stream, backpressure);\n        const startResult = startAlgorithm();\n        const startPromise = promiseResolvedWith(startResult);\n        uponPromise(startPromise, () => {\n            controller._started = true;\n            WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n        }, r => {\n            controller._started = true;\n            WritableStreamDealWithRejection(stream, r);\n        });\n    }\n    function SetUpWritableStreamDefaultControllerFromUnderlyingSink(stream, underlyingSink, highWaterMark, sizeAlgorithm) {\n        const controller = Object.create(WritableStreamDefaultController.prototype);\n        let startAlgorithm = () => undefined;\n        let writeAlgorithm = () => promiseResolvedWith(undefined);\n        let closeAlgorithm = () => promiseResolvedWith(undefined);\n        let abortAlgorithm = () => promiseResolvedWith(undefined);\n        if (underlyingSink.start !== undefined) {\n            startAlgorithm = () => underlyingSink.start(controller);\n        }\n        if (underlyingSink.write !== undefined) {\n            writeAlgorithm = chunk => underlyingSink.write(chunk, controller);\n        }\n        if (underlyingSink.close !== undefined) {\n            closeAlgorithm = () => underlyingSink.close();\n        }\n        if (underlyingSink.abort !== undefined) {\n            abortAlgorithm = reason => underlyingSink.abort(reason);\n        }\n        SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n    }\n    // ClearAlgorithms may be called twice. Erroring the same stream in multiple ways will often result in redundant calls.\n    function WritableStreamDefaultControllerClearAlgorithms(controller) {\n        controller._writeAlgorithm = undefined;\n        controller._closeAlgorithm = undefined;\n        controller._abortAlgorithm = undefined;\n        controller._strategySizeAlgorithm = undefined;\n    }\n    function WritableStreamDefaultControllerClose(controller) {\n        EnqueueValueWithSize(controller, closeSentinel, 0);\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }\n    function WritableStreamDefaultControllerGetChunkSize(controller, chunk) {\n        try {\n            return controller._strategySizeAlgorithm(chunk);\n        }\n        catch (chunkSizeE) {\n            WritableStreamDefaultControllerErrorIfNeeded(controller, chunkSizeE);\n            return 1;\n        }\n    }\n    function WritableStreamDefaultControllerGetDesiredSize(controller) {\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    function WritableStreamDefaultControllerWrite(controller, chunk, chunkSize) {\n        try {\n            EnqueueValueWithSize(controller, chunk, chunkSize);\n        }\n        catch (enqueueE) {\n            WritableStreamDefaultControllerErrorIfNeeded(controller, enqueueE);\n            return;\n        }\n        const stream = controller._controlledWritableStream;\n        if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._state === 'writable') {\n            const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n            WritableStreamUpdateBackpressure(stream, backpressure);\n        }\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }\n    // Abstract operations for the WritableStreamDefaultController.\n    function WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller) {\n        const stream = controller._controlledWritableStream;\n        if (!controller._started) {\n            return;\n        }\n        if (stream._inFlightWriteRequest !== undefined) {\n            return;\n        }\n        const state = stream._state;\n        if (state === 'erroring') {\n            WritableStreamFinishErroring(stream);\n            return;\n        }\n        if (controller._queue.length === 0) {\n            return;\n        }\n        const value = PeekQueueValue(controller);\n        if (value === closeSentinel) {\n            WritableStreamDefaultControllerProcessClose(controller);\n        }\n        else {\n            WritableStreamDefaultControllerProcessWrite(controller, value);\n        }\n    }\n    function WritableStreamDefaultControllerErrorIfNeeded(controller, error) {\n        if (controller._controlledWritableStream._state === 'writable') {\n            WritableStreamDefaultControllerError(controller, error);\n        }\n    }\n    function WritableStreamDefaultControllerProcessClose(controller) {\n        const stream = controller._controlledWritableStream;\n        WritableStreamMarkCloseRequestInFlight(stream);\n        DequeueValue(controller);\n        const sinkClosePromise = controller._closeAlgorithm();\n        WritableStreamDefaultControllerClearAlgorithms(controller);\n        uponPromise(sinkClosePromise, () => {\n            WritableStreamFinishInFlightClose(stream);\n        }, reason => {\n            WritableStreamFinishInFlightCloseWithError(stream, reason);\n        });\n    }\n    function WritableStreamDefaultControllerProcessWrite(controller, chunk) {\n        const stream = controller._controlledWritableStream;\n        WritableStreamMarkFirstWriteRequestInFlight(stream);\n        const sinkWritePromise = controller._writeAlgorithm(chunk);\n        uponPromise(sinkWritePromise, () => {\n            WritableStreamFinishInFlightWrite(stream);\n            const state = stream._state;\n            DequeueValue(controller);\n            if (!WritableStreamCloseQueuedOrInFlight(stream) && state === 'writable') {\n                const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n                WritableStreamUpdateBackpressure(stream, backpressure);\n            }\n            WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n        }, reason => {\n            if (stream._state === 'writable') {\n                WritableStreamDefaultControllerClearAlgorithms(controller);\n            }\n            WritableStreamFinishInFlightWriteWithError(stream, reason);\n        });\n    }\n    function WritableStreamDefaultControllerGetBackpressure(controller) {\n        const desiredSize = WritableStreamDefaultControllerGetDesiredSize(controller);\n        return desiredSize <= 0;\n    }\n    // A client of WritableStreamDefaultController may use these functions directly to bypass state check.\n    function WritableStreamDefaultControllerError(controller, error) {\n        const stream = controller._controlledWritableStream;\n        WritableStreamDefaultControllerClearAlgorithms(controller);\n        WritableStreamStartErroring(stream, error);\n    }\n    // Helper functions for the WritableStream.\n    function streamBrandCheckException$2(name) {\n        return new TypeError(`WritableStream.prototype.${name} can only be used on a WritableStream`);\n    }\n    // Helper functions for the WritableStreamDefaultController.\n    function defaultControllerBrandCheckException$2(name) {\n        return new TypeError(`WritableStreamDefaultController.prototype.${name} can only be used on a WritableStreamDefaultController`);\n    }\n    // Helper functions for the WritableStreamDefaultWriter.\n    function defaultWriterBrandCheckException(name) {\n        return new TypeError(`WritableStreamDefaultWriter.prototype.${name} can only be used on a WritableStreamDefaultWriter`);\n    }\n    function defaultWriterLockException(name) {\n        return new TypeError('Cannot ' + name + ' a stream using a released writer');\n    }\n    function defaultWriterClosedPromiseInitialize(writer) {\n        writer._closedPromise = newPromise((resolve, reject) => {\n            writer._closedPromise_resolve = resolve;\n            writer._closedPromise_reject = reject;\n            writer._closedPromiseState = 'pending';\n        });\n    }\n    function defaultWriterClosedPromiseInitializeAsRejected(writer, reason) {\n        defaultWriterClosedPromiseInitialize(writer);\n        defaultWriterClosedPromiseReject(writer, reason);\n    }\n    function defaultWriterClosedPromiseInitializeAsResolved(writer) {\n        defaultWriterClosedPromiseInitialize(writer);\n        defaultWriterClosedPromiseResolve(writer);\n    }\n    function defaultWriterClosedPromiseReject(writer, reason) {\n        if (writer._closedPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(writer._closedPromise);\n        writer._closedPromise_reject(reason);\n        writer._closedPromise_resolve = undefined;\n        writer._closedPromise_reject = undefined;\n        writer._closedPromiseState = 'rejected';\n    }\n    function defaultWriterClosedPromiseResetToRejected(writer, reason) {\n        defaultWriterClosedPromiseInitializeAsRejected(writer, reason);\n    }\n    function defaultWriterClosedPromiseResolve(writer) {\n        if (writer._closedPromise_resolve === undefined) {\n            return;\n        }\n        writer._closedPromise_resolve(undefined);\n        writer._closedPromise_resolve = undefined;\n        writer._closedPromise_reject = undefined;\n        writer._closedPromiseState = 'resolved';\n    }\n    function defaultWriterReadyPromiseInitialize(writer) {\n        writer._readyPromise = newPromise((resolve, reject) => {\n            writer._readyPromise_resolve = resolve;\n            writer._readyPromise_reject = reject;\n        });\n        writer._readyPromiseState = 'pending';\n    }\n    function defaultWriterReadyPromiseInitializeAsRejected(writer, reason) {\n        defaultWriterReadyPromiseInitialize(writer);\n        defaultWriterReadyPromiseReject(writer, reason);\n    }\n    function defaultWriterReadyPromiseInitializeAsResolved(writer) {\n        defaultWriterReadyPromiseInitialize(writer);\n        defaultWriterReadyPromiseResolve(writer);\n    }\n    function defaultWriterReadyPromiseReject(writer, reason) {\n        if (writer._readyPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(writer._readyPromise);\n        writer._readyPromise_reject(reason);\n        writer._readyPromise_resolve = undefined;\n        writer._readyPromise_reject = undefined;\n        writer._readyPromiseState = 'rejected';\n    }\n    function defaultWriterReadyPromiseReset(writer) {\n        defaultWriterReadyPromiseInitialize(writer);\n    }\n    function defaultWriterReadyPromiseResetToRejected(writer, reason) {\n        defaultWriterReadyPromiseInitializeAsRejected(writer, reason);\n    }\n    function defaultWriterReadyPromiseResolve(writer) {\n        if (writer._readyPromise_resolve === undefined) {\n            return;\n        }\n        writer._readyPromise_resolve(undefined);\n        writer._readyPromise_resolve = undefined;\n        writer._readyPromise_reject = undefined;\n        writer._readyPromiseState = 'fulfilled';\n    }\n\n    /// <reference lib=\"dom\" />\n    const NativeDOMException = typeof DOMException !== 'undefined' ? DOMException : undefined;\n\n    /// <reference types=\"node\" />\n    function isDOMExceptionConstructor(ctor) {\n        if (!(typeof ctor === 'function' || typeof ctor === 'object')) {\n            return false;\n        }\n        try {\n            new ctor();\n            return true;\n        }\n        catch (_a) {\n            return false;\n        }\n    }\n    function createDOMExceptionPolyfill() {\n        // eslint-disable-next-line no-shadow\n        const ctor = function DOMException(message, name) {\n            this.message = message || '';\n            this.name = name || 'Error';\n            if (Error.captureStackTrace) {\n                Error.captureStackTrace(this, this.constructor);\n            }\n        };\n        ctor.prototype = Object.create(Error.prototype);\n        Object.defineProperty(ctor.prototype, 'constructor', { value: ctor, writable: true, configurable: true });\n        return ctor;\n    }\n    // eslint-disable-next-line no-redeclare\n    const DOMException$1 = isDOMExceptionConstructor(NativeDOMException) ? NativeDOMException : createDOMExceptionPolyfill();\n\n    function ReadableStreamPipeTo(source, dest, preventClose, preventAbort, preventCancel, signal) {\n        const reader = AcquireReadableStreamDefaultReader(source);\n        const writer = AcquireWritableStreamDefaultWriter(dest);\n        source._disturbed = true;\n        let shuttingDown = false;\n        // This is used to keep track of the spec's requirement that we wait for ongoing writes during shutdown.\n        let currentWrite = promiseResolvedWith(undefined);\n        return newPromise((resolve, reject) => {\n            let abortAlgorithm;\n            if (signal !== undefined) {\n                abortAlgorithm = () => {\n                    const error = new DOMException$1('Aborted', 'AbortError');\n                    const actions = [];\n                    if (!preventAbort) {\n                        actions.push(() => {\n                            if (dest._state === 'writable') {\n                                return WritableStreamAbort(dest, error);\n                            }\n                            return promiseResolvedWith(undefined);\n                        });\n                    }\n                    if (!preventCancel) {\n                        actions.push(() => {\n                            if (source._state === 'readable') {\n                                return ReadableStreamCancel(source, error);\n                            }\n                            return promiseResolvedWith(undefined);\n                        });\n                    }\n                    shutdownWithAction(() => Promise.all(actions.map(action => action())), true, error);\n                };\n                if (signal.aborted) {\n                    abortAlgorithm();\n                    return;\n                }\n                signal.addEventListener('abort', abortAlgorithm);\n            }\n            // Using reader and writer, read all chunks from this and write them to dest\n            // - Backpressure must be enforced\n            // - Shutdown must stop all activity\n            function pipeLoop() {\n                return newPromise((resolveLoop, rejectLoop) => {\n                    function next(done) {\n                        if (done) {\n                            resolveLoop();\n                        }\n                        else {\n                            // Use `PerformPromiseThen` instead of `uponPromise` to avoid\n                            // adding unnecessary `.catch(rethrowAssertionErrorRejection)` handlers\n                            PerformPromiseThen(pipeStep(), next, rejectLoop);\n                        }\n                    }\n                    next(false);\n                });\n            }\n            function pipeStep() {\n                if (shuttingDown) {\n                    return promiseResolvedWith(true);\n                }\n                return PerformPromiseThen(writer._readyPromise, () => {\n                    return newPromise((resolveRead, rejectRead) => {\n                        ReadableStreamDefaultReaderRead(reader, {\n                            _chunkSteps: chunk => {\n                                currentWrite = PerformPromiseThen(WritableStreamDefaultWriterWrite(writer, chunk), undefined, noop);\n                                resolveRead(false);\n                            },\n                            _closeSteps: () => resolveRead(true),\n                            _errorSteps: rejectRead\n                        });\n                    });\n                });\n            }\n            // Errors must be propagated forward\n            isOrBecomesErrored(source, reader._closedPromise, storedError => {\n                if (!preventAbort) {\n                    shutdownWithAction(() => WritableStreamAbort(dest, storedError), true, storedError);\n                }\n                else {\n                    shutdown(true, storedError);\n                }\n            });\n            // Errors must be propagated backward\n            isOrBecomesErrored(dest, writer._closedPromise, storedError => {\n                if (!preventCancel) {\n                    shutdownWithAction(() => ReadableStreamCancel(source, storedError), true, storedError);\n                }\n                else {\n                    shutdown(true, storedError);\n                }\n            });\n            // Closing must be propagated forward\n            isOrBecomesClosed(source, reader._closedPromise, () => {\n                if (!preventClose) {\n                    shutdownWithAction(() => WritableStreamDefaultWriterCloseWithErrorPropagation(writer));\n                }\n                else {\n                    shutdown();\n                }\n            });\n            // Closing must be propagated backward\n            if (WritableStreamCloseQueuedOrInFlight(dest) || dest._state === 'closed') {\n                const destClosed = new TypeError('the destination writable stream closed before all data could be piped to it');\n                if (!preventCancel) {\n                    shutdownWithAction(() => ReadableStreamCancel(source, destClosed), true, destClosed);\n                }\n                else {\n                    shutdown(true, destClosed);\n                }\n            }\n            setPromiseIsHandledToTrue(pipeLoop());\n            function waitForWritesToFinish() {\n                // Another write may have started while we were waiting on this currentWrite, so we have to be sure to wait\n                // for that too.\n                const oldCurrentWrite = currentWrite;\n                return PerformPromiseThen(currentWrite, () => oldCurrentWrite !== currentWrite ? waitForWritesToFinish() : undefined);\n            }\n            function isOrBecomesErrored(stream, promise, action) {\n                if (stream._state === 'errored') {\n                    action(stream._storedError);\n                }\n                else {\n                    uponRejection(promise, action);\n                }\n            }\n            function isOrBecomesClosed(stream, promise, action) {\n                if (stream._state === 'closed') {\n                    action();\n                }\n                else {\n                    uponFulfillment(promise, action);\n                }\n            }\n            function shutdownWithAction(action, originalIsError, originalError) {\n                if (shuttingDown) {\n                    return;\n                }\n                shuttingDown = true;\n                if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                    uponFulfillment(waitForWritesToFinish(), doTheRest);\n                }\n                else {\n                    doTheRest();\n                }\n                function doTheRest() {\n                    uponPromise(action(), () => finalize(originalIsError, originalError), newError => finalize(true, newError));\n                }\n            }\n            function shutdown(isError, error) {\n                if (shuttingDown) {\n                    return;\n                }\n                shuttingDown = true;\n                if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                    uponFulfillment(waitForWritesToFinish(), () => finalize(isError, error));\n                }\n                else {\n                    finalize(isError, error);\n                }\n            }\n            function finalize(isError, error) {\n                WritableStreamDefaultWriterRelease(writer);\n                ReadableStreamReaderGenericRelease(reader);\n                if (signal !== undefined) {\n                    signal.removeEventListener('abort', abortAlgorithm);\n                }\n                if (isError) {\n                    reject(error);\n                }\n                else {\n                    resolve(undefined);\n                }\n            }\n        });\n    }\n\n    /**\n     * Allows control of a {@link ReadableStream | readable stream}'s state and internal queue.\n     *\n     * @public\n     */\n    class ReadableStreamDefaultController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n         * over-full. An underlying source ought to use this information to determine when and how to apply backpressure.\n         */\n        get desiredSize() {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('desiredSize');\n            }\n            return ReadableStreamDefaultControllerGetDesiredSize(this);\n        }\n        /**\n         * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n         * the stream, but once those are read, the stream will become closed.\n         */\n        close() {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('close');\n            }\n            if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n                throw new TypeError('The stream is not in a state that permits close');\n            }\n            ReadableStreamDefaultControllerClose(this);\n        }\n        enqueue(chunk = undefined) {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('enqueue');\n            }\n            if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n                throw new TypeError('The stream is not in a state that permits enqueue');\n            }\n            return ReadableStreamDefaultControllerEnqueue(this, chunk);\n        }\n        /**\n         * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n         */\n        error(e = undefined) {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('error');\n            }\n            ReadableStreamDefaultControllerError(this, e);\n        }\n        /** @internal */\n        [CancelSteps](reason) {\n            ResetQueue(this);\n            const result = this._cancelAlgorithm(reason);\n            ReadableStreamDefaultControllerClearAlgorithms(this);\n            return result;\n        }\n        /** @internal */\n        [PullSteps](readRequest) {\n            const stream = this._controlledReadableStream;\n            if (this._queue.length > 0) {\n                const chunk = DequeueValue(this);\n                if (this._closeRequested && this._queue.length === 0) {\n                    ReadableStreamDefaultControllerClearAlgorithms(this);\n                    ReadableStreamClose(stream);\n                }\n                else {\n                    ReadableStreamDefaultControllerCallPullIfNeeded(this);\n                }\n                readRequest._chunkSteps(chunk);\n            }\n            else {\n                ReadableStreamAddReadRequest(stream, readRequest);\n                ReadableStreamDefaultControllerCallPullIfNeeded(this);\n            }\n        }\n    }\n    Object.defineProperties(ReadableStreamDefaultController.prototype, {\n        close: { enumerable: true },\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableStreamDefaultController.\n    function IsReadableStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableStream')) {\n            return false;\n        }\n        return x instanceof ReadableStreamDefaultController;\n    }\n    function ReadableStreamDefaultControllerCallPullIfNeeded(controller) {\n        const shouldPull = ReadableStreamDefaultControllerShouldCallPull(controller);\n        if (!shouldPull) {\n            return;\n        }\n        if (controller._pulling) {\n            controller._pullAgain = true;\n            return;\n        }\n        controller._pulling = true;\n        const pullPromise = controller._pullAlgorithm();\n        uponPromise(pullPromise, () => {\n            controller._pulling = false;\n            if (controller._pullAgain) {\n                controller._pullAgain = false;\n                ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n            }\n        }, e => {\n            ReadableStreamDefaultControllerError(controller, e);\n        });\n    }\n    function ReadableStreamDefaultControllerShouldCallPull(controller) {\n        const stream = controller._controlledReadableStream;\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return false;\n        }\n        if (!controller._started) {\n            return false;\n        }\n        if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            return true;\n        }\n        const desiredSize = ReadableStreamDefaultControllerGetDesiredSize(controller);\n        if (desiredSize > 0) {\n            return true;\n        }\n        return false;\n    }\n    function ReadableStreamDefaultControllerClearAlgorithms(controller) {\n        controller._pullAlgorithm = undefined;\n        controller._cancelAlgorithm = undefined;\n        controller._strategySizeAlgorithm = undefined;\n    }\n    // A client of ReadableStreamDefaultController may use these functions directly to bypass state check.\n    function ReadableStreamDefaultControllerClose(controller) {\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return;\n        }\n        const stream = controller._controlledReadableStream;\n        controller._closeRequested = true;\n        if (controller._queue.length === 0) {\n            ReadableStreamDefaultControllerClearAlgorithms(controller);\n            ReadableStreamClose(stream);\n        }\n    }\n    function ReadableStreamDefaultControllerEnqueue(controller, chunk) {\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return;\n        }\n        const stream = controller._controlledReadableStream;\n        if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            ReadableStreamFulfillReadRequest(stream, chunk, false);\n        }\n        else {\n            let chunkSize;\n            try {\n                chunkSize = controller._strategySizeAlgorithm(chunk);\n            }\n            catch (chunkSizeE) {\n                ReadableStreamDefaultControllerError(controller, chunkSizeE);\n                throw chunkSizeE;\n            }\n            try {\n                EnqueueValueWithSize(controller, chunk, chunkSize);\n            }\n            catch (enqueueE) {\n                ReadableStreamDefaultControllerError(controller, enqueueE);\n                throw enqueueE;\n            }\n        }\n        ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n    }\n    function ReadableStreamDefaultControllerError(controller, e) {\n        const stream = controller._controlledReadableStream;\n        if (stream._state !== 'readable') {\n            return;\n        }\n        ResetQueue(controller);\n        ReadableStreamDefaultControllerClearAlgorithms(controller);\n        ReadableStreamError(stream, e);\n    }\n    function ReadableStreamDefaultControllerGetDesiredSize(controller) {\n        const state = controller._controlledReadableStream._state;\n        if (state === 'errored') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    // This is used in the implementation of TransformStream.\n    function ReadableStreamDefaultControllerHasBackpressure(controller) {\n        if (ReadableStreamDefaultControllerShouldCallPull(controller)) {\n            return false;\n        }\n        return true;\n    }\n    function ReadableStreamDefaultControllerCanCloseOrEnqueue(controller) {\n        const state = controller._controlledReadableStream._state;\n        if (!controller._closeRequested && state === 'readable') {\n            return true;\n        }\n        return false;\n    }\n    function SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm) {\n        controller._controlledReadableStream = stream;\n        controller._queue = undefined;\n        controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._started = false;\n        controller._closeRequested = false;\n        controller._pullAgain = false;\n        controller._pulling = false;\n        controller._strategySizeAlgorithm = sizeAlgorithm;\n        controller._strategyHWM = highWaterMark;\n        controller._pullAlgorithm = pullAlgorithm;\n        controller._cancelAlgorithm = cancelAlgorithm;\n        stream._readableStreamController = controller;\n        const startResult = startAlgorithm();\n        uponPromise(promiseResolvedWith(startResult), () => {\n            controller._started = true;\n            ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n        }, r => {\n            ReadableStreamDefaultControllerError(controller, r);\n        });\n    }\n    function SetUpReadableStreamDefaultControllerFromUnderlyingSource(stream, underlyingSource, highWaterMark, sizeAlgorithm) {\n        const controller = Object.create(ReadableStreamDefaultController.prototype);\n        let startAlgorithm = () => undefined;\n        let pullAlgorithm = () => promiseResolvedWith(undefined);\n        let cancelAlgorithm = () => promiseResolvedWith(undefined);\n        if (underlyingSource.start !== undefined) {\n            startAlgorithm = () => underlyingSource.start(controller);\n        }\n        if (underlyingSource.pull !== undefined) {\n            pullAlgorithm = () => underlyingSource.pull(controller);\n        }\n        if (underlyingSource.cancel !== undefined) {\n            cancelAlgorithm = reason => underlyingSource.cancel(reason);\n        }\n        SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n    }\n    // Helper functions for the ReadableStreamDefaultController.\n    function defaultControllerBrandCheckException$1(name) {\n        return new TypeError(`ReadableStreamDefaultController.prototype.${name} can only be used on a ReadableStreamDefaultController`);\n    }\n\n    function ReadableStreamTee(stream, cloneForBranch2) {\n        if (IsReadableByteStreamController(stream._readableStreamController)) {\n            return ReadableByteStreamTee(stream);\n        }\n        return ReadableStreamDefaultTee(stream);\n    }\n    function ReadableStreamDefaultTee(stream, cloneForBranch2) {\n        const reader = AcquireReadableStreamDefaultReader(stream);\n        let reading = false;\n        let canceled1 = false;\n        let canceled2 = false;\n        let reason1;\n        let reason2;\n        let branch1;\n        let branch2;\n        let resolveCancelPromise;\n        const cancelPromise = newPromise(resolve => {\n            resolveCancelPromise = resolve;\n        });\n        function pullAlgorithm() {\n            if (reading) {\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            const readRequest = {\n                _chunkSteps: chunk => {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(() => {\n                        reading = false;\n                        const chunk1 = chunk;\n                        const chunk2 = chunk;\n                        // There is no way to access the cloning code right now in the reference implementation.\n                        // If we add one then we'll need an implementation for serializable objects.\n                        // if (!canceled2 && cloneForBranch2) {\n                        //   chunk2 = StructuredDeserialize(StructuredSerialize(chunk2));\n                        // }\n                        if (!canceled1) {\n                            ReadableStreamDefaultControllerEnqueue(branch1._readableStreamController, chunk1);\n                        }\n                        if (!canceled2) {\n                            ReadableStreamDefaultControllerEnqueue(branch2._readableStreamController, chunk2);\n                        }\n                    });\n                },\n                _closeSteps: () => {\n                    reading = false;\n                    if (!canceled1) {\n                        ReadableStreamDefaultControllerClose(branch1._readableStreamController);\n                    }\n                    if (!canceled2) {\n                        ReadableStreamDefaultControllerClose(branch2._readableStreamController);\n                    }\n                    if (!canceled1 || !canceled2) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: () => {\n                    reading = false;\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n            return promiseResolvedWith(undefined);\n        }\n        function cancel1Algorithm(reason) {\n            canceled1 = true;\n            reason1 = reason;\n            if (canceled2) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function cancel2Algorithm(reason) {\n            canceled2 = true;\n            reason2 = reason;\n            if (canceled1) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function startAlgorithm() {\n            // do nothing\n        }\n        branch1 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel1Algorithm);\n        branch2 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel2Algorithm);\n        uponRejection(reader._closedPromise, (r) => {\n            ReadableStreamDefaultControllerError(branch1._readableStreamController, r);\n            ReadableStreamDefaultControllerError(branch2._readableStreamController, r);\n            if (!canceled1 || !canceled2) {\n                resolveCancelPromise(undefined);\n            }\n        });\n        return [branch1, branch2];\n    }\n    function ReadableByteStreamTee(stream) {\n        let reader = AcquireReadableStreamDefaultReader(stream);\n        let reading = false;\n        let canceled1 = false;\n        let canceled2 = false;\n        let reason1;\n        let reason2;\n        let branch1;\n        let branch2;\n        let resolveCancelPromise;\n        const cancelPromise = newPromise(resolve => {\n            resolveCancelPromise = resolve;\n        });\n        function forwardReaderError(thisReader) {\n            uponRejection(thisReader._closedPromise, r => {\n                if (thisReader !== reader) {\n                    return;\n                }\n                ReadableByteStreamControllerError(branch1._readableStreamController, r);\n                ReadableByteStreamControllerError(branch2._readableStreamController, r);\n                if (!canceled1 || !canceled2) {\n                    resolveCancelPromise(undefined);\n                }\n            });\n        }\n        function pullWithDefaultReader() {\n            if (IsReadableStreamBYOBReader(reader)) {\n                ReadableStreamReaderGenericRelease(reader);\n                reader = AcquireReadableStreamDefaultReader(stream);\n                forwardReaderError(reader);\n            }\n            const readRequest = {\n                _chunkSteps: chunk => {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(() => {\n                        reading = false;\n                        const chunk1 = chunk;\n                        let chunk2 = chunk;\n                        if (!canceled1 && !canceled2) {\n                            try {\n                                chunk2 = CloneAsUint8Array(chunk);\n                            }\n                            catch (cloneE) {\n                                ReadableByteStreamControllerError(branch1._readableStreamController, cloneE);\n                                ReadableByteStreamControllerError(branch2._readableStreamController, cloneE);\n                                resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n                                return;\n                            }\n                        }\n                        if (!canceled1) {\n                            ReadableByteStreamControllerEnqueue(branch1._readableStreamController, chunk1);\n                        }\n                        if (!canceled2) {\n                            ReadableByteStreamControllerEnqueue(branch2._readableStreamController, chunk2);\n                        }\n                    });\n                },\n                _closeSteps: () => {\n                    reading = false;\n                    if (!canceled1) {\n                        ReadableByteStreamControllerClose(branch1._readableStreamController);\n                    }\n                    if (!canceled2) {\n                        ReadableByteStreamControllerClose(branch2._readableStreamController);\n                    }\n                    if (branch1._readableStreamController._pendingPullIntos.length > 0) {\n                        ReadableByteStreamControllerRespond(branch1._readableStreamController, 0);\n                    }\n                    if (branch2._readableStreamController._pendingPullIntos.length > 0) {\n                        ReadableByteStreamControllerRespond(branch2._readableStreamController, 0);\n                    }\n                    if (!canceled1 || !canceled2) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: () => {\n                    reading = false;\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n        }\n        function pullWithBYOBReader(view, forBranch2) {\n            if (IsReadableStreamDefaultReader(reader)) {\n                ReadableStreamReaderGenericRelease(reader);\n                reader = AcquireReadableStreamBYOBReader(stream);\n                forwardReaderError(reader);\n            }\n            const byobBranch = forBranch2 ? branch2 : branch1;\n            const otherBranch = forBranch2 ? branch1 : branch2;\n            const readIntoRequest = {\n                _chunkSteps: chunk => {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(() => {\n                        reading = false;\n                        const byobCanceled = forBranch2 ? canceled2 : canceled1;\n                        const otherCanceled = forBranch2 ? canceled1 : canceled2;\n                        if (!otherCanceled) {\n                            let clonedChunk;\n                            try {\n                                clonedChunk = CloneAsUint8Array(chunk);\n                            }\n                            catch (cloneE) {\n                                ReadableByteStreamControllerError(byobBranch._readableStreamController, cloneE);\n                                ReadableByteStreamControllerError(otherBranch._readableStreamController, cloneE);\n                                resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n                                return;\n                            }\n                            if (!byobCanceled) {\n                                ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                            }\n                            ReadableByteStreamControllerEnqueue(otherBranch._readableStreamController, clonedChunk);\n                        }\n                        else if (!byobCanceled) {\n                            ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                        }\n                    });\n                },\n                _closeSteps: chunk => {\n                    reading = false;\n                    const byobCanceled = forBranch2 ? canceled2 : canceled1;\n                    const otherCanceled = forBranch2 ? canceled1 : canceled2;\n                    if (!byobCanceled) {\n                        ReadableByteStreamControllerClose(byobBranch._readableStreamController);\n                    }\n                    if (!otherCanceled) {\n                        ReadableByteStreamControllerClose(otherBranch._readableStreamController);\n                    }\n                    if (chunk !== undefined) {\n                        if (!byobCanceled) {\n                            ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                        }\n                        if (!otherCanceled && otherBranch._readableStreamController._pendingPullIntos.length > 0) {\n                            ReadableByteStreamControllerRespond(otherBranch._readableStreamController, 0);\n                        }\n                    }\n                    if (!byobCanceled || !otherCanceled) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: () => {\n                    reading = false;\n                }\n            };\n            ReadableStreamBYOBReaderRead(reader, view, readIntoRequest);\n        }\n        function pull1Algorithm() {\n            if (reading) {\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            const byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch1._readableStreamController);\n            if (byobRequest === null) {\n                pullWithDefaultReader();\n            }\n            else {\n                pullWithBYOBReader(byobRequest._view, false);\n            }\n            return promiseResolvedWith(undefined);\n        }\n        function pull2Algorithm() {\n            if (reading) {\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            const byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch2._readableStreamController);\n            if (byobRequest === null) {\n                pullWithDefaultReader();\n            }\n            else {\n                pullWithBYOBReader(byobRequest._view, true);\n            }\n            return promiseResolvedWith(undefined);\n        }\n        function cancel1Algorithm(reason) {\n            canceled1 = true;\n            reason1 = reason;\n            if (canceled2) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function cancel2Algorithm(reason) {\n            canceled2 = true;\n            reason2 = reason;\n            if (canceled1) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function startAlgorithm() {\n            return;\n        }\n        branch1 = CreateReadableByteStream(startAlgorithm, pull1Algorithm, cancel1Algorithm);\n        branch2 = CreateReadableByteStream(startAlgorithm, pull2Algorithm, cancel2Algorithm);\n        forwardReaderError(reader);\n        return [branch1, branch2];\n    }\n\n    function convertUnderlyingDefaultOrByteSource(source, context) {\n        assertDictionary(source, context);\n        const original = source;\n        const autoAllocateChunkSize = original === null || original === void 0 ? void 0 : original.autoAllocateChunkSize;\n        const cancel = original === null || original === void 0 ? void 0 : original.cancel;\n        const pull = original === null || original === void 0 ? void 0 : original.pull;\n        const start = original === null || original === void 0 ? void 0 : original.start;\n        const type = original === null || original === void 0 ? void 0 : original.type;\n        return {\n            autoAllocateChunkSize: autoAllocateChunkSize === undefined ?\n                undefined :\n                convertUnsignedLongLongWithEnforceRange(autoAllocateChunkSize, `${context} has member 'autoAllocateChunkSize' that`),\n            cancel: cancel === undefined ?\n                undefined :\n                convertUnderlyingSourceCancelCallback(cancel, original, `${context} has member 'cancel' that`),\n            pull: pull === undefined ?\n                undefined :\n                convertUnderlyingSourcePullCallback(pull, original, `${context} has member 'pull' that`),\n            start: start === undefined ?\n                undefined :\n                convertUnderlyingSourceStartCallback(start, original, `${context} has member 'start' that`),\n            type: type === undefined ? undefined : convertReadableStreamType(type, `${context} has member 'type' that`)\n        };\n    }\n    function convertUnderlyingSourceCancelCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (reason) => promiseCall(fn, original, [reason]);\n    }\n    function convertUnderlyingSourcePullCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => promiseCall(fn, original, [controller]);\n    }\n    function convertUnderlyingSourceStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => reflectCall(fn, original, [controller]);\n    }\n    function convertReadableStreamType(type, context) {\n        type = `${type}`;\n        if (type !== 'bytes') {\n            throw new TypeError(`${context} '${type}' is not a valid enumeration value for ReadableStreamType`);\n        }\n        return type;\n    }\n\n    function convertReaderOptions(options, context) {\n        assertDictionary(options, context);\n        const mode = options === null || options === void 0 ? void 0 : options.mode;\n        return {\n            mode: mode === undefined ? undefined : convertReadableStreamReaderMode(mode, `${context} has member 'mode' that`)\n        };\n    }\n    function convertReadableStreamReaderMode(mode, context) {\n        mode = `${mode}`;\n        if (mode !== 'byob') {\n            throw new TypeError(`${context} '${mode}' is not a valid enumeration value for ReadableStreamReaderMode`);\n        }\n        return mode;\n    }\n\n    function convertIteratorOptions(options, context) {\n        assertDictionary(options, context);\n        const preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n        return { preventCancel: Boolean(preventCancel) };\n    }\n\n    function convertPipeOptions(options, context) {\n        assertDictionary(options, context);\n        const preventAbort = options === null || options === void 0 ? void 0 : options.preventAbort;\n        const preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n        const preventClose = options === null || options === void 0 ? void 0 : options.preventClose;\n        const signal = options === null || options === void 0 ? void 0 : options.signal;\n        if (signal !== undefined) {\n            assertAbortSignal(signal, `${context} has member 'signal' that`);\n        }\n        return {\n            preventAbort: Boolean(preventAbort),\n            preventCancel: Boolean(preventCancel),\n            preventClose: Boolean(preventClose),\n            signal\n        };\n    }\n    function assertAbortSignal(signal, context) {\n        if (!isAbortSignal(signal)) {\n            throw new TypeError(`${context} is not an AbortSignal.`);\n        }\n    }\n\n    function convertReadableWritablePair(pair, context) {\n        assertDictionary(pair, context);\n        const readable = pair === null || pair === void 0 ? void 0 : pair.readable;\n        assertRequiredField(readable, 'readable', 'ReadableWritablePair');\n        assertReadableStream(readable, `${context} has member 'readable' that`);\n        const writable = pair === null || pair === void 0 ? void 0 : pair.writable;\n        assertRequiredField(writable, 'writable', 'ReadableWritablePair');\n        assertWritableStream(writable, `${context} has member 'writable' that`);\n        return { readable, writable };\n    }\n\n    /**\n     * A readable stream represents a source of data, from which you can read.\n     *\n     * @public\n     */\n    class ReadableStream {\n        constructor(rawUnderlyingSource = {}, rawStrategy = {}) {\n            if (rawUnderlyingSource === undefined) {\n                rawUnderlyingSource = null;\n            }\n            else {\n                assertObject(rawUnderlyingSource, 'First parameter');\n            }\n            const strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n            const underlyingSource = convertUnderlyingDefaultOrByteSource(rawUnderlyingSource, 'First parameter');\n            InitializeReadableStream(this);\n            if (underlyingSource.type === 'bytes') {\n                if (strategy.size !== undefined) {\n                    throw new RangeError('The strategy for a byte stream cannot have a size function');\n                }\n                const highWaterMark = ExtractHighWaterMark(strategy, 0);\n                SetUpReadableByteStreamControllerFromUnderlyingSource(this, underlyingSource, highWaterMark);\n            }\n            else {\n                const sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n                const highWaterMark = ExtractHighWaterMark(strategy, 1);\n                SetUpReadableStreamDefaultControllerFromUnderlyingSource(this, underlyingSource, highWaterMark, sizeAlgorithm);\n            }\n        }\n        /**\n         * Whether or not the readable stream is locked to a {@link ReadableStreamDefaultReader | reader}.\n         */\n        get locked() {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('locked');\n            }\n            return IsReadableStreamLocked(this);\n        }\n        /**\n         * Cancels the stream, signaling a loss of interest in the stream by a consumer.\n         *\n         * The supplied `reason` argument will be given to the underlying source's {@link UnderlyingSource.cancel | cancel()}\n         * method, which might or might not use it.\n         */\n        cancel(reason = undefined) {\n            if (!IsReadableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$1('cancel'));\n            }\n            if (IsReadableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot cancel a stream that already has a reader'));\n            }\n            return ReadableStreamCancel(this, reason);\n        }\n        getReader(rawOptions = undefined) {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('getReader');\n            }\n            const options = convertReaderOptions(rawOptions, 'First parameter');\n            if (options.mode === undefined) {\n                return AcquireReadableStreamDefaultReader(this);\n            }\n            return AcquireReadableStreamBYOBReader(this);\n        }\n        pipeThrough(rawTransform, rawOptions = {}) {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('pipeThrough');\n            }\n            assertRequiredArgument(rawTransform, 1, 'pipeThrough');\n            const transform = convertReadableWritablePair(rawTransform, 'First parameter');\n            const options = convertPipeOptions(rawOptions, 'Second parameter');\n            if (IsReadableStreamLocked(this)) {\n                throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked ReadableStream');\n            }\n            if (IsWritableStreamLocked(transform.writable)) {\n                throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked WritableStream');\n            }\n            const promise = ReadableStreamPipeTo(this, transform.writable, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n            setPromiseIsHandledToTrue(promise);\n            return transform.readable;\n        }\n        pipeTo(destination, rawOptions = {}) {\n            if (!IsReadableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$1('pipeTo'));\n            }\n            if (destination === undefined) {\n                return promiseRejectedWith(`Parameter 1 is required in 'pipeTo'.`);\n            }\n            if (!IsWritableStream(destination)) {\n                return promiseRejectedWith(new TypeError(`ReadableStream.prototype.pipeTo's first argument must be a WritableStream`));\n            }\n            let options;\n            try {\n                options = convertPipeOptions(rawOptions, 'Second parameter');\n            }\n            catch (e) {\n                return promiseRejectedWith(e);\n            }\n            if (IsReadableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked ReadableStream'));\n            }\n            if (IsWritableStreamLocked(destination)) {\n                return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked WritableStream'));\n            }\n            return ReadableStreamPipeTo(this, destination, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n        }\n        /**\n         * Tees this readable stream, returning a two-element array containing the two resulting branches as\n         * new {@link ReadableStream} instances.\n         *\n         * Teeing a stream will lock it, preventing any other consumer from acquiring a reader.\n         * To cancel the stream, cancel both of the resulting branches; a composite cancellation reason will then be\n         * propagated to the stream's underlying source.\n         *\n         * Note that the chunks seen in each branch will be the same object. If the chunks are not immutable,\n         * this could allow interference between the two branches.\n         */\n        tee() {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('tee');\n            }\n            const branches = ReadableStreamTee(this);\n            return CreateArrayFromList(branches);\n        }\n        values(rawOptions = undefined) {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('values');\n            }\n            const options = convertIteratorOptions(rawOptions, 'First parameter');\n            return AcquireReadableStreamAsyncIterator(this, options.preventCancel);\n        }\n    }\n    Object.defineProperties(ReadableStream.prototype, {\n        cancel: { enumerable: true },\n        getReader: { enumerable: true },\n        pipeThrough: { enumerable: true },\n        pipeTo: { enumerable: true },\n        tee: { enumerable: true },\n        values: { enumerable: true },\n        locked: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStream',\n            configurable: true\n        });\n    }\n    if (typeof SymbolPolyfill.asyncIterator === 'symbol') {\n        Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.asyncIterator, {\n            value: ReadableStream.prototype.values,\n            writable: true,\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableStream.\n    // Throws if and only if startAlgorithm throws.\n    function CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark = 1, sizeAlgorithm = () => 1) {\n        const stream = Object.create(ReadableStream.prototype);\n        InitializeReadableStream(stream);\n        const controller = Object.create(ReadableStreamDefaultController.prototype);\n        SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n        return stream;\n    }\n    // Throws if and only if startAlgorithm throws.\n    function CreateReadableByteStream(startAlgorithm, pullAlgorithm, cancelAlgorithm) {\n        const stream = Object.create(ReadableStream.prototype);\n        InitializeReadableStream(stream);\n        const controller = Object.create(ReadableByteStreamController.prototype);\n        SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, 0, undefined);\n        return stream;\n    }\n    function InitializeReadableStream(stream) {\n        stream._state = 'readable';\n        stream._reader = undefined;\n        stream._storedError = undefined;\n        stream._disturbed = false;\n    }\n    function IsReadableStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readableStreamController')) {\n            return false;\n        }\n        return x instanceof ReadableStream;\n    }\n    function IsReadableStreamLocked(stream) {\n        if (stream._reader === undefined) {\n            return false;\n        }\n        return true;\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamCancel(stream, reason) {\n        stream._disturbed = true;\n        if (stream._state === 'closed') {\n            return promiseResolvedWith(undefined);\n        }\n        if (stream._state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        ReadableStreamClose(stream);\n        const reader = stream._reader;\n        if (reader !== undefined && IsReadableStreamBYOBReader(reader)) {\n            reader._readIntoRequests.forEach(readIntoRequest => {\n                readIntoRequest._closeSteps(undefined);\n            });\n            reader._readIntoRequests = new SimpleQueue();\n        }\n        const sourceCancelPromise = stream._readableStreamController[CancelSteps](reason);\n        return transformPromiseWith(sourceCancelPromise, noop);\n    }\n    function ReadableStreamClose(stream) {\n        stream._state = 'closed';\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return;\n        }\n        defaultReaderClosedPromiseResolve(reader);\n        if (IsReadableStreamDefaultReader(reader)) {\n            reader._readRequests.forEach(readRequest => {\n                readRequest._closeSteps();\n            });\n            reader._readRequests = new SimpleQueue();\n        }\n    }\n    function ReadableStreamError(stream, e) {\n        stream._state = 'errored';\n        stream._storedError = e;\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return;\n        }\n        defaultReaderClosedPromiseReject(reader, e);\n        if (IsReadableStreamDefaultReader(reader)) {\n            reader._readRequests.forEach(readRequest => {\n                readRequest._errorSteps(e);\n            });\n            reader._readRequests = new SimpleQueue();\n        }\n        else {\n            reader._readIntoRequests.forEach(readIntoRequest => {\n                readIntoRequest._errorSteps(e);\n            });\n            reader._readIntoRequests = new SimpleQueue();\n        }\n    }\n    // Helper functions for the ReadableStream.\n    function streamBrandCheckException$1(name) {\n        return new TypeError(`ReadableStream.prototype.${name} can only be used on a ReadableStream`);\n    }\n\n    function convertQueuingStrategyInit(init, context) {\n        assertDictionary(init, context);\n        const highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n        assertRequiredField(highWaterMark, 'highWaterMark', 'QueuingStrategyInit');\n        return {\n            highWaterMark: convertUnrestrictedDouble(highWaterMark)\n        };\n    }\n\n    // The size function must not have a prototype property nor be a constructor\n    const byteLengthSizeFunction = (chunk) => {\n        return chunk.byteLength;\n    };\n    Object.defineProperty(byteLengthSizeFunction, 'name', {\n        value: 'size',\n        configurable: true\n    });\n    /**\n     * A queuing strategy that counts the number of bytes in each chunk.\n     *\n     * @public\n     */\n    class ByteLengthQueuingStrategy {\n        constructor(options) {\n            assertRequiredArgument(options, 1, 'ByteLengthQueuingStrategy');\n            options = convertQueuingStrategyInit(options, 'First parameter');\n            this._byteLengthQueuingStrategyHighWaterMark = options.highWaterMark;\n        }\n        /**\n         * Returns the high water mark provided to the constructor.\n         */\n        get highWaterMark() {\n            if (!IsByteLengthQueuingStrategy(this)) {\n                throw byteLengthBrandCheckException('highWaterMark');\n            }\n            return this._byteLengthQueuingStrategyHighWaterMark;\n        }\n        /**\n         * Measures the size of `chunk` by returning the value of its `byteLength` property.\n         */\n        get size() {\n            if (!IsByteLengthQueuingStrategy(this)) {\n                throw byteLengthBrandCheckException('size');\n            }\n            return byteLengthSizeFunction;\n        }\n    }\n    Object.defineProperties(ByteLengthQueuingStrategy.prototype, {\n        highWaterMark: { enumerable: true },\n        size: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ByteLengthQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ByteLengthQueuingStrategy',\n            configurable: true\n        });\n    }\n    // Helper functions for the ByteLengthQueuingStrategy.\n    function byteLengthBrandCheckException(name) {\n        return new TypeError(`ByteLengthQueuingStrategy.prototype.${name} can only be used on a ByteLengthQueuingStrategy`);\n    }\n    function IsByteLengthQueuingStrategy(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_byteLengthQueuingStrategyHighWaterMark')) {\n            return false;\n        }\n        return x instanceof ByteLengthQueuingStrategy;\n    }\n\n    // The size function must not have a prototype property nor be a constructor\n    const countSizeFunction = () => {\n        return 1;\n    };\n    Object.defineProperty(countSizeFunction, 'name', {\n        value: 'size',\n        configurable: true\n    });\n    /**\n     * A queuing strategy that counts the number of chunks.\n     *\n     * @public\n     */\n    class CountQueuingStrategy {\n        constructor(options) {\n            assertRequiredArgument(options, 1, 'CountQueuingStrategy');\n            options = convertQueuingStrategyInit(options, 'First parameter');\n            this._countQueuingStrategyHighWaterMark = options.highWaterMark;\n        }\n        /**\n         * Returns the high water mark provided to the constructor.\n         */\n        get highWaterMark() {\n            if (!IsCountQueuingStrategy(this)) {\n                throw countBrandCheckException('highWaterMark');\n            }\n            return this._countQueuingStrategyHighWaterMark;\n        }\n        /**\n         * Measures the size of `chunk` by always returning 1.\n         * This ensures that the total queue size is a count of the number of chunks in the queue.\n         */\n        get size() {\n            if (!IsCountQueuingStrategy(this)) {\n                throw countBrandCheckException('size');\n            }\n            return countSizeFunction;\n        }\n    }\n    Object.defineProperties(CountQueuingStrategy.prototype, {\n        highWaterMark: { enumerable: true },\n        size: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(CountQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n            value: 'CountQueuingStrategy',\n            configurable: true\n        });\n    }\n    // Helper functions for the CountQueuingStrategy.\n    function countBrandCheckException(name) {\n        return new TypeError(`CountQueuingStrategy.prototype.${name} can only be used on a CountQueuingStrategy`);\n    }\n    function IsCountQueuingStrategy(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_countQueuingStrategyHighWaterMark')) {\n            return false;\n        }\n        return x instanceof CountQueuingStrategy;\n    }\n\n    function convertTransformer(original, context) {\n        assertDictionary(original, context);\n        const flush = original === null || original === void 0 ? void 0 : original.flush;\n        const readableType = original === null || original === void 0 ? void 0 : original.readableType;\n        const start = original === null || original === void 0 ? void 0 : original.start;\n        const transform = original === null || original === void 0 ? void 0 : original.transform;\n        const writableType = original === null || original === void 0 ? void 0 : original.writableType;\n        return {\n            flush: flush === undefined ?\n                undefined :\n                convertTransformerFlushCallback(flush, original, `${context} has member 'flush' that`),\n            readableType,\n            start: start === undefined ?\n                undefined :\n                convertTransformerStartCallback(start, original, `${context} has member 'start' that`),\n            transform: transform === undefined ?\n                undefined :\n                convertTransformerTransformCallback(transform, original, `${context} has member 'transform' that`),\n            writableType\n        };\n    }\n    function convertTransformerFlushCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => promiseCall(fn, original, [controller]);\n    }\n    function convertTransformerStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => reflectCall(fn, original, [controller]);\n    }\n    function convertTransformerTransformCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (chunk, controller) => promiseCall(fn, original, [chunk, controller]);\n    }\n\n    // Class TransformStream\n    /**\n     * A transform stream consists of a pair of streams: a {@link WritableStream | writable stream},\n     * known as its writable side, and a {@link ReadableStream | readable stream}, known as its readable side.\n     * In a manner specific to the transform stream in question, writes to the writable side result in new data being\n     * made available for reading from the readable side.\n     *\n     * @public\n     */\n    class TransformStream {\n        constructor(rawTransformer = {}, rawWritableStrategy = {}, rawReadableStrategy = {}) {\n            if (rawTransformer === undefined) {\n                rawTransformer = null;\n            }\n            const writableStrategy = convertQueuingStrategy(rawWritableStrategy, 'Second parameter');\n            const readableStrategy = convertQueuingStrategy(rawReadableStrategy, 'Third parameter');\n            const transformer = convertTransformer(rawTransformer, 'First parameter');\n            if (transformer.readableType !== undefined) {\n                throw new RangeError('Invalid readableType specified');\n            }\n            if (transformer.writableType !== undefined) {\n                throw new RangeError('Invalid writableType specified');\n            }\n            const readableHighWaterMark = ExtractHighWaterMark(readableStrategy, 0);\n            const readableSizeAlgorithm = ExtractSizeAlgorithm(readableStrategy);\n            const writableHighWaterMark = ExtractHighWaterMark(writableStrategy, 1);\n            const writableSizeAlgorithm = ExtractSizeAlgorithm(writableStrategy);\n            let startPromise_resolve;\n            const startPromise = newPromise(resolve => {\n                startPromise_resolve = resolve;\n            });\n            InitializeTransformStream(this, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n            SetUpTransformStreamDefaultControllerFromTransformer(this, transformer);\n            if (transformer.start !== undefined) {\n                startPromise_resolve(transformer.start(this._transformStreamController));\n            }\n            else {\n                startPromise_resolve(undefined);\n            }\n        }\n        /**\n         * The readable side of the transform stream.\n         */\n        get readable() {\n            if (!IsTransformStream(this)) {\n                throw streamBrandCheckException('readable');\n            }\n            return this._readable;\n        }\n        /**\n         * The writable side of the transform stream.\n         */\n        get writable() {\n            if (!IsTransformStream(this)) {\n                throw streamBrandCheckException('writable');\n            }\n            return this._writable;\n        }\n    }\n    Object.defineProperties(TransformStream.prototype, {\n        readable: { enumerable: true },\n        writable: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(TransformStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'TransformStream',\n            configurable: true\n        });\n    }\n    function InitializeTransformStream(stream, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm) {\n        function startAlgorithm() {\n            return startPromise;\n        }\n        function writeAlgorithm(chunk) {\n            return TransformStreamDefaultSinkWriteAlgorithm(stream, chunk);\n        }\n        function abortAlgorithm(reason) {\n            return TransformStreamDefaultSinkAbortAlgorithm(stream, reason);\n        }\n        function closeAlgorithm() {\n            return TransformStreamDefaultSinkCloseAlgorithm(stream);\n        }\n        stream._writable = CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, writableHighWaterMark, writableSizeAlgorithm);\n        function pullAlgorithm() {\n            return TransformStreamDefaultSourcePullAlgorithm(stream);\n        }\n        function cancelAlgorithm(reason) {\n            TransformStreamErrorWritableAndUnblockWrite(stream, reason);\n            return promiseResolvedWith(undefined);\n        }\n        stream._readable = CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n        // The [[backpressure]] slot is set to undefined so that it can be initialised by TransformStreamSetBackpressure.\n        stream._backpressure = undefined;\n        stream._backpressureChangePromise = undefined;\n        stream._backpressureChangePromise_resolve = undefined;\n        TransformStreamSetBackpressure(stream, true);\n        stream._transformStreamController = undefined;\n    }\n    function IsTransformStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_transformStreamController')) {\n            return false;\n        }\n        return x instanceof TransformStream;\n    }\n    // This is a no-op if both sides are already errored.\n    function TransformStreamError(stream, e) {\n        ReadableStreamDefaultControllerError(stream._readable._readableStreamController, e);\n        TransformStreamErrorWritableAndUnblockWrite(stream, e);\n    }\n    function TransformStreamErrorWritableAndUnblockWrite(stream, e) {\n        TransformStreamDefaultControllerClearAlgorithms(stream._transformStreamController);\n        WritableStreamDefaultControllerErrorIfNeeded(stream._writable._writableStreamController, e);\n        if (stream._backpressure) {\n            // Pretend that pull() was called to permit any pending write() calls to complete. TransformStreamSetBackpressure()\n            // cannot be called from enqueue() or pull() once the ReadableStream is errored, so this will will be the final time\n            // _backpressure is set.\n            TransformStreamSetBackpressure(stream, false);\n        }\n    }\n    function TransformStreamSetBackpressure(stream, backpressure) {\n        // Passes also when called during construction.\n        if (stream._backpressureChangePromise !== undefined) {\n            stream._backpressureChangePromise_resolve();\n        }\n        stream._backpressureChangePromise = newPromise(resolve => {\n            stream._backpressureChangePromise_resolve = resolve;\n        });\n        stream._backpressure = backpressure;\n    }\n    // Class TransformStreamDefaultController\n    /**\n     * Allows control of the {@link ReadableStream} and {@link WritableStream} of the associated {@link TransformStream}.\n     *\n     * @public\n     */\n    class TransformStreamDefaultController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the desired size to fill the readable side’s internal queue. It can be negative, if the queue is over-full.\n         */\n        get desiredSize() {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('desiredSize');\n            }\n            const readableController = this._controlledTransformStream._readable._readableStreamController;\n            return ReadableStreamDefaultControllerGetDesiredSize(readableController);\n        }\n        enqueue(chunk = undefined) {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('enqueue');\n            }\n            TransformStreamDefaultControllerEnqueue(this, chunk);\n        }\n        /**\n         * Errors both the readable side and the writable side of the controlled transform stream, making all future\n         * interactions with it fail with the given error `e`. Any chunks queued for transformation will be discarded.\n         */\n        error(reason = undefined) {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('error');\n            }\n            TransformStreamDefaultControllerError(this, reason);\n        }\n        /**\n         * Closes the readable side and errors the writable side of the controlled transform stream. This is useful when the\n         * transformer only needs to consume a portion of the chunks written to the writable side.\n         */\n        terminate() {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('terminate');\n            }\n            TransformStreamDefaultControllerTerminate(this);\n        }\n    }\n    Object.defineProperties(TransformStreamDefaultController.prototype, {\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        terminate: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(TransformStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'TransformStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Transform Stream Default Controller Abstract Operations\n    function IsTransformStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledTransformStream')) {\n            return false;\n        }\n        return x instanceof TransformStreamDefaultController;\n    }\n    function SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm) {\n        controller._controlledTransformStream = stream;\n        stream._transformStreamController = controller;\n        controller._transformAlgorithm = transformAlgorithm;\n        controller._flushAlgorithm = flushAlgorithm;\n    }\n    function SetUpTransformStreamDefaultControllerFromTransformer(stream, transformer) {\n        const controller = Object.create(TransformStreamDefaultController.prototype);\n        let transformAlgorithm = (chunk) => {\n            try {\n                TransformStreamDefaultControllerEnqueue(controller, chunk);\n                return promiseResolvedWith(undefined);\n            }\n            catch (transformResultE) {\n                return promiseRejectedWith(transformResultE);\n            }\n        };\n        let flushAlgorithm = () => promiseResolvedWith(undefined);\n        if (transformer.transform !== undefined) {\n            transformAlgorithm = chunk => transformer.transform(chunk, controller);\n        }\n        if (transformer.flush !== undefined) {\n            flushAlgorithm = () => transformer.flush(controller);\n        }\n        SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm);\n    }\n    function TransformStreamDefaultControllerClearAlgorithms(controller) {\n        controller._transformAlgorithm = undefined;\n        controller._flushAlgorithm = undefined;\n    }\n    function TransformStreamDefaultControllerEnqueue(controller, chunk) {\n        const stream = controller._controlledTransformStream;\n        const readableController = stream._readable._readableStreamController;\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(readableController)) {\n            throw new TypeError('Readable side is not in a state that permits enqueue');\n        }\n        // We throttle transform invocations based on the backpressure of the ReadableStream, but we still\n        // accept TransformStreamDefaultControllerEnqueue() calls.\n        try {\n            ReadableStreamDefaultControllerEnqueue(readableController, chunk);\n        }\n        catch (e) {\n            // This happens when readableStrategy.size() throws.\n            TransformStreamErrorWritableAndUnblockWrite(stream, e);\n            throw stream._readable._storedError;\n        }\n        const backpressure = ReadableStreamDefaultControllerHasBackpressure(readableController);\n        if (backpressure !== stream._backpressure) {\n            TransformStreamSetBackpressure(stream, true);\n        }\n    }\n    function TransformStreamDefaultControllerError(controller, e) {\n        TransformStreamError(controller._controlledTransformStream, e);\n    }\n    function TransformStreamDefaultControllerPerformTransform(controller, chunk) {\n        const transformPromise = controller._transformAlgorithm(chunk);\n        return transformPromiseWith(transformPromise, undefined, r => {\n            TransformStreamError(controller._controlledTransformStream, r);\n            throw r;\n        });\n    }\n    function TransformStreamDefaultControllerTerminate(controller) {\n        const stream = controller._controlledTransformStream;\n        const readableController = stream._readable._readableStreamController;\n        ReadableStreamDefaultControllerClose(readableController);\n        const error = new TypeError('TransformStream terminated');\n        TransformStreamErrorWritableAndUnblockWrite(stream, error);\n    }\n    // TransformStreamDefaultSink Algorithms\n    function TransformStreamDefaultSinkWriteAlgorithm(stream, chunk) {\n        const controller = stream._transformStreamController;\n        if (stream._backpressure) {\n            const backpressureChangePromise = stream._backpressureChangePromise;\n            return transformPromiseWith(backpressureChangePromise, () => {\n                const writable = stream._writable;\n                const state = writable._state;\n                if (state === 'erroring') {\n                    throw writable._storedError;\n                }\n                return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n            });\n        }\n        return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n    }\n    function TransformStreamDefaultSinkAbortAlgorithm(stream, reason) {\n        // abort() is not called synchronously, so it is possible for abort() to be called when the stream is already\n        // errored.\n        TransformStreamError(stream, reason);\n        return promiseResolvedWith(undefined);\n    }\n    function TransformStreamDefaultSinkCloseAlgorithm(stream) {\n        // stream._readable cannot change after construction, so caching it across a call to user code is safe.\n        const readable = stream._readable;\n        const controller = stream._transformStreamController;\n        const flushPromise = controller._flushAlgorithm();\n        TransformStreamDefaultControllerClearAlgorithms(controller);\n        // Return a promise that is fulfilled with undefined on success.\n        return transformPromiseWith(flushPromise, () => {\n            if (readable._state === 'errored') {\n                throw readable._storedError;\n            }\n            ReadableStreamDefaultControllerClose(readable._readableStreamController);\n        }, r => {\n            TransformStreamError(stream, r);\n            throw readable._storedError;\n        });\n    }\n    // TransformStreamDefaultSource Algorithms\n    function TransformStreamDefaultSourcePullAlgorithm(stream) {\n        // Invariant. Enforced by the promises returned by start() and pull().\n        TransformStreamSetBackpressure(stream, false);\n        // Prevent the next pull() call until there is backpressure.\n        return stream._backpressureChangePromise;\n    }\n    // Helper functions for the TransformStreamDefaultController.\n    function defaultControllerBrandCheckException(name) {\n        return new TypeError(`TransformStreamDefaultController.prototype.${name} can only be used on a TransformStreamDefaultController`);\n    }\n    // Helper functions for the TransformStream.\n    function streamBrandCheckException(name) {\n        return new TypeError(`TransformStream.prototype.${name} can only be used on a TransformStream`);\n    }\n\n    exports.ByteLengthQueuingStrategy = ByteLengthQueuingStrategy;\n    exports.CountQueuingStrategy = CountQueuingStrategy;\n    exports.ReadableByteStreamController = ReadableByteStreamController;\n    exports.ReadableStream = ReadableStream;\n    exports.ReadableStreamBYOBReader = ReadableStreamBYOBReader;\n    exports.ReadableStreamBYOBRequest = ReadableStreamBYOBRequest;\n    exports.ReadableStreamDefaultController = ReadableStreamDefaultController;\n    exports.ReadableStreamDefaultReader = ReadableStreamDefaultReader;\n    exports.TransformStream = TransformStream;\n    exports.TransformStreamDefaultController = TransformStreamDefaultController;\n    exports.WritableStream = WritableStream;\n    exports.WritableStreamDefaultController = WritableStreamDefaultController;\n    exports.WritableStreamDefaultWriter = WritableStreamDefaultWriter;\n\n    Object.defineProperty(exports, '__esModule', { value: true });\n\n})));\n//# sourceMappingURL=ponyfill.es2018.js.map\n","// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n",null,"/* c8 ignore start */\n// 64 KiB (same size chrome slice theirs blob into Uint8array's)\nconst POOL_SIZE = 65536;\n\nif (!globalThis.ReadableStream) {\n  try {\n    Object.assign(globalThis, require('stream/web'))\n  } catch (error) {\n\t\t// TODO: Remove when only supporting node >= 16.5.0\n    Object.assign(globalThis, require('web-streams-polyfill/dist/ponyfill.es2018.js'))\n  }\n}\n\ntry {\n  const {Blob} = require('buffer')\n  if (Blob && !Blob.prototype.stream) {\n\t\tBlob.prototype.stream = function name(params) {\n\t\t\tlet position = 0;\n\t\t\tconst blob = this;\n\n\t\t\treturn new ReadableStream({\n\t\t\t\ttype: 'bytes',\n\t\t\t\tasync pull(ctrl) {\n\t\t\t\t\tconst chunk = blob.slice(position, Math.min(blob.size, position + POOL_SIZE));\n\t\t\t\t\tconst buffer = await chunk.arrayBuffer();\n\t\t\t\t\tposition += buffer.byteLength;\n\t\t\t\t\tctrl.enqueue(new Uint8Array(buffer))\n\n\t\t\t\t\tif (position === blob.size) {\n\t\t\t\t\t\tctrl.close()\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t})\n\t\t}\n\t}\n} catch (error) {}\n/* c8 ignore end */\n","var r=function(r,e,u){void 0===e&&(e=null),void 0===u&&(u=null);try{var l,t=function(){if(!r.path_args)return r.base_url+r.path_url;var e=r.path_url.split(\"/\").map(function(e){return e.startsWith(\"{\")&&e.endsWith(\"}\")?r.path_args[e.substring(1,e.length-1)]:e}).join(\"/\");return r.base_url+e}()+(r.query_args?\"?\"+new URLSearchParams(r.query_args).toString():\"\"),n=r.header||{\"Accept-Type\":\"application/json\"},o=r.body?JSON.stringify(r.body):null,a=null==(l=r.security)?void 0:l.bearer;return a&&(n.Authorization=\"Bearer \"+a),o&&!n[\"Content-Type\"]&&(n[\"Content-Type\"]=\"application/json\"),Promise.resolve(fetch(t,{method:r.method,headers:n,body:o})).then(function(r){return r.ok?Promise.resolve(e?e(r):r.json()):u?Promise.resolve(u(r)):null})}catch(r){return Promise.reject(r)}},e=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/browser/list\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),u=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/browser\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_put=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"PUT\",base_url:q(),path_url:\"/browser\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_delete=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"DELETE\",base_url:q(),path_url:\"/browser\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),l=function(){function e(){}return e.do_put=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"PUT\",base_url:q(),path_url:\"/cc\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_delete=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"DELETE\",base_url:q(),path_url:\"/cc\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),t=function(){function e(){}return e.do_post=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"POST\",base_url:q(),path_url:\"/cc/list\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),n=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/cc/total\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),o=function(){function e(){}return e.do_post=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"POST\",base_url:q(),path_url:\"/ci\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),a=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/code/list\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),s=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/code\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_put=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"PUT\",base_url:q(),path_url:\"/code\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_delete=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"DELETE\",base_url:q(),path_url:\"/code\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),i=function(){function e(){}return e.do_post=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"POST\",base_url:q(),path_url:\"/crawl/start\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),d=function(){function e(){}return e.do_post=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"POST\",base_url:q(),path_url:\"/crawl/stop\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),c=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/crawl\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_put=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"PUT\",base_url:q(),path_url:\"/crawl\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_delete=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"DELETE\",base_url:q(),path_url:\"/crawl\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),h=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/crawl/list\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),y=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/monitor\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_put=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"PUT\",base_url:q(),path_url:\"/monitor\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_delete=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"DELETE\",base_url:q(),path_url:\"/monitor\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),_=function(){function e(){}return e.do_post=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"POST\",base_url:q(),path_url:\"/pdf\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),g=function(){function e(){}return e.do_post=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"POST\",base_url:q(),path_url:\"/html\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),p=function(){function e(){}return e.do_post=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"POST\",base_url:q(),path_url:\"/sandbox/func\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),b=function(){function e(){}return e.do_post=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"POST\",base_url:q(),path_url:\"/sandbox/code\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),m=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/search_engine/all\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),v=function(){function e(){}return e.do_get=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"GET\",base_url:q(),path_url:\"/search_engine\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_put=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"PUT\",base_url:q(),path_url:\"/search_engine\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e.do_delete=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"DELETE\",base_url:q(),path_url:\"/search_engine\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),f=function(){function e(){}return e.do_post=function(e,u,l){void 0===u&&(u=null),void 0===l&&(l=null);try{return Promise.resolve(r({method:\"POST\",base_url:q(),path_url:\"/search\",path_args:e.path_args||null,query_args:e.query_args||null,header:e.header||null,body:e.body||null,security:e.security||null},u,l))}catch(r){return Promise.reject(r)}},e}(),P=null;function q(){return P||\"http://127.0.0.1:18082/v1\"}\"undefined\"==typeof fetch&&(global.fetch=require(\"node-fetch\")),exports.Browser=u,exports.BrowserList=e,exports.Cc=l,exports.CcList=t,exports.CcTotal=n,exports.Ci=o,exports.Code=s,exports.CodeList=a,exports.Crawl=c,exports.CrawlList=h,exports.CrawlStart=i,exports.CrawlStop=d,exports.Html=g,exports.Monitor=y,exports.Pdf=_,exports.SandboxCode=b,exports.SandboxFunc=p,exports.Search=f,exports.SearchEngine=v,exports.SearchEngineAll=m,exports.getGlobalBaseUrl=q,exports.setGlobalBaseUrl=function(r){P=r};\n//# sourceMappingURL=seo_js_sdk.cjs.map\n","module.exports = require(\"assert\");","module.exports = require(\"buffer\");","module.exports = require(\"child_process\");","module.exports = require(\"crypto\");","module.exports = require(\"events\");","module.exports = require(\"fs\");","module.exports = require(\"http\");","module.exports = require(\"https\");","module.exports = require(\"net\");","module.exports = require(\"os\");","module.exports = require(\"path\");","module.exports = require(\"perf_hooks\");","module.exports = require(\"process\");","module.exports = require(\"stream\");","module.exports = require(\"tls\");","module.exports = require(\"url\");","module.exports = require(\"util\");","module.exports = require(\"zlib\");","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = __dirname + \"/\";","// startup\n// Load entry module and return exports\n// This entry module is referenced by other modules so it can't be inlined\nvar __webpack_exports__ = __webpack_require__(3109);\n"],"mappings":";;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACzDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACpJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AClRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AC5DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AC1EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACxFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AC1XA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACvFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AChTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AC3FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACvTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACzDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxhBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACxMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACjEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC9SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC3OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AClxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACleA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC15BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC1OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACl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xQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC3IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AClOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACzUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACn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zvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACnXA;;;A;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACvQA;AACA;AACA;AACA;AACA;AACA,KACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACpkIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AChCA;;;A;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACpCA;AACA;;;A;;;;;;ACDA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACNA;AACA;;;;ACDA;AACA;AACA;AACA;;;;A","sourceRoot":""}